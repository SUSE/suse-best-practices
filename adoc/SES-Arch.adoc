== Architectural Overview

This architecture overview section complements the https://www.suse.com/docrep/documents/1mdg7eq2kz/suse_enterprise_storage_technical_overview_wp.pdf[SUSE Enterprise Storage Technical Overview] document available online which presents the concepts behind software defined storage and Ceph as well as a quick start guide (non-platform specific).

=== Solution Architecture

{SESProduct} provides unified block, file, and object access based on Ceph. Ceph is a distributed storage solution designed for scalability, reliability and performance. A critical component of Ceph is the RADOS object storage. RADOS enables a number of storage nodes to function together to store and retrieve data from the cluster using object storage techniques. The result is a storage solution that is abstracted from the hardware.
Ceph supports both native and traditional client access. The native clients are aware of the storage topology and communicate directly with the storage daemons over the public network, resulting in horizontally scaling performance. Non-native protocols, such as ISCSI, S3, and NFS require the use of gateways. While these gateways may be thought of as a limiting factor, the ISCSI and S3 gateways can scale horizontally using load balancing techniques.
[[img-SES-Arch]]
.Ceph Architecture
image::{imgpath}ses-rag.png[Ceph Architecture, scaledwidth=100%]

In addition to the required network infrastructure, the minimum {SESProduct} cluster is comprised of a minimum of one administration server (physical or virtual), four object storage device nodes (OSDs), and three monitor nodes (MONs).

.Specific to this implementation:
 * One system is deployed as the administrative host server. The administration host is the Salt-master and hosts the {SESProduct} Administration Interface, openATTIC, which is the central management system which supports the cluster.
 * Three systems are deployed as monitor (MONs) nodes. Monitor nodes maintain information about the cluster health state, a map of the other monitor nodes and a CRUSH map. They also keep history of changes performed to the cluster.
 * Additional  servers may be deployed as iSCSI gateway nodes. iSCSI is a storage area network (SAN) protocol that allows clients (called initiators) to send SCSI command to SCSI storage devices (targets) on remote servers. This protocol is utilized for block-based connectivity to environments such as Microsoft Windows, VMware, and traditional UNIX. These systems may be scaled horizontally through client usage of multi-path technology.
 * The RADOS gateway provides S3 and Swift based access methods to the cluster. These nodes are generally situated behind a load balancer infrastructure to provide redundancy and scalability. It is important to note that the load generated by the RADOS gateway can consume a significant amount of compute and memory resources making the minimum recommended configuration contain 6-8 CPU cores and 32GB of RAM.
 * {SESProduct} requires a minimum of four systems as storage nodes. The storage nodes contain individual storage devices that are each assigned an Object Storage Daemon (OSD). The OSD assigned to the device stores data and manages the data replication and rebalancing processes. OSDs also communicate with the monitor (MON) nodes and provide them with the state of the other OSDs.

=== Networking Architecture

A software-defined solution is only as reliable as its slowest and least redundant component. This makes it important to design and implement a robust, high performance storage network infrastructure. From a network perspective for Ceph, this translates into:

* Separation of cluster (backend) and client-facing (public) network traffic.  This isolates Ceph OSD replication activities from Ceph clients. This may be achieved through separate physical networks or through use of VLANs.
* Redundancy and capacity in the form of bonded network interfaces connected to switches.

The following figure shows the logical layout of the traditional Ceph cluster implementation.

[[img-SESNetwork]]
.Ceph Network Architecture
image::{imgpath}sesnetwork.png[Ceph Network Architecture, scaledwidth=100%]
