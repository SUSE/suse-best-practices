<?xml version="1.0" encoding="UTF-8"?>
<!--<?oxygen RNGSchema="http://www.oasis-open.org/docbook/xml/5.0/rng/docbook.rng" type="xml"?>-->
<!DOCTYPE article [
<!ENTITY % entity SYSTEM "entity-decl.ent">
%entity;
]>

<article role="sbp" xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude"
	xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0" xml:id="art-rook-kubernetes-ceph"
	xml:lang="en">

	<info>
		<title>Rook Best Practices for Running Ceph on Kubernetes </title>
		<productname>SUSE Enterprise Storage, Ceph, Rook, Kubernetes, CaaS Platform</productname>
		<dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
			<dm:bugtracker>
				<dm:url>https://github.com/SUSE/suse-best-practices/issues/new</dm:url>
				<dm:product>Rook Best Practices for Running Ceph on Kubernetes</dm:product>
			</dm:bugtracker>
			<dm:editurl>https://github.com/SUSE/suse-best-practices/edit/main/xml/</dm:editurl>
		</dm:docmanager>		
		
		
			<meta name="series">SUSE Best Practices</meta> 
			<meta name="category">Storage</meta> 
			
		<meta name="platform">SUSE Enterprise Storage</meta>    
			<!--<meta name="platform"></meta>-->        
			
			<authorgroup>
			<author>
			<personname>
				<firstname>Blaine</firstname>
			<surname>Gardner</surname>
			</personname>
			<affiliation>
				<jobtitle>Senior Software Developer</jobtitle>
			<orgname>SUSE</orgname>
			</affiliation>
			</author>
			<author>
			<personname>
			<firstname>Alexandra</firstname>
			<surname>Settle</surname>
			</personname>
			<affiliation>
				<jobtitle>Senior Information Developer</jobtitle>
			<orgname>SUSE</orgname>
			</affiliation>
			</author>
			<!--<editor>
			<orgname></orgname>
			</editor>
			<othercredit>
			<orgname></orgname>
			</othercredit>-->
			</authorgroup>
		
		<cover role="logos">
			<mediaobject>
				<imageobject>
					<imagedata fileref="suse.svg" width="4em"/>
				</imageobject>
			</mediaobject>
<!--			<mediaobject>
				<imageobject>
					<imagedata fileref="microsoft.svg" width="6em"/>
				</imageobject>
			</mediaobject>-->
		</cover>		

		<date>May 27, 2020</date>

		<abstract>
			<para>The document at hand provides an overview of the best practices and tested
				patterns of using Rook v1.3 to manage your Ceph Octopus cluster running in
				Kubernetes.</para>
			
			<para>
				<emphasis role="strong">Disclaimer: </emphasis>
				Documents published as part of the SUSE Best Practices series have been contributed voluntarily
				by SUSE employees and third parties. They are meant to serve as examples of how particular
				actions can be performed. They have been compiled with utmost attention to detail. However,
				this does not guarantee complete accuracy. SUSE cannot verify that actions described in these
				documents do what is claimed or whether actions described have unintended consequences.
				SUSE LLC, its affiliates, the authors, and the translators may not be held liable for possible errors
				or the consequences thereof.
			</para>
			
		</abstract>

	</info>

	<sect1 xml:id="sec-rook-bp-overview">
		<title>Overview</title>
		<para> Ceph and Kubernetes are both complex tools and harmonizing the interactions between
			the two can be daunting. This is especially true for users who are new to operating
			either system, prompting questions such as: </para>
		<itemizedlist>
			<listitem>
				<para> How can I restrict Ceph to a portion of my nodes? </para>
			</listitem>
			<listitem>
				<para> Can I set Kubernetes CPU or RAM limits for my Ceph daemons? </para>
			</listitem>
			<listitem>
				<para> What are some ways to get better performance from my cluster? </para>
			</listitem>
		</itemizedlist>
		<para> This document covers tested patterns and best practices to answer these questions and
			more. Our examples will help you configure and manage your Ceph cluster running in
			Kubernetes to meet your needs. The following examples and advice are based on Ceph
			Octopus (v15) with Rook v1.3 running in a Kubernetes 1.17 cluster. </para>
		<para> This is a moderately advanced topic, so basic experience with Rook is recommended.
			Before you begin, ensure you have the following requisite knowledge: </para>
		<itemizedlist>
			<listitem>
				<para> Basics of Kubernetes </para>
			</listitem>
			<listitem>
				<para> How to create Kubernetes applications using manifests </para>
			</listitem>
			<listitem>
				<para> Kubernetes topics: </para>
				<itemizedlist>
					<listitem>
						<para> Pods </para>
					</listitem>
					<listitem>
						<para> Nodes </para>
					</listitem>
					<listitem>
						<para> Labels </para>
					</listitem>
					<listitem>
						<para> Topology </para>
					</listitem>
					<listitem>
						<para> Taints and tolerations </para>
					</listitem>
					<listitem>
						<para> Affinity and Anti-affinity </para>
					</listitem>
					<listitem>
						<para> Resource requests </para>
					</listitem>
					<listitem>
						<para> Limits </para>
					</listitem>
				</itemizedlist>
			</listitem>
			<listitem>
				<para> Ceph components and daemons, basic Ceph configuration </para>
			</listitem>
			<listitem>
				<para> Rook basics and how to install Rook-Ceph. For more information see <link
						xlink:href="https://rook.io/docs/rook/v1.3/ceph-storage.html"/>
				</para>
			</listitem>
		</itemizedlist>
		<para> In places, we will give examples that describe an imaginary data center. This data
			center is hypothetical, and it will focus on the Ceph- and Rook-centric elements and
			ignore user applications. </para>
		<para> Our example data center has two rooms for data storage. A properly fault tolerant
			Ceph cluster should have at least three monitor (MON) nodes. These should be spread
			across fault-tolerant rooms if possible. The example will have a separate failure domain
			for the third monitor node. As such, our hypothetical data center has two rooms and one
			failure domain, with the following configuration: </para>
		<itemizedlist>
			<listitem>
				<para> The failure domain is small and can only to be used for the third Ceph MON;
					it does not have space for storage nodes. </para>
			</listitem>
			<listitem>
				<para> Eight OSD nodes provide a good amount of data safety without requiring too
					many nodes. </para>
			</listitem>
			<listitem>
				<para> These eight nodes should be equally separated — four to each data center
					room. </para>
			</listitem>
			<listitem>
				<para> The four nodes are separated in each room into two racks. </para>
			</listitem>
			<listitem>
				<para> In the event of a MON node failure, ensure that you can run MONs on each rack
					for failure scenarios. </para>
			</listitem>
		</itemizedlist>
		<para> The data center looks as follows: </para>

		<figure xml:id="fig-datacenter">
			<title>Example Datacenter</title>
			<mediaobject>
				<imageobject role="fo">
					<imagedata fileref="example-datacenter.png" width="100%"/>
				</imageobject>
				<imageobject role="html">
					<imagedata fileref="example-datacenter.png" width="100%"/>
				</imageobject>
			</mediaobject>
		</figure>

		<para> Now we will dig a little deeper and talk about the actual disks used for Rook and
			Ceph storage. To ensure we are following known Ceph best practices for this data center
			setup, ensure that MON storage goes on the SSDs. Because each rack should be able to run
			a Ceph MON, one of the nodes in each rack will have an SSD that is usable for MON
			storage. Additionally, all nodes in all racks (except in the failure domain) will have
			disks for OSD storage. This will look like the following: </para>

		<figure xml:id="fig-datacenter-disks">
			<title>Example Datacenter - Disks</title>
			<mediaobject>
				<imageobject role="fo">
					<imagedata fileref="example-datacenter-disks.png" width="100%"/>
				</imageobject>
				<imageobject role="html">
					<imagedata fileref="example-datacenter-disks.png" width="100%"/>
				</imageobject>
			</mediaobject>
		</figure>

		<important>
			<title>Diagrams</title>
			<para> Refer to these diagrams when we discuss the example data center below. </para>
		</important>

	</sect1>
	<sect1 xml:id="sec-rook-bp-intro">
		<title>Introduction</title>
		<para> Ceph and Kubernetes both have their own well-known and established best practices.
			Rook bridges the gap between Ceph and Kubernetes, putting it in a unique domain with its
			own best practices to follow. This document specifically covers best practice for
			running Ceph on Kubernetes with Rook. Because Rook augments on top of Kubernetes, it has
			different ways of meeting Ceph and Kubernetes best practices. This is in comparison to
			the bare metal version of each. Out of the box, Rook is predominantly a default Ceph
			cluster. The Ceph cluster needs tuning to meet user workloads, and Rook does not absolve
			the user from planning out their production storage cluster beforehand. </para>
		<para> For the purpose of this document, we will consider two simplified use cases to help
			us make informed decisions about Rook and Ceph: </para>

		<itemizedlist>
			<listitem>
				<para> Co-located: User applications co-exist on nodes running Ceph </para>
			</listitem>
			<listitem>
				<para> Disaggregated: Ceph nodes are totally separated from user applications
				</para>
			</listitem>
		</itemizedlist>

	</sect1>
	<sect1 xml:id="sec-rook-bp-general">
		<title>General Best Practices</title>
		<para> This chapter provides an outline of a series of generalized recommendations for best
			practices: </para>

		<itemizedlist>
			<listitem>
				<para> Ceph monitors are more stable on fast storage (SSD-class or better) according
					to Ceph best practices. In Rook, this means that the
						<literal>dataDirHostPath</literal> location in the
						<filename>cluster.yaml</filename> should be backed by SSD or better on MON
					nodes. </para>
			</listitem>
			<listitem>
				<para> Raise the Rook log level to <option>DEBUG</option> for initial deployment and
					for upgrades, as it will help with debugging problems that are more likely to
					occur at those times. </para>
				<para> Ensure that the <literal>ROOK_LOG_LEVEL</literal> in
						<filename>operator.yaml</filename> equals <option>DEBUG</option>. </para>
			</listitem>
			<listitem>
				<para> The Kubernetes CSI driver is the preferred default but ensure that in
						<filename>operator.yaml</filename> the
						<option>ROOK_ENABLE_FLEX_DRIVER</option> remains set to
						<option>false</option>. This is because the FlexVolume driver is in
					sustaining mode, is not getting non-priority bug fixes, and will soon be
					deprecated. </para>
			</listitem>
			<listitem>
				<para> Ceph’s placement group (PG) auto-scaler module makes it unnecessary to
					manually manage PGs. We recommend you always set this to
						<option>enabled</option>, unless you have some need to manage PGs manually.
					In <filename>cluster.yaml</filename>, enable the
						<literal>pg_autoscaler</literal> MGR module. </para>
			</listitem>
			<listitem>
				<para> Rook has the capability to auto-remove Deployments for OSDs which are kicked
					out of a Ceph cluster. This is enabled by:
						<literal>removeOSDsIfOutAndSafeToRemove: true</literal>. This means there is
					less user OSD maintenance and no need to delete Deployments for OSDs that have
					been kicked out. Rook will automatically clean up the cluster by removing OSD
					Pods if the OSDs are no longer holding Ceph data. However, keep in mind that
					this can reduce the visibility of failures from Kubernetes Pod and Pod
					Controller views. You can optionally set
						<literal>removeOSDsIfOutAndSafeToRemove</literal> to <option>false</option>
					if need be, such as if a Kubernetes administrator wants to see disk failures via
					a Pod overview. </para>
			</listitem>
			<listitem>
				<para> Configure Ceph using the central configuration database when possible. This
					allows for more runtime configuration flexibility. Do this using the
						<command>ceph config set</command> commands from Rook's toolbox. Only use
					Rook’s provided <filename>ceph.conf</filename> to override
						<literal>ConfigMap</literal> when it is required. </para>
			</listitem>
		</itemizedlist>

	</sect1>
	<sect1 xml:id="sec-limit-ceph-specifc-nodes">
		<title>Limiting Ceph to Specific Nodes</title>
		<para> One of the more common setups you may want for your Rook-Ceph cluster is to limit
			Ceph to a specific set of nodes. Even for co-located use cases, you could have valid
			reasons why you must not (or do not want to) use some nodes for storage. This is
			applicable for both co-located and disaggregated use cases. To limit Ceph to specific
			nodes, we can Label Kubernetes Nodes and configure Rook to have Affinity (as a hard
			preference). </para>
		<para> Label the desired storage nodes with <literal>storage-node=true</literal>. To run
			Rook and ceph daemons on labeled nodes, we will configure Rook Affinities in both the
			Rook Operator manifest (<filename>operator.yaml</filename>) and the Ceph cluster
			manifest (<filename>cluster.yaml</filename>). </para>
		<para>
			<filename>operator.yaml</filename>
		</para>

		<screen>
CSI_PROVISIONER_NODE_AFFINITY:“storage-node=true”
AGENT_NODE_AFFINITY:“storage-node=true”
DISCOVER_AGENT_NODE_AFFINITY:“storage-node=true”
</screen>

		<para>For Rook daemons and the CSI driver daemons, adjust the Operator manifest. The CSI
			Provisioner is best started on the same nodes as the other Ceph daemons. As above, add
			affinity for all storage nodes in <filename>cluster.yaml</filename>: </para>

		<screen>
placement:
  all:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key:storage-node
                operator:In
                values:
                  -"true"
</screen>

	</sect1>
	<sect1 xml:id="sec-segregate-ceph-user-app">
		<title>Segregating Ceph From User Applications</title>
		<para> You could also have reason to totally separate Rook and Ceph nodes from application
			nodes. This falls under the disaggregated use-case, and it is a more traditional way to
			deploy storage. In this case, we still need to <xref
				linkend="sec-limit-ceph-specifc-nodes"/> as described in the section above, and we
			also need some additional settings. </para>
		<para> To segregate Ceph from user applications, we will also label all non-storage nodes
			with <literal>storage-node=false</literal>. The CSI plugin pods must run where user
			applications run and not where Rook or Ceph pods are run. Add a CSI plugin Affinity for
			all non-storage nodes in the Rook operator configuration. </para>

		<screen>
CSI_PLUGIN_NODE_AFFINITY:"storage-node=false"
</screen>

		<para> In addition to that, we will set Kubernetes Node Taints and configure Rook
			Tolerations. For example, Taint the storage nodes with
				<literal>storage-node=true:NoSchedule</literal> and then add the Tolerations below
			to the Rook operator in <filename>operator.yaml</filename>: </para>

		<screen>
AGENT_TOLERATIONS:|
  - key:storage-node
    operator:Exists
</screen>

		<screen>
DISCOVER_TOLERATIONS:|
  - key:storage-node
    operator:Exists
</screen>

		<screen>
CSI_PROVISIONER_TOLERATIONS:|
  - key:storage-node
    operator:Exists
</screen>

		<para> Also add a Toleration for all Ceph daemon Pods in <filename>cluster.yaml</filename>: </para>

		<screen>
placement:
  all:
    tolerations:
      - key:storage-node
        operator:Exists
</screen>
	</sect1>

	<sect1 xml:id="sec-set-crush-map">
		<title>Setting Ceph CRUSH Map via Kubernetes Node Labels</title>
		<para> A feature that was implemented early in Rook’s development is to set Ceph’s CRUSH map
			via Kubernetes Node labels. For our example data center, we recommend labelling Nodes
			with <option>room</option>, <option>rack</option>, and <option>chassis</option>. </para>
		<para> As a note, Rook will only set a CRUSH map on initial creation for each OSD associated
			with the node. It will not alter the CRUSH map if labels are modified later. Therefore,
			modifying the CRUSH location of an OSD after Rook has created it must be done manually. </para>
		<para> For example, in our hypothetical data center, labeling nodes will look like the
			following: </para>

		<screen>
# -- room-1 --

kubectl label node node-1-1-1 topology.rook.io/room=room-1
kubectl label node node-1-1-1 topology.rook.io/rack=rack-1-1
kubectl label node node-1-1-1 topology.rook.io/chassis=node-1-1-1

kubectl label node node-1-1-2 topology.rook.io/room=room-1
kubectl label node node-1-1-2 topology.rook.io/rack=rack-1-1
kubectl label node node-1-1-2 topology.rook.io/chassis=node-1-1-2

kubectl label node node-1-2-1 topology.rook.io/room=room-1
kubectl label node node-1-2-1 topology.rook.io/rack=rack-1-2
kubectl label node node-1-2-1 topology.rook.io/chassis=node-1-2-1

kubectl label node node-1-2-2 topology.rook.io/room=room-1
kubectl label node node-1-2-2 topology.rook.io/rack=rack-1-2
kubectl label node node-1-2-2 topology.rook.io/chassis=node-1-2-2

# -- room-2 --

kubectl label node node-2-1-1 topology.rook.io/room=room-2
kubectl label node node-2-1-1 topology.rook.io/rack=rack-2-1
kubectl label node node-2-1-1 topology.rook.io/chassis=node-2-1-1

kubectl label node node-2-1-2 topology.rook.io/room=room-2
kubectl label node node-2-1-2 topology.rook.io/rack=rack-2-1
kubectl label node node-2-1-2 topology.rook.io/chassis=node-2-1-2

kubectl label node node-2-2-1 topology.rook.io/room=room-2
kubectl label node node-2-2-1 topology.rook.io/rack=rack-2-2
kubectl label node node-2-2-1 topology.rook.io/chassis=node-2-2-1

kubectl label node node-2-2-2 topology.rook.io/room=room-2
kubectl label node node-2-2-2 topology.rook.io/rack=rack-2-2
kubectl label node node-2-2-2 topology.rook.io/chassis=node-2-2-2

# -- room-f (failure domain) --

kubectl label node node-f-1-1 topology.rook.io/room=room-f
kubectl label node node-f-1-1 topology.rook.io/rack=rack-f-1
kubectl label node node-f-1-1 topology.rook.io/chassis=node-f-1-1
</screen>
	</sect1>

	<sect1 xml:id="sec-planning-nodes-ceph-daemons">
		<title>Planning the Nodes Where Ceph Daemons Will Run</title>
		<sect2 xml:id="ceph-mons">
			<title>Ceph MONS</title>
			<para> Using the hypothetical data center described in the <xref
					linkend="sec-rook-bp-overview"/>, this section will look at planning the nodes
				where Ceph daemons are going to run. </para>
			<para> Ceph MON scheduling is one of the more detailed, and more important, things to
				understand about maintaining a healthy Ceph cluster. The goals we will target in
				this section can be summarized as: <quote>Avoid risky co-location scenarios, but
					allow them if there are no other options, to still have as much redundancy as
					possible.</quote>
			</para>
			<para> This can lead us to the following specific goals: </para>

			<itemizedlist>
				<listitem>
					<para> Allow MONs to be in the same room if a room is unavailable. </para>
				</listitem>
				<listitem>
					<para> Allow MONs to be in the same rack if no other racks in the room are
						available. </para>
				</listitem>
				<listitem>
					<para> Allow MONs to be on the same host only if no other hosts are available. </para>
					<para> We must allow this specifically in the cluster configuration
							<filename>cluster.yaml</filename> by setting
							<option>allowMultiplePerNode: true</option>. </para>
					<important>
						<para> This cannot be set to <option>true</option> for clusters using host
							networking. </para>
					</important>
				</listitem>
			</itemizedlist>

			<tip>
				<title>Topology Labels</title>
				<para> We recommend using the same topology labels used for informing the CRUSH map
					here for convenience. </para>
			</tip>

			<para> Because of our MON SSD availability, in our hypothetical data center, we only
				want monitors to be able to run where shown below in green. We need to plan for
				monitors to fail over, and so we will make two nodes explicitly available for this
				scenario. In our example, we want any node with a MON SSD to be a MON failover
				location in emergencies, for maximum cluster health. This is highlighted in orange
				below. This will give us the most redundancy under failure conditions. </para>

			<figure xml:id="fig-datacenter-mon-failover">
				<title>Example Datacenter - MON Failover</title>
				<mediaobject>
					<imageobject role="fo">
						<imagedata fileref="example-datacenter-mon-failover.png" width="100%"/>
					</imageobject>
					<imageobject role="html">
						<imagedata fileref="example-datacenter-mon-failover.png" width="100%"/>
					</imageobject>
				</mediaobject>
			</figure>

			<para> To implement this in Rook, ensure that Rook will only schedule MONs on nodes with
				MON SSDs. There is a required Affinity for those nodes, which can be accomplished by
				applying a <option>ceph-mon-ssd=true</option> label to nodes with SSDs for Ceph
				MONs. Note that the MON section’s <literal>nodeAffinity</literal> takes precedence
				over the <literal>all</literal> section’s <literal>nodeAffinity</literal>. Make sure
				that you re-specify the rules from the all section to ensure Ceph MONs maintain
				affinity only for storage nodes. </para>

			<screen>
nodeAffinity:​
  requiredDuringSchedulingIgnoredDuringExecution:​
    nodeSelectorTerms:​
      - matchExpressions:​
          - key:role​
            operator:In​
            values:​
              - storage-node  ​
      - matchExpressions:​
          - key:ceph-mon-ssd​
            operator:In​
            values:​
              -"true"
</screen>

			<para> We want to schedule MONs so they are spread across failure domains whenever
				possible. We will accomplish this by applying Anti-affinity between MON pods. Rook
				labels all MON pods <literal>app=rook-ceph-mon</literal>, and that is what will be
				used to spread the monitors apart. There is one rule for rooms, and one for racks if
				a room is down. We want to ensure a higher weight is given to riskier co-location
				scenarios:</para>
			<para> We do not recommend running MONs on the same node unless absolutely necessary.
				Rook automatically applies an Anti-affinity with medium-level weight. However, this
				might not be appropriate for all scenarios. For our scenario, we only want
				node-level co-location in the worst of failure scenarios, so we want to apply the
				highest weight Anti-affinity for nodes.</para>

			<screen>
cluster.yaml:
placement:
  mon:
    # ... nodeAffinity from above ...
    podAntiAffinity:​
      preferredDuringSchedulingIgnoredDuringExecution:​
        - weight:80​
          podAffinityTerm:​
            labelSelector:​
              matchLabels:​
                app:rook-ceph-mon​
            topologyKey:topology.rook.io/room​
        - weight:90​
          podAffinityTerm:​
            labelSelector:​
              matchLabels:​
                app:rook-ceph-mon​
            topologyKey:topology.rook.io/rack​
        - weight: 100​
          podAffinityTerm:​
            labelSelector:​
              matchLabels:​
                app: rook-ceph-mon​
            topologyKey: kubernetes.io/hostname​
</screen>

			<note>
				<para> If <literal>hostNetworking</literal> is enabled, you cannot co-locate MONs,
					because the ports will collide on nodes. To enforce this, if host networking is
					enabled, Rook will automatically set a
						<literal>requiredDuringSchedulingIgnoredDuringExecution</literal> Pod
					Anti-affinity rule. </para>
			</note>
		</sect2>
		<sect2 xml:id="sec-ceph-osds">
			<title>Ceph OSDS</title>
			<para> There is a lot of planning that goes into the placement of monitors, and this is
				also true for OSDs. Fortunately, because the planning is already done with the
				monitors and because we have discussed the methods, it is quite a bit easier to plan
				for the OSDs. </para>

			<figure xml:id="fig-datacenter-osd-placement">
				<title>Example Datacenter - OSD Placement</title>
				<mediaobject>
					<imageobject role="fo">
						<imagedata fileref="example-datacenter-osd-placement.png" width="100%"/>
					</imageobject>
					<imageobject role="html">
						<imagedata fileref="example-datacenter-osd-placement.png" width="100%"/>
					</imageobject>
				</mediaobject>
			</figure>

			<para> There are two ways to select nodes to use for OSDs: </para>

			<itemizedlist>
				<listitem>
					<para> Apply Kubernetes Node labels and tell Rook to look for those labels.
						Specify in the <filename>cluster.yaml</filename>
						<filename>storage:useAllNodes true</filename> and specify
							<literal>osd</literal>
						<literal>nodeAffinity</literal> using <literal>ceph-osd=true</literal> label
						using the same Affinity methods we used for MONs. </para>
				</listitem>
				<listitem>
					<para> Specify node names in the <literal>CephCluster</literal> definition
							(<filename>cluster.yaml</filename>) individually in
							<literal>storage:nodes</literal>. </para>
				</listitem>
			</itemizedlist>

			<para> Choosing which option to use depends on your desired management strategy. There
				is no single strategy we would recommend over any other. </para>
		</sect2>

		<sect2 xml:id="sec-other-ceph-daemons">
			<title>Other Ceph Daemons</title>
			<para> Placing the other Ceph daemons follows the same logic and methods as MONs and
				OSDs: MGR, MDS, RGW, NFS-Ganesha, and RBD mirroring daemons can all be placed as
				desired. For more information, see <link
					xlink:href="https://rook.io/docs/rook/v1.3/ceph-cluster-crd.html#placement-configuration-settings"
				/>
			</para>
		</sect2>

	</sect1>
	<sect1 xml:id="sec-hardware-resource-req">
		<title>Hardware Resource Requirements and Requests</title>
		<para> Kubernetes can watch the system resources available on nodes and can help schedule
			applications—such as the Ceph daemons—automatically. Kubernetes uses Resource Requests
			to do this. For Rook, we are notably concerned about Kubernetes' scheduling of Ceph
			daemons. </para>
		<para> Kubernetes has two Resource Request types: <emphasis>Requests</emphasis> and
				<emphasis>Limits</emphasis>. <emphasis>Requests</emphasis> govern scheduling, and
				<emphasis>Limits</emphasis> instruct Kubernetes to kill and restart application Pods
			when they are over-consuming given <emphasis>Limits</emphasis>. </para>
		<para> When there are Ceph hardware requirements, treat those requirements as
				<emphasis>Requests</emphasis>, not <emphasis>Limits</emphasis>. This is because all
			Ceph daemons are critical for storage, and it is best to never set Resource
				<emphasis>Limits</emphasis> for Ceph Pods. If Ceph Daemons are over-consuming
				<emphasis>Requests</emphasis>, there is likely a failure scenario happening. In a
			failure scenario, killing a daemon beyond a <emphasis>Limit</emphasis> is likely to make
			an already bad situation worse. This could create a “thundering herds” situation where
			failures synchronize and magnify. </para>
		<para> Generally, storage is given minimum resource guarantees, and other applications
			should be limited so as not to interfere. This guideline already applies to bare-metal
			storage deployments, not only for Kubernetes. </para>
		<para> As you read on, it is important to note that all recommendations can be affected by
			how Ceph daemons are configured. For example, any configuration regarding caching. Keep
			in mind that individual configurations are out of scope for this document. </para>

		<sect2 xml:id="sec-resource-req-mon-mgr">
			<title>Resource Requests - MON/MGR</title>
			<para> Resource Requests for MONs and MGRs are straightforward. MONs try to keep memory
				usage to around 1 GB — however, that can expand under failure scenarios. We
				recommend 4 GB RAM and 4 CPU cores. </para>
			<para> Recommendations for MGR nodes are harder to make, since enabling more modules
				means higher usage. We recommend starting with 2 GB RAM and 2 CPU cores for MGRs. It
				is a good idea to look at the actual usage for deployments and do not forget to
				consider usage during failure scenarios. </para>
			<para> MONs: </para>

			<itemizedlist>
				<listitem>
					<para>
						<emphasis>Request</emphasis> 4 CPU cores </para>
				</listitem>
				<listitem>
					<para>
						<emphasis>Request</emphasis> 4GB RAM (2.5GB minimum) </para>
				</listitem>
			</itemizedlist>
			<para> MGR: </para>
			<itemizedlist>
				<listitem>
					<para> Memory will grow the more MGR modules are enabled </para>
				</listitem>
				<listitem>
					<para>
						<emphasis>Request</emphasis> 2 GB RAM and 2 CPU cores </para>
				</listitem>
			</itemizedlist>

		</sect2>
		<sect2 xml:id="sec-resource-req-osd-cpu">
			<title>Resource Requests - OSD CPU</title>
			<para> Recommendations and calculations for OSD CPU are straightforward.</para>
			<para> Hardware recommendations: </para>

			<itemizedlist>
				<listitem>
					<para> 1 x 2GHz CPU Thread per spinner </para>
				</listitem>
				<listitem>
					<para> 2 x GHz CPU Thread per SSD </para>
				</listitem>
				<listitem>
					<para> 4 x GHz CPU Thread per NVMe </para>
				</listitem>
			</itemizedlist>
			<para> Examples: </para>
			<itemizedlist>
				<listitem>
					<para> 8 HDDS journaled to SSD – 10 cores / 8 OSDs = 1.25 cores per OSD </para>
				</listitem>
				<listitem>
					<para> 6 SSDs without journals – 12 cores / 6 OSDs = 2 cores per OSD </para>
				</listitem>
				<listitem>
					<para> 8 SSDs journaled to NVMe – 20 cores / 8 OSDs = 2.5 cores per OSD </para>
				</listitem>
			</itemizedlist>

			<para> Note that resources are applied cluster-wide to all OSDs. If a cluster contains
				multiple OSD types, you must use the highest Requests for the whole cluster. For the
				examples below, a mixture of HDDs journaled to SSD and SSDs without journals would
				necessitate a <emphasis>Request</emphasis> for 2 cores.</para>

		</sect2>
		<sect2 xml:id="sec-resource-req-osd-ram">
			<title>Resource Requests - OSD RAM</title>
			<para> There are node hardware recommendations for OSD RAM usage, and this needs to be
				translated to RAM requests on a per-OSD basis. The node-level recommendation below
				describes <literal>osd_memory_target</literal>. This is a Ceph configuration that is
				described in detail further on. </para>
			<screen>
Total RAM required = [number of OSDs] x (1 GB + osd_memory_target) + 16 GB
</screen>

			<para> Ceph OSDs will attempt to keep heap memory usage under a designated target size
				set via the <literal>osd_memory_target</literal> configuration option. Ceph’s
				default <literal>osd_memory_target</literal> is 4GB, and we do not recommend
				decreasing the <literal>osd_memory_target</literal> below 4GB. You may wish to
				increase this value to improve overall Ceph read performance by allowing the OSDs to
				use more RAM. While the total amount of heap memory mapped by the process should
				stay close to this target, there is no guarantee that the kernel will actually
				reclaim memory that has been unmapped. </para>
			<para> For example, a node hosting 8 OSDs, memory <emphasis>Requests</emphasis> would be
				calculated as such: </para>
			<screen>
8 OSDs x (1GB + 4GB) + 16GB = 56GB per node
</screen>
			<para> Allowing resource usage for each OSD: </para>
			<screen>
56GB / 8 OSDs = 7GB
</screen>
			<para> Ceph has a feature that allows it to set <literal>osd_memory_target</literal>
				automatically when a Rook OSD Resource Request is set. However, Ceph sets this value
					<literal>1:1</literal> and does not leave overhead for waiting for the kernel to
				free memory. Therefore, we recommend setting <literal>osd_memory_target</literal> in
				Ceph explicitly, even if you wish to use the default value. Set Rook’s OSD resource
				requests accordingly and to a higher value than <literal>osd_memory_target</literal>
				by at least an additional 1GB. This is so Kubernetes does not schedule more
				applications or Ceph daemons onto a node than the node is likely to have RAM
				available for. </para>
			<para> OSD RAM <emphasis>Resource Requests</emphasis> come with the same cluster-wide
					<emphasis>Resource Requests</emphasis> note as for OSD CPU. Use the highest
					<emphasis>Requests</emphasis> for a cluster consisting of multiple different
				configurations of OSDs. </para>
		</sect2>
		<sect2 xml:id="sec-resource-req-gateways">
			<title>Resource Requests - Gateways</title>
			<para> For gateways, the best recommendation is to always tune your workload and daemon
				configurations. However, we do recommend the following initial configurations: </para>
			<para> RGWs: </para>

			<itemizedlist>
				<listitem>
					<para> 6-8 CPU cores </para>
				</listitem>
				<listitem>
					<para> 64 GB RAM (32 GB minimum – may only apply to older "civetweb" protocol)
					</para>
				</listitem>
			</itemizedlist>

			<note>
				<para> The numbers below for RGW assume a lot of clients connecting. Thus they might
					not be the best for your scenario. The RAM usage should be lower for the newer
					“beast” protocol as opposed to the older “civetweb” protocol. </para>

			</note>

			<para> MDS: </para>

			<itemizedlist>
				<listitem>
					<para> 2.5 GHz CPU with a least 2 cores </para>
				</listitem>
				<listitem>
					<para> 3GB RAM </para>
				</listitem>
			</itemizedlist>

			<para> NFS-Ganesha: </para>

			<itemizedlist>
				<listitem>
					<para> 6-8 CPU cores (untested, high estimate) </para>
				</listitem>
				<listitem>
					<para> 4GB RAM for default settings (settings hardcoded in Rook presently)
					</para>
				</listitem>
			</itemizedlist>
		</sect2>

	</sect1>
	<sect1 xml:id="sec-basic-performance-enhancements">
		<title>Basic Performance Enhancements</title>
		<para> The following are some basic performance enhancements. These are a few easy,
			low-hanging-fruit recommendations. </para>

		<note>
			<para> Not all of these will be right for all clusters or workloads. Always performance
				test and use your best judgment. </para>
		</note>

		<itemizedlist>
			<listitem>
				<para> You can gain performance by using a CNI plugin with an accelerated network
					stack. For example, Cilium uses eBPF to improve performance over some other CNI
					plugins. </para>
			</listitem>
			<listitem>
				<para> Enable host networking to improve network performance. Notably, this provides
					lower, more stable latency. This does, however, step outside of Kubernetes’
					network security domain. In <filename>cluster.yaml</filename> set
						<literal>network:provider:host</literal>. </para>
			</listitem>
			<listitem>
				<para> Use jumbo frames for your networking. This can be applied to both host
					networking and the CNI plugin. </para>
			</listitem>
			<listitem>
				<para> For performance-sensitive deployments, ensure Ceph OSDs always get the
					performance they need by not allowing other Ceph daemons or user applications to
					run on OSD nodes. Co-locating MONs and MGRs with OSDs can still be done fairly
					safely as long as there are enough hardware resources to also include monitors
					and managers. </para>
			</listitem>
		</itemizedlist>
	</sect1>

	<?pdfpagebreak style="sbp" formatter="fop"?>
	
	<xi:include href="sbp-legal-notice.xml"/>

	<?pdfpagebreak style="sbp" formatter="fop"?>

	<xi:include href="license-gfdl.xml"/>
</article>
