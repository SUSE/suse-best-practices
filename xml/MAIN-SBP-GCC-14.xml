<?xml version="1.0" encoding="UTF-8"?>
<!--<?oxygen RNGSchema="http://www.oasis-open.org/docbook/xml/5.0/rng/docbook.rng" type="xml"?>-->
<!DOCTYPE article [
<!ENTITY % entity SYSTEM "entity-decl.ent">
%entity;
]>

<!-- I use special character &#8288; to avoid line brakes after the leading hyphen of compiler
     options (such as -O2 or -ffast-math).  It looks horrible in the document source but fixes
     the issue, at least in the pdf output. -->


<article role="sbp" xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude"
 xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0" xmlns:its="http://www.w3.org/2005/11/its"
 xml:id="art-sbp-gcc14-sle15" xml:lang="en">

 <info>
   <title>Advanced Optimization and New Capabilities of GCC 14</title>

  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:bugtracker>
    <dm:url>https://github.com/SUSE/suse-best-practices/issues/new</dm:url>
    <dm:product>Advanced Optimization and New Capabilities of GCC 14</dm:product>
   </dm:bugtracker>
   <dm:editurl>https://github.com/SUSE/suse-best-practices/blob/master/xml/</dm:editurl>
  </dm:docmanager>

  <meta name="series" its:translate="no">Best Practices</meta>
  <meta name="category" its:translate="no">
   <phrase>Development Tools</phrase>
  </meta>
  <meta name="task" its:translate="no">
   <phrase>Configuration</phrase>
  </meta>
  <meta name="title" its:translate="yes">Advanced Optimization and New Capabilities of GCC 14</meta>
  <meta name="description" its:translate="yes">Overview of GCC 14 and compilation optimization options for
  applications</meta>
  <meta name="social-descr" its:translate="yes">Advanced optimization and new capabilities of GCC 14</meta>
  <meta name="productname" its:translate="no">
   <productname version="15 SP6">SUSE Linux Enterprise Server</productname>
  </meta>

  <meta name="platform" its:translate="no">SUSE Linux Enterprise Server 15 SP6 and later</meta>
  <meta name="platform" its:translate="no">Development Tools Module</meta>

  <authorgroup>
   <author>
    <personname>
     <firstname>Martin</firstname>
     <surname>Jambor</surname>
    </personname>
    <affiliation>
     <jobtitle>Toolchain Team Lead</jobtitle>
     <orgname>SUSE</orgname>
    </affiliation>
   </author>

   <author>
    <personname>
     <firstname>Jan</firstname>
     <surname>Hubička</surname>
    </personname>
    <affiliation>
     <jobtitle>Toolchain Developer</jobtitle>
     <orgname>SUSE</orgname>
    </affiliation>
   </author>

   <author>
    <personname>
     <firstname>Richard</firstname>
     <surname>Biener</surname>
    </personname>
    <affiliation>
     <jobtitle>Toolchain Developer</jobtitle>
     <orgname>SUSE</orgname>
    </affiliation>
   </author>

   <author>
    <personname>
     <firstname>Michael</firstname>
     <surname>Matz</surname>
    </personname>
    <affiliation>
     <jobtitle>Toolchain Developer</jobtitle>
     <orgname>SUSE</orgname>
    </affiliation>
   </author>

   <author>
    <personname>
     <firstname>Venkataramanan</firstname>
     <surname>Kumar</surname>
    </personname>
    <affiliation>
     <jobtitle>PMTS Software System Design Eng</jobtitle>
     <orgname>AMD</orgname>
    </affiliation>
   </author>

   <author>
    <personname>
     <firstname>Kim</firstname>
     <surname>Naru</surname>
    </personname>
    <affiliation>
     <jobtitle>Engineering Manager</jobtitle>
     <orgname>AMD</orgname>
    </affiliation>
   </author>

   <!--   <editor>
   <orgname></orgname>
   </editor>
   <othercredit>
   <orgname></orgname>
   </othercredit>-->
  </authorgroup>

  <cover role="logos">
   <mediaobject>
    <imageobject role="fo">
     <imagedata fileref="suse.svg" width="5em" align="center" valign="bottom"/>
    </imageobject>
    <imageobject role="html">
     <imagedata fileref="suse.svg" width="152px" align="center" valign="bottom"/>
    </imageobject>
    <textobject><phrase>SUSE logo</phrase></textobject>
   </mediaobject>
  </cover>

  <revhistory xml:id="rh-art-sbp-gcc14-sle15">
   <revision>
    <date>2025-02-17</date>
    <revdescription>
     <para> </para>
    </revdescription>
   </revision>
  </revhistory>


  <abstract>
   <para> The document at hand provides an overview of GCC 14.2 as the current Development Tools
    Module compiler in SUSE Linux Enterprise 15 SP6. It focuses on the important optimization levels
    and options <emphasis role="strong">Link Time Optimization (LTO)</emphasis> and <emphasis
     role="strong">Profile Guided Optimization (PGO)</emphasis>. Their effects are demonstrated by
    compiling the SPEC CPU benchmark suite for AMD EPYC 9005 Series Processors.</para>

   <!-- If we manage to revive FF analysis put the following back: ...and building Mozilla Firefox
         for a generic <literal>x86_64</literal> machine. -->

   <para>
    <emphasis role="strong">Disclaimer: </emphasis> Documents published as part of the SUSE Best
    Practices series have been contributed voluntarily by SUSE employees and third parties. They are
    meant to serve as examples of how particular actions can be performed. They have been compiled
    with utmost attention to detail. However, this does not guarantee complete accuracy. SUSE cannot
    verify that actions described in these documents do what is claimed or whether actions described
    have unintended consequences. SUSE LLC, its affiliates, the authors, and the translators may not
    be held liable for possible errors or the consequences thereof. </para>

   
  </abstract>
 </info>

 <sect1 xml:id="sec-gcc14-overview">
  <title>Overview</title>

  <para> The first release of the GNU Compiler Collection (GCC) with the major version 14, GCC 14.1,
  took place in May 2024.  GCC 14.2, with fixes to over 100 bugs, was released in August of the same
  year. Soon after, the openSUSE Tumbleweed Linux distribution began using this compiler to build its packages.
  Subsequently, it has replaced the compiler in the SUSE Linux Enterprise (SLE)
  Development Tools Module.  GCC 14 is the first major version to support the new capabilities of a wide range 
  of computer architectures, including AMD CPUs based on the Zen 5 core. 
  It also introduces many new features. These include the implementation of parts of the most recent versions of 
  various language specifications (particularly <literal>C23</literal>, <literal>C++23</literal>, and 
   <literal>C++26</literal>), along with their extensions (such as OpenMP and OpenACC). 
   Additionally, there are numerous generic improvements in optimization.</para>

  <para> This document gives an overview of GCC 14. It focuses on selecting appropriate optimization
  options for your application and stresses the benefits of advanced modes of compilation. First, we
  describe the optimization levels the compiler offers, and other important options developers often
  use. We explain when and how you can benefit from using <emphasis role="bold">Link Time
  Optimization (LTO)</emphasis> and <emphasis role="bold">Profile Guided Optimization
  (PGO)</emphasis> builds. We also detail their effects when building a set of well-known CPU
  intensive benchmarks. Finally, we look at how these perform on AMD Zen 5 based AMD EPYC 9005
  Series Processors. </para>
  <!-- If we manage to revive FF analysis put the following back: Finally, we take a closer look at
       the effects they have on a big software project: Mozilla Firefox. -->
 </sect1>

 <!-- The important box below (and other elements) just look bad in pdf without this.  -->
 <?pdfpagebreak style="sbp" formatter="fop"?>

 <sect1 xml:id="sec-gcc14-system-compiler-vs-module-compiler">
  <title>System compiler versus Development Tools Module compiler</title>

  <para> The major version of the system compiler in SUSE Linux Enterprise 15 remains to be GCC 7,
   regardless of the service pack level. This is to minimize the danger of any unintended changes
   over the entire life time of the product. </para>

  <screen>sles15: # gcc --version
gcc (SUSE Linux) 7.5.0
Copyright (C) 2017 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
</screen>

  <para> That does not mean that, as a user of SUSE Linux Enterprise 15, you are forced to use a
   compiler with features frozen in 2016. You can install an add-on module called <emphasis
    role="strong">Development Tools Module</emphasis> which is included in the SUSE Linux
   Enterprise Server 15 subscription and contains a much newer compiler. </para>

  <para> At the time of writing this document, the compiler included in the Development Tools Module
   is GCC 14.2. It is important to note, however, that unlike the system compiler, the major version of the 
   latest GCC from the module will change a few months after the upstream release of GCC 15.2 
   (scheduled for summer 2025), followed by GCC 16.2 (summer 2026), and so on. Note
   that only the most recent compiler in the Development Tools Module is supported at any time,
   with the exception of a six-month overlap period following an upgrade. Developers on a SUSE Linux
   Enterprise Server 15 system therefore have always access to two supported GCC versions: the
   almost unchanging system compiler and the most recent compiler from the Development Tools Module. </para>

  <para> Programs and libraries built with the compiler from the Development Tools Module can run on
   computers running SUSE Linux Enterprise Server 15 which do not have the module installed. All
   necessary runtime libraries are available from the main repositories of the operating system
   itself, and new ones are added through the standard update mechanism. In this document, we use the 
   term GCC 14 to refer to any minor version within the major version 14, while GCC 14.2 specifically 
   refers to that particular version. In practice they should be interchangeable. </para>

  <sect2 xml:id="sec-gcc14-when-module-compiler">
   <title>When to use compilers from the Development Tools Module</title>

   <para> Often you will find that the system compiler perfectly satisfies your needs. After all, it
    is the compiler used to build the vast majority of packages and their updates in the system
    itself. On the other hand, there are situations where a newer compiler is necessary, or where
    you want to consider using a newer compiler to get some benefits of its ongoing development. </para>

   <para> If the program or library you are building uses language features which are not supported
    by GCC 7, you cannot use the system compiler. However, the compiler from the Development Tools
    Module will usually be sufficiently new. The most obvious case is <literal>C++</literal>. GCC 14
    has a mature implementation of <literal>C++17</literal> features, whereas the one in GCC 7 is
    only experimental and incomplete. The <literal>GNU C++ Library</literal> which accompanies GCC
    14 is also <literal>C++17</literal> feature-complete.</para>

   <important>
    <title>Code using <literal>C++17</literal> features</title>
    <para> Code using <literal>C++17</literal> features should always be compiled with the compiler
     from the Development Tools Module. Linking two objects, such as an application and a shared library, 
     both using <literal>C++17</literal>—where one is built with <literal>g++ 8</literal> or earlier 
     and the other with <literal>g++ 9 or later</literal>—is especially risky. This is because <literal>C++</literal> 
     STL objects instantiated by the experimental code may provide implementation and even ABI that 
     is different from what the mature implementation expects and vice versa. Issues caused by such 
     a mismatch are difficult to predict and may include silent data corruption. </para>
   </important>

   <para> Most of <literal>C++20</literal> features are implemented in GCC 14 as experimental
    features. Try them out with appropriate caution and avoid linking together code that uses them
    and is produced by different compilers. <emphasis role="italic">Modules</emphasis> are only
    partially implemented <footnote>
     <para> Proposals P1766R1 and P1815R2</para>
    </footnote> and require that the source file is compiled with
     <literal>-&#8288;fmodules-ts</literal> option. Similarly, <emphasis role="italic"
     >coroutines</emphasis>
    <footnote>
     <para> Proposal P0912R5</para>
    </footnote>
    are also implemented but require that the source file is compiled with the
    <literal>-&#8288;fcoroutines</literal> switch. GCC 14 also experimentally implements many
    <literal>C++23</literal> and some <literal>C++26</literal> features. If you are interested in
    the implementation status of any particular <literal>C++</literal> feature in the compiler or
    the standard library, consult the following pages: </para>

   <itemizedlist>
    <listitem>
     <para>
      <link xlink:href="https://gcc.gnu.org/projects/cxx-status.html"><literal>C++</literal>
       Standards Support in GCC</link>, and </para>
    </listitem>
    <listitem>
     <para>
      <link xlink:href="https://gcc.gnu.org/onlinedocs/gcc-14.2.0/libstdc++/manual">The GNU
        <literal>C++</literal> Library Manual</link>. </para>
    </listitem>
   </itemizedlist>

   <para> Advances in supporting new language specifications are not limited to
     <literal>C++</literal>. GCC 14 experimentally supports most of the new features from the ISO
     <literal>C23</literal> standard, and the Fortran compiler is also continuously improved.
    And if you use <literal>OpenMP</literal> or <literal>OpenACC</literal> extensions for parallel
    programming, you will find that the compiler supports a lot of features of new versions of these
    standards. For more details, visit the links at the end of this section. </para>

   <para> In addition to new supported language constructs, GCC 14 offers improved diagnostics when
    it reports errors and warnings to the user so that they are easier to understand and to be acted
    upon. This is particularly useful when dealing with issues in templated <literal>C++
     code</literal>. Furthermore, there are several new warnings which help to avoid common
    programming mistakes. </para>

   <para> Because GCC 14 is newer, it can generate code for many recent processors not supported by
   GCC 7. Such a list of processors would be too large to be enumerated here. Nevertheless, in <xref
   linkend="sec-gcc14-spec"/> we specifically look at optimizing code for AMD EPYC 9005 Series
   Processors which are based on AMD Zen 5 cores. The <emphasis role="italic">system
   compiler</emphasis> does not know this kind of core and therefore cannot optimize for it. On the
   other hand, GCC 14.2 can both detect and optimize for Zen 5.</para>

   <para> Finally, the general optimization pipeline of the compiler has also significantly improved
    over the years. To find out more about improvements in versions of GCC 8 through 14, visit their
    respective <quote>changes</quote> pages: </para>

   <itemizedlist>
    <listitem>
     <para>
      <link xlink:href="https://gcc.gnu.org/gcc-8/changes.html">GCC 8 Release Series Changes, New
       Features, and Fixes</link>, </para>
    </listitem>
    <listitem>
     <para>
      <link xlink:href="https://gcc.gnu.org/gcc-9/changes.html">GCC 9 Release Series Changes, New
       Features, and Fixes</link>, </para>
    </listitem>
    <listitem>
     <para>
      <link xlink:href="https://gcc.gnu.org/gcc-10/changes.html">GCC 10 Release Series Changes, New
       Features, and Fixes</link>, </para>
    </listitem>
    <listitem>
     <para>
      <link xlink:href="https://gcc.gnu.org/gcc-11/changes.html">GCC 11 Release Series Changes, New
       Features, and Fixes</link>, </para>
    </listitem>
    <listitem>
     <para>
      <link xlink:href="https://gcc.gnu.org/gcc-12/changes.html">GCC 12 Release Series Changes, New
       Features, and Fixes</link>, </para>
    </listitem>
    <listitem>
     <para>
      <link xlink:href="https://gcc.gnu.org/gcc-13/changes.html">GCC 13 Release Series Changes, New
       Features, and Fixes</link>, and </para>
    </listitem>
    <listitem>
     <para>
      <link xlink:href="https://gcc.gnu.org/gcc-14/changes.html">GCC 14 Release Series Changes, New
       Features, and Fixes</link>. </para>
    </listitem>
   </itemizedlist>
  </sect2>

  <sect2 xml:id="sec-gcc11-issues-with-module-compiler">
   <title>Potential issues with the Development Tools Module Compiler</title>

   <para> GCC 14 from the Development Tools Module can sometimes behave differently in a way that
    can cause issues which were not present with the system compiler. Such problems encountered by
    other users are listed in the following documents: </para>

   <itemizedlist>
    <listitem>
     <para>
      <link xlink:href="https://gcc.gnu.org/gcc-8/porting_to.html">Porting to GCC 8</link>, </para>
    </listitem>
    <listitem>
     <para>
      <link xlink:href="https://gcc.gnu.org/gcc-9/porting_to.html">Porting to GCC 9</link>,
     </para>
    </listitem>
    <listitem>
     <para>
      <link xlink:href="https://gcc.gnu.org/gcc-10/porting_to.html">Porting to GCC 10</link>,
     </para>
    </listitem>
    <listitem>
     <para>
      <link xlink:href="https://gcc.gnu.org/gcc-11/porting_to.html">Porting to GCC 11</link>,
     </para>
    </listitem>
    <listitem>
     <para>
      <link xlink:href="https://gcc.gnu.org/gcc-12/porting_to.html">Porting to GCC 12</link>,
     </para>
    </listitem>
    <listitem>
     <para>
      <link xlink:href="https://gcc.gnu.org/gcc-13/porting_to.html">Porting to GCC 13</link>, and
     </para>
    </listitem>
    <listitem>
     <para>
      <link xlink:href="https://gcc.gnu.org/gcc-14/porting_to.html">Porting to GCC 14</link>.
     </para>
    </listitem>
   </itemizedlist>

   <para> To get an understanding of the problems, read through these pages, all but the last one
   are fairly short. The document at hand briefly mentions a few most common potential
   pitfalls.</para>

   <para>
     Starting with GCC 14, the <literal>C</literal> compiler treats some situations which were never
     allowed since the 1999 revision ISO <literal>C</literal> as errors.  In GCC 13 and before, the
     compiler only generated warnings for them:
   </para>
   <itemizedlist>
     <listitem>
       <para> Implicit int types (<literal>-Werror=implicit-int</literal>)
       </para>
     </listitem>
     <listitem>
       <para> Implicit function declarations (<literal>-&#8288;Werror=implicit-function-declaration</literal>),
       </para>
     </listitem>
     <listitem>
       <para> Wrong or misspelled function prototypes (<literal>-&#8288;Werror=declaration-missing-parameter-type</literal>),
       </para>
     </listitem>
     <listitem>
       <para> Incorrect uses of the return statement (<literal>-&#8288;Werror=return-mismatch</literal>),
       </para>
     </listitem>
     <listitem>
       <para> Using pointers as integers and vice versa (<literal>-&#8288;Werror=int-conversion</literal>), and
       </para>
     </listitem>
     <listitem>
       <para> Type mismatches of pointer types (<literal>-&#8288;Werror=incompatible-pointer-types</literal>)
       </para>
     </listitem>
   </itemizedlist>

   <para>
     We strongly recommend that you take the time to fix any of the above problems if you encounter
     them in your code.  They have been a frequent source of bugs, portability and even security
     issues.  More information about all of these cases together with the most common ways of
     addressing them are given in the <quote>Porting to GCC 14</quote>
    document referenced above. If the code is written in a version of <literal>C</literal> before 
    the 1999 ISO standard, you can tell the compiler by using the <literal>-std=gnu89</literal> 
    or <literal>-std=c89</literal> option, which will again allow those constructs.
    If your code uses features of this standard or a later one and for some reason it is not
     possible to fix it, you can either turn a specific class of the new errors back to warnings
     with a corresponding <literal>-&#8288;Wno-error=</literal> option or use a new compiler switch
     <literal>-&#8288;fpermissive</literal> to do so for all of the above.
   </para>

   <note>
    <title>Impact on build environment probing</title>
    <para> Many code snippets (also called <emphasis role="italic">probes</emphasis>) generated by
    <literal>autoconf</literal> to discover the availability of various features work in the way
    that they trigger a compile error when a feature is missing. The new errors may cause
    compilation to fail when it worked before and thus lead to features being silently disabled even
    when they are actually available. <literal>autoconf</literal> has supported C99 compilers since version 2.69 in
    its generic, core probes. However, earlier versions or very specific probes might rely on C features
    that were removed in C99 and thus fail with GCC 14. In cases where this is a concern, you can
    compare the generated <filename>config.log</filename>, <filename>config.h</filename> 
    and other generated files using <command>diff</command> to ensure there are no unexpected differences.
    </para>
   </note>

   <para>The second common pitfall is that GCC 10 and later default to <literal>-&#8288;fno-common</literal> 
    for performance reasons. This means a linker error will now be reported
    if the same variable is defined in two <literal>C</literal> compilation units. This can happen
    if two or more <filename>.c</filename> files include the same header file which intends to declare
    a variable but omits the <literal>extern</literal> keyword when doing so, inadvertently
    resulting in multiple definitions. If you encounter such an error, you need to add the
     <literal>extern</literal> keyword to the declaration in the header file and define the variable
    in only a single compilation unit. Alternatively, you can compile your project with an explicit
     <literal>-&#8288;fcommon</literal> if you are willing to accept that this behavior is
    inconsistent with <literal>C++</literal> and may incur speed and code size penalties. </para>

   <para> Users compiling <literal>C++</literal> sources should also be aware that
     <literal>g++</literal> version 11 and later default to <literal>-std=gnu++17</literal>, the
     <literal>C++17</literal> standard with GNU extensions, instead of <literal>
     -std=gnu++14</literal>. Moreover, some <literal>C++</literal> Standard Library headers have
    been changed to no longer include other headers that they do not depend on. You may need to
    explicitly include <literal>&lt;limits&gt;</literal>,
     <literal>&lt;memory&gt;</literal>, <literal>&lt;utility&gt;</literal> or
     <literal>&lt;thread&gt;</literal>.</para>

   <para> The final issue emphasized here is that the <literal>C++</literal> compiler in GCC 8 and
    later now assumes that no execution path in a non-void function reaches the end of the
    function without a return statement. This means it is assumed that such code paths will never be
    executed, and thus they will be eliminated. You should therefore pay special attention to
    warnings produced by <literal>-Wreturn-type</literal>. This option is enabled by default and
    indicates which functions are affected. </para>
  </sect2>

  <sect2 xml:id="sec-gcc14-installing-module-compiler">
   <title>Installing GCC 14 from the Development Tools Module</title>

   <para> Similar to other modules and extensions for SUSE Linux Enterprise Server 15, you can
    activate the Development Tools Module using either the command line tool
     <command>SUSEConnect</command> or the <command>YaST</command> setup and configuration tool. To
    use the former, carry out the following steps: </para>

   <procedure>
    <step>
     <para> As root, start by listing the available and activated modules and extensions: </para>
     <screen>sles15: # SUSEConnect --list-extensions</screen>
    </step>
    <step>
     <para> In the computer output, look for <quote>Development Tools Module</quote>: </para>
     <screen>
            Development Tools Module 15 SP6 x86_64
            Activate with: suseconnect -p sle-module-development-tools/15.6/x86_64
          </screen>
     <para> If you see the text <literal>(Activated)</literal> next to the module name, the module
      is already ready to be used. You can safely proceed to the installation of the compiler
      packages. </para>
    </step>
    <step>
     <para> Otherwise, issue the activation command that is shown in the command output above: </para>

     <screen>sles15: # suseconnect -p sle-module-development-tools/15.6/x86_64
Registering system to SUSE Customer Center

Updating system details on https://scc.suse.com ...

Activating sle-module-development-tools 15.6 x86_64 ...
-> Adding service to system ...
-> Installing release package ...

Successfully registered system
     </screen>
    </step>
   </procedure>

   <para> If you prefer to use <command>YaST</command>, the procedure is also straightforward. Run
    YaST as root and go to the <emphasis role="strong">Add-On Products</emphasis> menu in the
     <emphasis role="strong">Software</emphasis> section. If <quote>Development Tools Module</quote>
    is among the listed installed modules, you already have the module activated and can proceed
    with installing individual compiler packages. If not, click the <emphasis role="strong"
     >Add</emphasis> button, select <emphasis role="strong">Select Extensions and Modules from
     Registration Server</emphasis>, and <command>YaST</command> will guide you through a simple
    procedure to add the module. </para>


   <para> When you have the Development Tools Module installed, you can verify that the GCC 14
    packages are available to be installed on your system:. </para>

   <screen>sles15: # zypper search gcc14
Refreshing service 'Basesystem_Module_15_SP6_x86_64'.
Refreshing service 'Certifications_Module_15_SP6_x86_64'.
Refreshing service 'Containers_Module_15_SP6_x86_64'.
Refreshing service 'Desktop_Applications_Module_15_SP6_x86_64'.
Refreshing service 'Development_Tools_Module_15_SP6_x86_64'.
Refreshing service 'Python_3_Module_15_SP6_x86_64'.
Refreshing service 'SUSE_Linux_Enterprise_Server_15_SP6_x86_64'.
Refreshing service 'SUSE_Package_Hub_15_SP6_x86_64'.
Refreshing service 'Web_and_Scripting_Module_15_SP6_x86_64'.
Loading repository data...
Reading installed packages...

S  | Name                     | Summary
---+--------------------------+----------------------------------------------------------
   | gcc14                    | The GNU C Compiler and Support Files
   | gcc14                    | The GNU C Compiler and Support Files
   | gcc14-32bit              | The GNU C Compiler 32bit support
   | gcc14-ada                | GNU Ada Compiler Based on GCC (GNAT)
   | gcc14-ada-32bit          | GNU Ada Compiler Based on GCC (GNAT)
   | gcc14-c++                | The GNU C++ Compiler
   | gcc14-c++-32bit          | The GNU C++ Compiler
   | gcc14-d                  | GNU D Compiler
   | gcc14-d-32bit            | GNU D Compiler
   | gcc14-fortran            | The GNU Fortran Compiler and Support Files
   | gcc14-fortran-32bit      | The GNU Fortran Compiler and Support Files
   | gcc14-go                 | GNU Go Compiler
   | gcc14-go-32bit           | GNU Go Compiler
   | gcc14-info               | Documentation for the GNU compiler collection
   | gcc14-locale             | Locale Data for the GNU Compiler Collection
   | gcc14-m2                 | GNU Modula-2 Compiler
   | gcc14-m2-32bit           | GNU Modula-2 Compiler
   | gcc14-obj-c++            | GNU Objective C++ Compiler
   | gcc14-obj-c++-32bit      | GNU Objective C++ Compiler
   | gcc14-objc               | GNU Objective C Compiler
   | gcc14-objc-32bit         | GNU Objective C Compiler
   | gcc14-PIE                | A default configuration to build all binaries in PIE mode
   | libquadmath0-devel-gcc14 | The GNU Fortran Compiler Quadmath Runtime Library Develop
   | libstdc++6-devel-gcc14   | Include Files and Libraries mandatory for Development

</screen>

   <para> Now you can install the compilers for the programming languages you use with
     <command>zypper</command>: </para>

   <screen>sles15: # zypper install gcc14 gcc14-c++ gcc14-fortran
</screen>

   <para> The compilers are installed on your system, the executables are called
     <command>gcc-14</command>, <command>g++-14</command>, <command>gfortran-14</command> and so
    forth. It is also possible to install the packages in <command>YaST</command>. To do so,
    enter the <quote>Software Management</quote> menu in the <emphasis role="strong"
     >Software</emphasis> section and search for <quote>gcc14</quote>. Then select the packages you
    want to install. Finally, click the <emphasis role="strong">Accept</emphasis> button. </para>

   <note>
    <title>Newer compilers on openSUSE Leap 15.6</title>
    <para> The community distribution openSUSE Leap 15.6 shares the base packages with SUSE Linux
     Enterprise Server 15 SP6. The system compiler on systems running openSUSE Leap 15.6 is also GCC
     7.5. There is no Development Tools Module for the community distribution available, but a newer
     compiler is provided. Install the packages <package>gcc14</package>,
      <package>gcc14-c++</package>, <package>gcc14-fortran</package>, and the like. </para>
   </note>
  </sect2>
 </sect1>

 <sect1 xml:id="sec-gcc14-optimization-levels">
  <title>Optimization levels and related options</title>

  <para> GCC has a rich optimization pipeline that is controlled by approximately a hundred of
   command line options. It would be impractical to force users to decide about each one of them
   whether they want to have it enabled when compiling their code. Like all other modern compilers,
   GCC therefore introduces the concept of optimization levels which allow the user to pick a
   configuration from a few common ones. Optionally, the user can tweak the selected level, but that
   does not happen frequently. </para>

  <para> The default is to not optimize. You can specify this optimization level on the command line
   as <literal>-&#8288;O0</literal>. It is often used when developing and debugging a project.
   This means it is usually accompanied with the command line switch <literal>-g</literal> so that
   debug information is emitted. As no optimizations take place, no information is lost because of
   it. No variables are optimized away, the compiler only inlines functions with special attributes
   that require it, and so forth. As a consequence, the debugger can almost always find everything
   it searches for in the running program and report on its state very well. On the other hand, the
   resulting code is big and slow. Thus this optimization level should not be used for release
   builds. </para>

  <para> The most common optimization level for release builds is <literal>-&#8288;O2</literal>
   which attempts to optimize the code aggressively but avoids large compile times and excessive
   code growth. Optimization level <literal>-&#8288;O3</literal> instructs GCC to optimize as much 
   as possible, even if the resulting code might be considerably bigger and the
   compilation can take longer. Note that neither <literal>-&#8288;O2</literal> nor
    <literal>-&#8288;O3</literal> imply anything about the precision and semantics of
   floating-point operations. Even at the optimization level <literal>-&#8288;O3</literal> GCC
   implements math operations and functions so that they follow the respective IEEE and/or ISO rules <footnote>
    <para> When the rounding mode is set to the default round-to-nearest (look up
      <literal>-&#8288;frounding-&#8288;math</literal> in the manual).</para>
   </footnote> with the exception of allowing floating-point expression contraction, for example
   when fusing an addition and a multiplication into one operation<footnote>
    <para>See documentation of <literal>-&#8288;ffp-&#8288;contract.</literal></para>
   </footnote>. This often means that the compiled programs run markedly slower than necessary if
   such strict adherence is not required. The command line switch
    <literal>-&#8288;ffast-math</literal> is a common way to relax rules governing
   floating-point operations. It is out of scope of this document to provide a list of the
   fine-grained options it enables and their meaning. However, if your software crunches
   floating-point numbers and its runtime is a priority, you can look them up in the GCC manual and
   review what semantics of floating-point operations you need. </para>

  <para> The most aggressive optimization level is <literal>-&#8288;Ofast</literal> which does
   imply <literal>-&#8288;ffast-math</literal> along with a few options that disregard strict
   standard compliance. In GCC 14, this level also means the optimizers may introduce data races when
   moving memory stores which may not be safe for multithreaded applications, and disregards the
   possibility of ELF symbol interposition happening at runtime. Additionally, the Fortran compiler
   can take advantage of associativity of math operations even across parentheses and convert big
   memory allocations on the heap to allocations on stack. The last mentioned transformation may
   cause the code to violate maximum stack size allowed by <command>ulimit</command> which is then
   reported to the user as a segmentation fault. To work around this issue, you can use 
   <command>ulimit -S</command> with a sufficiently high limit, or <command>ulimit -S unlimited</command>. 
   We often use level <literal>-&#8288;Ofast</literal> to build benchmarks. It
   is a shorthand for the options on top of <literal>-&#8288;O3</literal> which often make them run
   faster. Most benchmarks are intentionally written in a way that they run correctly even when
   these rules are relaxed. </para>

  <para> If you feed the compiler with huge machine-generated input, especially if individual
   functions happen to be extremely large, the compile time can become an issue even when using
    <literal>-&#8288;O2</literal>. In such cases, use the most lightweight optimization level
    <literal>-&#8288;O1</literal> that avoids running almost all optimizations with quadratic
   complexity. Finally, the <literal>-&#8288;Os</literal> level directs the compiler to
   aggressively optimize for the size of the binary. </para>

  <note>
   <title>Optimization level recommendation</title>
   <para> Usually we recommend using <literal>-&#8288;O2</literal>. This is the optimization
    level we use to build most SUSE and openSUSE packages, because at this level the compiler makes
    balanced size and speed trade-offs when building a general-purpose operating system. However, we
    suggest using <literal>-&#8288;O3</literal> if you know that your project is
    compute-intensive and is either small or an important part of your actual workload. Moreover, if
    the compiled code contains performance-critical floating-point operations, we strongly advise
    that you investigate whether <literal>-&#8288;ffast-math</literal> or any of the
    fine-grained options it implies can be safely used. </para>
  </note>

  <para> If your project and the techniques you use to debug or instrument it do not depend on
    <emphasis role="italic">ELF symbol interposition</emphasis>, you may consider trying to speed it
   up by using <literal>-&#8288;fno-semantic-interposition</literal>. This allows the compiler
   to inline calls and propagate information even when it would be illegal if a symbol changed
   during dynamic linking. Using this option to signal to the compiler that interposition is not
   going to happen is known to significantly boost performance of some projects, most notably the
   Python interpreter. </para>

  <para> Some projects use <literal>-&#8288;fno-strict-aliasing</literal> to work around type
   punning problems in the source code. This is not recommended except for very low-level
   hand-optimized code such as the Linux kernel. Type-based alias analysis is a very powerful tool.
   It is used to enable other transformations, such as store-to-load propagation that in turn
   enables other high level optimizations, such as aggressive inlining, vectorization and others. </para>

  <para> With the <literal>-g</literal> switch GCC tries hard to generate useful debug information
   even when optimizing. However, a lot of information is irrecoverably lost in the process.
   Debuggers also often struggle to present the user with a view of the state of a program in which
   statements are not necessarily executed in the original order. Debugging optimized code can
   therefore be a challenging task but usually is still somewhat possible. </para>

  <para> The complete list of optimization and other command line switches is available in the
   compiler manual. The manual is provided in the info format in the package
    <package>gcc14-info</package> or online at <link
    xlink:href="https://gcc.gnu.org/onlinedocs/gcc-14.2.0/gcc/">the GCC project Web site</link>. </para>

  <para>Keep in mind that while nearly all optimizing compilers have optimization levels, and these levels 
   often share the same names as those in GCC, they don't necessarily involve the same trade-offs. 
   Famously, GCC's <literal>-&#8288;Os</literal>
   optimizes for size much more aggressively than LLVM/Clang's level with the same name. Therefore,
   it often produces slower code; the more equivalent option in Clang is
    <literal>-&#8288;Oz</literal>. Similarly, <literal>-&#8288;O2</literal> can have
   different meanings for different compilers. For example, the difference between
    <literal>-&#8288;O2</literal> and <literal>-&#8288;O3</literal> is much bigger in GCC
   than in LLVM/Clang. </para>

  <note>
   <title>Changing the optimization level with <command>cmake</command></title>
   <para> If you use <command>cmake</command> to configure and set up builds of your application, be
    aware that its <emphasis role="italic">release</emphasis> optimization level defaults to
     <literal>-&#8288;O3</literal> which might not be what you want. To change it, you must
    modify the <literal>CMAKE_C_FLAGS_RELEASE</literal>, <literal>CMAKE_CXX_FLAGS_RELEASE</literal>
    and/or <literal>CMAKE_Fortran_FLAGS_RELEASE</literal> variables. Since they are appended at the
    end of the compilation command lines, they are overwriting any level set in the variables
     <literal>CMAKE_C_FLAGS</literal>, <literal>CMAKE_CXX_FLAGS</literal>, and the like. </para>
  </note>
 </sect1>

 <sect1 xml:id="sec-gcc14-target-options">
  <title>Taking advantage of newer processors</title>

  <para> By default, GCC assumes that you want to run the compiled program on a wide variety of CPUs,
   including fairly old ones, regardless of the selected optimization level. On architectures like
    <literal>x86_64</literal> and <literal>aarch64</literal> the generated code will only contain
   instructions available on every CPU model of the architecture, including the earliest ones. On
    <literal>x86_64</literal> in particular this means that the programs will use the
    <literal>SSE</literal> and <literal>SSE2</literal> instruction sets for floating-point and
   vector operations but not any more recent ones. </para>

  <para> If you know that the generated binary will run only on machines supporting newer
   instruction set extensions, you can specify it on the command line. Their complete list is
   available in the manual, but the most prominent one is <literal>-&#8288;march</literal> which
   lets you select a CPU model to generate code for. For example, if you know that your program will
   only be executed on AMD EPYC 9005 Series Processors based on AMD Zen 5 cores or processors that
   are compatible with it, you can instruct GCC to take advantage of all the instructions the CPU
   supports with option <literal>-&#8288;march=znver5</literal>. Note that, on SUSE Linux
   Enterprise Server 15, the system compiler does not know this particular value of the switch. You
   need to use GCC 14 from the Development Tools Module to optimize code for these processors. </para>

  <para> To run the program on the machine on which you are compiling it, you can have the compiler
   auto-detect the target CPU model for you with the option
    <literal>-&#8288;march=native</literal>. This only works if the compiler is new enough. The
   system compiler of SUSE Linux Enterprise Server, for example, misidentifies AMD EPYC 9005 Series
   Processors as being based on the AMD Zen 1 core. Among other things, this means that it only
   emits 128 bit vector instructions, even though the CPU has data-paths wide enough to efficiently
   execute 512 bit ones. Again, the easy solution is to use the compiler from the Development Tools
   Module when targeting recent processors. </para>

  <note>
   <title>Running 32-bit code</title>
   <para> SUSE Linux Enterprise Server does not support compilation of 32-bit applications, it only
    offers runtime support for 32-bit binaries. To do so, you will need 32-bit libraries your binary
    depends on which likely include at least glibc which can be found in package
     <literal>glibc-32bit</literal>. See <link
     xlink:href="https://documentation.suse.com/sles/15-SP6/html/SLES-all/cha-64bit.html">chapter 20
     (32-bit and 64-bit applications in a 64-bit system environment) of the Administration
     Guide</link> for more information. </para>
  </note>

 </sect1>

 <sect1 xml:id="sec-gcc14-lto">
  <title>Link Time Optimization (LTO)</title>

  <para>
   <xref linkend="fig-gcc14-nonlto-build" xrefstyle="template:Figure %n"/> outlines the classic mode
   of operation of a compiler and a linker. Pieces of a program are compiled and optimized in chunks
   defined by the user called compilation units to produce so-called object files. These object
   files already contain binary machine instructions and are combined together by a linker. Because
   the linker works at such low level, it cannot perform much optimization and the division of the
   program into compilation units thus presents a profound barrier to optimization. </para>

  <figure xml:id="fig-gcc14-nonlto-build">
   <title>Traditional program build</title>
   <mediaobject>
    <imageobject role="fo">
     <imagedata fileref="gcc12-nonlto.svg" width="100%" format="SVG"/>
    </imageobject>
    <imageobject role="html">
     <imagedata fileref="gcc12-nonlto.svg" width="100%" format="SVG"/>
    </imageobject>
   </mediaobject>
  </figure>

  <para> This limitation can be overcome by rearranging the process so that the linker does not
   receive as its input the almost finished object files containing machine instructions, but is
   invoked on files containing so called <emphasis role="italic">intermediate language</emphasis>
   (IL). This is a much richer representation of each original compilation unit (see figure <xref
    linkend="fig-gcc14-lto-build" xrefstyle="template:figure %n"/>). The linker identifies the input
   as not yet entirely compiled and invokes a linker plugin which in turn runs the compiler again.
   But this time it has at its disposal the representation of the entire program or library that is
   being built. The compiler makes decisions about what optimizations across function and
   compilation unit boundaries will be carried out and then divides the program into a set of
   partitions. Each of the partitions is further optimized independently, and machine code is
   emitted for it, which is finally linked the traditional way. Processing of the partitions is
   performed in parallel. </para>

  <figure xml:id="fig-gcc14-lto-build">
   <title>Building a program with GCC using Link Time Optimization (LTO)</title>
   <mediaobject>
    <imageobject role="fo">
     <imagedata fileref="gcc12-lto.svg" width="100%" format="SVG"/>
    </imageobject>
    <imageobject role="html">
     <imagedata fileref="gcc12-lto.svg" width="100%" format="SVG"/>
    </imageobject>
   </mediaobject>
  </figure>

  <para> To use <emphasis role="strong">Link Time Optimization</emphasis>, all you need do is to add
   the <literal>-&#8288;flto</literal> switch to the compilation command line. The vast majority
   of packages in the Linux distribution openSUSE Tumbleweed has been built with LTO for over five
   years without any major problems. A lot of work has been put into emitting good debug information
   when building with LTO too. Thus the debugging experience is not severely limited anymore as it
   was seven years ago. </para>

  <para> LTO in GCC always consists of a <emphasis role="italic">whole program analysis</emphasis>
   (WPA) stage followed by the majority of the compilation process performed in parallel, which
   greatly reduces the build times of most projects. To control the parallelism, you can explicitly
   cap the number of parallel compilation processes by <emphasis role="italic">n</emphasis> if you
   specify <literal>-&#8288;flto=<replaceable>n</replaceable></literal> at linker command line.
   Alternatively, it is possible to use the GNU <command>make</command> jobserver with
    <literal>-&#8288;flto=jobserv</literal> while also prepending the <emphasis role="strong"
    >makefile</emphasis> rule invoking link step with character <literal>+</literal> to instruct GNU
    make to keep the jobserver available to the linker process. However, this modification of 
   <package>makefiles</package> is not necessary with make version 4.4 or newer.</para>
    <para> You can also use <literal>-&#8288;flto=auto</literal> which instructs GCC to search for 
     the jobserver and if it is not found, use all available CPU threads. </para>

  <para> Note that there is a principal architectural difference in how GCC and LLVM/Clang approach
   LTO. Clang provides two LTO mechanisms, so-called <emphasis role="italic">thin LTO</emphasis> and
    <emphasis role="italic">full LTO</emphasis>. In full LTO, LLVM processes the whole program as if
   it was a single translation unit which does not allow for any parallelism. GCC can be configured
   to operate in this way with the option <literal>-&#8288;flto-partition=one</literal>. LLVM in
   thin LTO mode can compile different compilation units in parallel and makes possible inlining
   across compilation unit boundaries, but not most other types of cross-module optimizations. This
   mechanism therefore has inherently higher code quality penalty than full LTO or the approach of
   GCC. </para>

  <sect2 xml:id="sec-gcc14-selected-lto-benefits">
   <title>Most notable benefits of LTO</title>

   <para> Applications built with LTO are often faster, mainly because the compiler can <emphasis
     role="italic">inline</emphasis> calls to functions in another compilation unit. This
    possibility also allows programmers to structure their code according to its logical division
    because they are not forced to put function definitions into header files to enable their
    inlining. Since the compiler cannot inline all calls conveying information known at
    compilation time, GCC tracks and propagates constants, value ranges, memory reference
    information and devirtualization contexts from the call sites to the callees, even when
    passed in an aggregate or by reference. These can then subsequently save unnecessary
    computations or enable subsequent optimizations and speed up the built program or library.  LTO
    allows such propagation across compilation unit boundaries, too. </para>

   <para> Link Time Optimization with <emphasis>whole program analysis</emphasis> also offers many
    opportunities to shrink the code size of the built project. Thanks to <emphasis role="italic"
     >symbol promotion</emphasis> and inter-procedural <emphasis role="italic">unreachable code
     elimination</emphasis>, functions and their parts which are not necessary in any particular
    project can be removed even when they are not declared <literal>static</literal> and are not
    defined in an anonymous namespace. Automatic <emphasis role="italic">attribute
     discovery</emphasis> can identify <literal>C++</literal> functions that do not throw exceptions.
    This allows the compiler to avoid generating a lot of code in exception cleanup regions.
     <emphasis role="italic">Identical code folding</emphasis> can find functions with the same
    semantics and remove all but one of them. The code size savings are often very significant and a
    compelling reason to use LTO even for applications which are not CPU-bound. </para>

   <note>
    <title>Building libraries with LTO</title>
    <para> The symbol promotion is controlled by resolution information given to the linker and
     depends on type of the DSO build. When producing a dynamically loaded shared library, all
     symbols with default visibility can be overwritten by the dynamic linker. This blocks the
     promotion of all functions not declared inline, thus it is necessary to use the hidden
     visibility wherever possible to achieve best results. Similar problems happen even when
     building static libraries with <literal>-rdynamic</literal>. </para>
   </note>
  </sect2>

  <sect2 xml:id="sec-gcc14-lto-issues">
   <title>Potential issues with LTO</title>

   <para> As mentioned earlier, the vast majority of packages in the openSUSE Tumbleweed distribution
    are built with LTO by default and work fine without any tweaks. Nevertheless, some
    low-level constructs pose a problem for LTO. One typical issue are symbols defined in <emphasis
     role="italic">inline assembly</emphasis> which can happen to be placed in a different partition
    from their uses and subsequently fail the final linking step. To build such projects with LTO,
    the assembler snippets defining symbols must be placed into a separate assembler source file so
    that they only participate in the final linking step. Global <literal>register</literal>
    variables are not supported by LTO, and programs either must not use this feature or be built
    the traditional way. You can also exclude some compilation units from LTO (by
    compiling them without <literal>-&#8288;flto</literal> or appending
     <literal>-&#8288;fno-&#8288;lto</literal> to the compilation command line), while the
    rest of the program can still benefit from using this feature.</para>

   <para> Another notable limitation of LTO is that it does not support <emphasis role="italic">
     symbol versioning</emphasis> implemented with special inline assembly snippets (as opposed to a
    linker map file). To define symbol versions in the source files, you can do so with the
     <literal>symver</literal> function attribute. As an example, the following snippet will make
    the function <literal>foo_v1</literal> implement <literal>foo</literal> in <emphasis
     role="italic">node</emphasis>
    <literal>VERS_1</literal> (which must be specified in the version script supplied to the
    linker). Consult <link
     xlink:href="https://gcc.gnu.org/onlinedocs/gcc/Common-Function-Attributes.html#index-symver-function-attribute"
     >the manual</link> for more details. </para>
   <screen>__attribute__ ((__symver__ ("foo@VERS_1")))
int foo_v1 (void)
{
}
      </screen>

   <para> Sometimes the extra power of LTO reveals pre-existing problems which do not manifest
    themselves otherwise. Violations of (strict) <emphasis role="italic">aliasing</emphasis> rules
    and <literal>C++</literal>
    <emphasis role="italic">one definition rule</emphasis> tend to cause misbehavior significantly
    more often. The latter is fortunately reported by the <literal>-Wodr</literal> warning which is
    on by default and should not be ignored. We have also seen cases where the use of the
     <literal>flatten</literal> function attribute led to unsustainable amount of inlining with LTO.
    Furthermore, LTO is not a good fit for code snippets compiled by <literal>configure</literal>
    scripts (generated by <literal>autoconf</literal>) to discover the availability of various
    features, especially when the script then searches for a string in the generated assembly. </para>

   <para> Finally, we needed to configure the virtual machines building the biggest openSUSE
    packages to have more memory than when not using LTO. Whereas in the traditional mode of
    compilation 1 GB of RAM per core was enough to build Mozilla Firefox, the serial step of LTO
    means the build-bots need 16 GB even when they have fewer than 16 cores. </para>
  </sect2>
 </sect1>

 <sect1 xml:id="sec-gcc14-pgo">
  <title>Profile-Guided Optimization (PGO)</title>

  <para> Optimizing compilers frequently make decisions that depend on which path through the code
   they consider most likely to be executed, how many times a loop is expected to iterate, and
   similar estimates. They also often face trade-offs between potential runtime benefits and code
   size growth. Ideally, they would optimize only frequently executed (also called <emphasis
    role="italic">hot</emphasis>) bits of a program for speed and everything else for size to reduce
   strain on caches and make the distribution of the built software cheaper. Unfortunately, guessing
   which parts of a program are the <emphasis role="italic">hot</emphasis> ones is difficult, and
   even sophisticated estimation algorithms implemented in GCC are no match for a measurement. </para>

  <para> If you do not mind adding an extra level of complexity to the build system of your project,
   you can make such measurement part of the process. The <emphasis role="strong"
    >makefile</emphasis> (or any other) build script needs to compile the project twice. The first
   time it needs to compile with the <literal>-&#8288;fprofile-generate</literal> option and
   then execute the resulting binary in one or multiple <emphasis role="italic">train
    runs</emphasis> during which it will save information about the behavior of the program to
   special files. Afterward, the project needs to be rebuilt again, this time with the
    <literal>-&#8288;fprofile-use</literal> option. This instructs the compiler to look for the
   files with the measurements and use them when making optimization decisions, a process called
    <emphasis role="italic">Profile-Guided Optimization (PGO)</emphasis>. </para>

  <para> It is important that the train run exhibits the same characteristics as the real workload.
   Unless you use the option <literal>-&#8288;fprofile-partial-training</literal> in the second
   build, it needs to exercise the code that is also the most frequently executed in real use,
   otherwise it will be optimized for size and PGO would make more harm than good. With the option,
   GCC reverts to guessing properties of portions of the projects not exercised in the train run, as
   if they were compiled without profile feedback. This however also means that this code will not
   perform better or shrink as much as one would expect from a PGO build. </para>

  <para> On the other hand, train runs do not need to be a perfect simulation of the real workload.
   For example, even though a test suite should not be a very good train run in theory because it
   disproportionally often tests various corner cases, in practice many projects use it as a train
   run and achieve significant runtime improvements with real workloads, too. </para>

  <para> Profiles collected using an instrumented binary for multithreaded programs may be
   inconsistent because of missed counter updates. You can use
    <literal>-&#8288;fprofile-correction</literal> in addition to
    <literal>-&#8288;fprofile-use</literal> so that GCC uses heuristics to correct or smooth out
   such inconsistencies instead of emitting an error. </para>

  <para> Profile-Guided Optimization can be combined and is complimentary to Link Time Optimization.
   While LTO expands what the compiler can do, PGO informs it about which parts of the program are
   the important ones and should be focused on. The case study in the following section shows how
   the two techniques work with each other on a well-known set of benchmarks. </para>
 </sect1>

 <sect1 xml:id="sec-gcc14-spec">
  <title>Performance evaluation: SPEC CPU 2017</title>

  <para>
   <emphasis role="italic">Standard Performance Evaluation Corporation</emphasis> (SPEC) is a
   non-profit corporation that publishes a variety of industry standard benchmarks to evaluate
   performance and other characteristics of computer systems. Its latest suite of CPU intensive
   workloads, SPEC CPU 2017, is often used to compare compilers and how well they optimize code with
   different settings. This is because the included benchmarks are well known and represent a wide
   variety of computation-heavy programs. The following section highlights selected results of a GCC
   14 evaluation using the suite. </para>

  <para> Note that when we use SPEC to perform compiler comparisons, we are lenient toward some
   official SPEC rules which system manufacturers need to observe to claim an official score for
   their system. We disregard the concepts of <emphasis role="italic">base</emphasis> and <emphasis
    role="italic">peak</emphasis> metrics and focus on results of compilations using a
   particular set of options. We even patched several benchmarks: </para>

  <itemizedlist>
   <listitem>
    <para> Benchmarks <literal>502.gcc_r</literal>, <literal>505.mcf_r</literal>,
      <literal>511.povray_r</literal>, and <literal>527.cam4_r</literal> contain an implementation
     of quicksort which violates (strict) <literal>C/C++</literal> aliasing rules which can lead to
     erroneous behavior when optimizing at link time. SPEC decided not to change the released
     benchmarks and suggests that these benchmarks are built with the
      <literal>-&#8288;fno-strict-aliasing</literal> option when they are built with GCC. That
     makes evaluation of compilers using SPEC problematic, examining their ability to use aliasing
     rules to facilitate optimizations is important. We have therefore disabled it only for the
     problematic <literal>qsort</literal> functions with the following function attribute: </para>
    <screen>__attribute__((optimize("-fno-strict-aliasing")))</screen>
    <para> As a result, the only benchmark which we compile with
      <literal>-&#8288;fno-strict-aliasing</literal> is <literal>500.perlbench_r</literal>.
    </para>
   </listitem>
   <listitem>
     <para> Benchmark <literal>511.povray_r</literal> cannot be built with option
     <literal>-&#8288;fno-finite-math-only</literal> which is a part of options enabled by
     <literal>-&#8288;ffast-math</literal> for reasons described in <link
     xlink:href="https://gcc.gnu.org/bugzilla/show_bug.cgi?id=107021">GCC bug 107021</link>.  The
     <literal>-&#8288;Ofast</literal> measurements using GCC 14 or Clang 19 in this section therefore
     append <literal>-&#8288;fno-finite-math-only</literal> to the compilation command lines, but again
     only for this one benchmark.
     </para>
   </listitem>
   <listitem>
    <para> We have increased the tolerance of <literal>549.fotonik3d_r</literal> to rounding errors
     after it became clear the intention was that the compiler can use relaxed semantics of
     floating-point operations in the benchmark (see <link
      xlink:href="https://gcc.gnu.org/bugzilla/show_bug.cgi?id=84201">GCC bug 84201</link>). </para>
   </listitem>
  </itemizedlist>

  <para> Moreover, SPEC 2017 CPU offers so-called <emphasis role="italic"> speed</emphasis> and
  <emphasis role="italic">rate</emphasis> metrics. For our purposes, we mostly ignore the
  differences and run the benchmarks configured for rate metrics (mainly because the runtimes
  are smaller) but we always run all benchmarks single-threaded.  For these and other reasons, all
  the results in this document are <emphasis role="italic"> non-reportable</emphasis>. </para>

  <para> Finally, SPEC specifies a base runtime for each benchmark and defines a <emphasis role="italic">
   rate</emphasis> as the ratio of the base runtime and the median measured runtime (this rate is
   a separate concept from the rate metrics). The overall suite score is then calculated as
   geometric mean of these ratios. The bigger the rate or score, the better it is. In the remainder
   of this section, we report runtimes using relative rates and their geometric means as they were
   measured on an AMD EPYC 9755 Processor running SUSE Linux Enterprise Server 15 SP6. </para>

  <sect2 xml:id="sec-gcc14-spec-lto-pgo">
   <title>Benefits of LTO and PGO</title>

   <para> In <xref linkend="sec-gcc14-optimization-levels"/> we recommend that HPC workloads are
    compiled with <literal>-&#8288;O3</literal> and benchmarks with
     <literal>-&#8288;Ofast</literal>. But it is still interesting to look at integer crunching
    benchmarks built with only <literal>-&#8288;O2</literal> because that is how Linux
    distributions often build the programs from which they were extracted. We have already mentioned
    that almost the whole openSUSE Tumbleweed distribution is now built with LTO, and selected
    packages with PGO, and the following paragraphs demonstrate why. </para>

   <figure xml:id="fig-gcc14-specint-o2-pgolto-geomean">
    <title>Overall performance (bigger is better) of SPEC INTrate 2017 built with GCC 14.2 and
     -&#8288;O2</title>
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="gcc14-specint-o2-pgolto-perf-geomean.svg" width="85%" format="SVG"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="gcc14-specint-o2-pgolto-perf-geomean.svg" width="85%" format="SVG"/>
     </imageobject>
    </mediaobject>
   </figure>

   <!-- xrefstyle="select:label" in xref also works but puts Figure with capital F everywhere -->

   <para>
    <xref linkend="fig-gcc14-specint-o2-pgolto-geomean" xrefstyle="template:Figure %n"/> shows the
    overall performance effect on the whole integer benchmark suite as captured by the geometric
    mean of all individual benchmark rates. Employing both PGO and LTO results in remarkable
    relative uplift of 16.5%. That is despite the fact that starting with GCC 12, the compiler
    can conservatively auto-vectorize code in <literal>525.x264_r</literal> also at plain
    <literal>-&#8288;O2</literal>, whereas previously it was only automatically performed with PGO at
    this level.  Nevertheless, this benchmark still benefits a lot from the more advanced modes of
    compilation, together with several others which are derived from programs that are
    typically compiled with <literal>-&#8288;O2</literal>. This is illustrated in <xref
    linkend="fig-gcc14-specint-o2-pgolto-perf-indiv" xrefstyle="template:figure %n"/>. </para>

   <figure xml:id="fig-gcc14-specint-o2-pgolto-perf-indiv">
    <title>Runtime performance (bigger is better) of individual integer benchmarks built with GCC
     14.2 and -&#8288;O2</title>
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="gcc14-specint-o2-pgolto-perf-indiv.svg" width="90%" format="SVG"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="gcc14-specint-o2-pgolto-perf-indiv.svg" width="90%" format="SVG"/>
     </imageobject>
    </mediaobject>
   </figure>

   <para>
    <xref linkend="fig-gcc14-specint-o2-ltopgo-size" xrefstyle="template:Figure %n"/> shows another
    important advantage of LTO and PGO which is significant reduction of the size of the binaries
    (measured without debug info). Note that it does not depict that the size of benchmark
     <literal>548.exchange2_r</literal> grew to 260% and 174% of the original size when built with
    PGO or both PGO and LTO respectively, which looks huge but the growth is from a particularly
    small base. It is the only Fortran benchmark in the integer suite and, most importantly, the
    size penalty is offset by significant speed-up, making the trade-off reasonable. For
    completeness, we show this result in <xref linkend="fig-gcc14-specint-o2-ltopgo-size-exchange"
     xrefstyle="template:figure %n"/>
   </para>

   <figure xml:id="fig-gcc14-specint-o2-ltopgo-size">
    <title>Binary size (smaller is better) of individual integer benchmarks built with GCC 14.2 and
     -&#8288;O2</title>
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="gcc14-specint-o2-pgolto-size.svg" width="90%" format="SVG"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="gcc14-specint-o2-pgolto-size.svg" width="90%" format="SVG"/>
     </imageobject>
    </mediaobject>
   </figure>

   <figure xml:id="fig-gcc14-specint-o2-ltopgo-size-exchange">
    <title>Binary size (smaller is better) of 548.exchange2_r built with GCC 14.2 and
     -&#8288;O2</title>
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="gcc14-specint-o2-pgolto-size-exchange.svg" width="90%" format="SVG"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="gcc14-specint-o2-pgolto-size-exchange.svg" width="90%" format="SVG"/>
     </imageobject>
    </mediaobject>
   </figure>



   <para> The runtime benefits and binary size savings are also easily visible when using the
   optimization level <literal>-&#8288;Ofast</literal> and option
   <literal>-&#8288;march=native</literal> to allow the compiler to take full advantage of all
   instructions that the AMD EPYC 9755 Processor supports. <xref
   linkend="fig-gcc14-specint-ofast-pgolto-geomean" xrefstyle="template:Figure %n"/> shows the
   respective geometric means, and <xref linkend="fig-gcc14-specint-ofast-pgolto-perf-indiv"
   xrefstyle="template:figure %n"/> shows how rates change for individual benchmarks.  Even at the
   aggressive optimization level PGO brings about clear benefits for benchmarks derived from
   interpreters and compilers like <literal>500.perlbench_r</literal> and
   <literal>502.gcc_r</literal> but the compiler can struggle to correctly update the measured
   profile information when performing complex inter-procedural optimizations like in the case of
   <literal>548.exchange2_r</literal> leading to the technique actually decreasing performance.
   Lastly, even though optimization levels <literal>-&#8288;O3</literal> and
   <literal>-&#8288;Ofast</literal> are permitted to be relaxed about the final binary size, PGO and
   especially LTO can bring it nicely down at these levels, too. <xref
   linkend="fig-gcc14-specint-ofast-pgolto-size" xrefstyle="template:Figure %n"/> depicts the
   relative binary sizes of all integer benchmarks. </para>

   <figure xml:id="fig-gcc14-specint-ofast-pgolto-geomean">
    <title>Overall performance (bigger is better) of SPEC INTrate 2017 built with GCC 14.2 using
     -&#8288;Ofast and -&#8288;march=native</title>
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="gcc14-specint-ofast-pgolto-perf-geomean.svg" width="85%" format="SVG"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="gcc14-specint-ofast-pgolto-perf-geomean.svg" width="85%" format="SVG"/>
     </imageobject>
    </mediaobject>
   </figure>

   <figure xml:id="fig-gcc14-specint-ofast-pgolto-perf-indiv">
    <title>Runtime performance (bigger is better) of individual integer benchmarks built with GCC
     14.2 using -&#8288;Ofast and -&#8288;march=native</title>
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="gcc14-specint-ofast-pgolto-perf-indiv.svg" width="90%" format="SVG"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="gcc14-specint-ofast-pgolto-perf-indiv.svg" width="90%" format="SVG"/>
     </imageobject>
    </mediaobject>
   </figure>

   <figure xml:id="fig-gcc14-specint-ofast-pgolto-size">
    <title>Binary size (smaller is better) of SPEC INTrate 2017 built with GCC 14.2 using
     -&#8288;Ofast and -&#8288;march=native</title>
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="gcc14-specint-ofast-pgolto-size.svg" width="90%" format="SVG"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="gcc14-specint-ofast-pgolto-size.svg" width="90%" format="SVG"/>
     </imageobject>
    </mediaobject>
   </figure>

   <para>Many of the SPEC 2017 floating-point benchmarks measure how well a given system can
   optimize and execute a handful of number crunching loops. They often come from performance
   sensitive programs written with traditional compilation method in mind. As a result, there are
   fewer cross-module dependencies, making the identification of hot paths less critical.
   Consequently, the overall impact of LTO and PGO on the suite is often minimal. Nevertheless,
   there are important cases when these modes of compilation also bring about significant
   performance increases.  <xref linkend="fig-gcc14-specfp-ofast-pgolto-perf-indiv"
   xrefstyle="template:Figure %n"/> shows the effect of these methods on individual benchmarks when
   compiled at <literal>-&#8288;Ofast</literal> and targeting the full ISA of the AMD EPYC 9755
   Processor. Furthermore, binary size savings of PGO and LTO are sometimes even bigger than those
   achieved on integer benchmarks, as can be seen in <xref
   linkend="fig-gcc14-specfp-ofast-pgolto-size" xrefstyle="template:figure %n"/></para>

   <para>Unfortunately, in the case of <literal>538.imagick_r</literal> benchmark there is a big
   mismatch in between the code paths exercised in the train run which is used to measure which
   parts of the program need to be optimized for speed and the actual reference run which is then
   used to obtain the benchmark score.  This is exactly the problem we warn against in <xref
   linkend="sec-gcc14-pgo"/> and it has the predictable detrimental effect on performance.<footnote>
   <para>See <link xlink:href="https://gcc.gnu.org/bugzilla/show_bug.cgi?id=111551">GCC bug
   111551</link> for more details.</para></footnote> Moreover, because the important loop, which is
   not appropriately optimized because it is not executed in the train run, is in a function in
   which there is another loop which is heavily executed in the train run, even using the
   <literal>-&#8288;fprofile-partial-training</literal> does not help to mitigate the problem.  This
   is a bug in the SPEC CPU suite and it means that the overall performance score even
   decreases by 1% when using both LTO and PGO.
   </para>

    <!--
   <figure xml:id="fig-gcc12-specfp-ofast-pgolto-geomean">
    <title>Overall performance (bigger is better) of SPEC FPrate 2017 built with GCC 12.3 and
     -&#8288;Ofast</title>
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="gcc12-specfp-ofast-pgolto-perf-geomean.svg" width="85%" format="SVG"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="gcc12-specfp-ofast-pgolto-perf-geomean.svg" width="85%" format="SVG"/>
     </imageobject>
    </mediaobject>
   </figure>
    -->

   <figure xml:id="fig-gcc14-specfp-ofast-pgolto-perf-indiv">
    <title>Runtime performance (bigger is better) of individual floating-point benchmarks built with
     GCC 14.2 using -&#8288;Ofast and -&#8288;march=native</title>
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="gcc14-specfp-ofast-pgolto-perf-indiv.svg" width="90%" format="SVG"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="gcc14-specfp-ofast-pgolto-perf-indiv.svg" width="90%" format="SVG"/>
     </imageobject>
    </mediaobject>
   </figure>

   <figure xml:id="fig-gcc14-specfp-ofast-pgolto-size">
    <title>Binary size (smaller is better) of SPEC FPrate 2017 built with GCC 14.2 using
     -&#8288;Ofast and -&#8288;march=native</title>
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="gcc14-specfp-ofast-pgolto-size.svg" width="90%" format="SVG"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="gcc14-specfp-ofast-pgolto-size.svg" width="90%" format="SVG"/>
     </imageobject>
    </mediaobject>
   </figure>



  </sect2>

  <sect2 xml:id="sec-gcc14-spec-cmp-to-gcc7">
   <title>GCC 14.2 compared to GCC 7.5</title>

   <para> In previous sections we have recommended the use of GCC 14.2 from the Development Tools
   Module over the system compiler. Among other reasons, we did so because of its more powerful
   optimization pipeline and its support for newer CPUs. This section compares SPEC CPU 2017 built
   with GCC 7.5, the system compiler in SUSE Linux Enterprise Server 15, and GCC 14.2 on an AMD EPYC
   9755 Processor, when all benchmarks are compiled with <literal>-&#8288;Ofast</literal> and
   <literal>-&#8288;march=native</literal>. Note that the latter option means that both compilers
   differ in their CPU targets because GCC 7.5 does not know the Zen 5 core. This in turn means that
   in large part the optimization benefits presented here exist because the old compiler only issues
   128bit (AVX2) vector operations whereas the newer one can take full advantage of
   AVX512. Nevertheless, be aware that using wider vectors everywhere often backfires. GCC
   has made substantial advancements over the recent years to avoid such issues, both in its
   vectorizer and other optimizers. It is therefore much better placed to use the extra vector width
   appropriately and produce code which utilizes the processor better in general. </para>

   <figure xml:id="fig-gcc14-specint-ofast-vs7-geomean">
    <title>Overall performance (bigger is better) of SPEC INTrate 2017 built with GCC 7.5 and 14.2
     (-&#8288;Ofast -&#8288;march=native)</title>
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="gcc14-specint-ofast-vs7-geomean.svg" width="85%" format="SVG"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="gcc14-specint-ofast-vs7-geomean.svg" width="85%" format="SVG"/>
     </imageobject>
    </mediaobject>
   </figure>

   <para>
    <xref linkend="fig-gcc14-specint-ofast-vs7-geomean" xrefstyle="template:Figure %n"/> captures
    the benefits of using the modern compiler with integer workloads in the form of relative
    improvements of the geometric mean of the whole SPEC INTrate 2017 suite. <xref
     linkend="fig-gcc14-specint-ofast-vs7-indiv" xrefstyle="template:Figure %n"/> dives deeper and
    shows which particular benchmarks gained most in terms of performance. It was already mentioned
    that <literal>525.x264_r</literal> especially benefits from vectorization and therefore it is
    not surprising it has improved a lot. <literal>531.deepsjeng_r</literal> is faster chiefly
    because it can emit better code for <emphasis role="italic">count trailing zeros</emphasis>
    (CTZ) operation which it performs frequently. Finally, modern GCC can optimize
     <literal>548.exchange2_r</literal> particularly well by specializing different invocations of
    the hottest recursive function and it also clearly shows in the picture.</para>

   <figure xml:id="fig-gcc14-specint-ofast-vs7-indiv">
    <title>Runtime performance (bigger is better) of selected integer benchmarks built with GCC 7.5
     and 14.2 (-&#8288;Ofast -&#8288;march=native)</title>
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="gcc14-specint-ofast-vs7-indiv.svg" width="90%" format="SVG"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="gcc14-specint-ofast-vs7-indiv.svg" width="90%" format="SVG"/>
     </imageobject>
    </mediaobject>
   </figure>

   <para> Floating-point computations tend to particularly benefit from vectorization advancements.
    Thus it should be no surprise that the FPrate benchmarks also improve substantially when
    compiled with GCC 14.2, which also emits AVX512 instructions for a Zen 5 based CPU. The overall
    boost is shown in <xref linkend="fig-gcc14-specfp-ofast-vs7-geomean"
     xrefstyle="template:figure
   %n"/> whereas <xref linkend="fig-gcc14-specfp-ofast-vs7-indiv"
     xrefstyle="template:figure %n"/> provides a detailed look at which benchmarks contributed most
    to the overall score difference. </para>

   <figure xml:id="fig-gcc14-specfp-ofast-vs7-geomean">
    <title>Overall performance (bigger is better) of SPEC FPrate 2017 built with GCC 7.5 and 14.2
     (-&#8288;Ofast -&#8288;march=native)</title>
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="gcc14-specfp-ofast-vs7-geomean.svg" width="85%" format="SVG"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="gcc14-specfp-ofast-vs7-geomean.svg" width="85%" format="SVG"/>
     </imageobject>
    </mediaobject>
   </figure>

   <figure xml:id="fig-gcc14-specfp-ofast-vs7-indiv">
    <title>Runtime performance (bigger is better) of selected floating-point benchmarks built with
     GCC 7.5 and 14.2 (-&#8288;Ofast -&#8288;march=native)</title>
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="gcc14-specfp-ofast-vs7-indiv.svg" width="90%" format="SVG"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="gcc14-specfp-ofast-vs7-indiv.svg" width="90%" format="SVG"/>
     </imageobject>
    </mediaobject>
   </figure>
  </sect2>

  <sect2 xml:id="sec-gcc14-spec-fast-math">
   <title>Effects of <literal>-&#8288;ffast-math</literal> on floating-point performance</title>

   <para> In <xref linkend="sec-gcc14-optimization-levels"/>, we highlighted that if you do not relax 
    the semantics of floating-point math functions, despite not needing strict adherence to all IEEE and/or ISO rules, 
    you are likely to sacrifice some performance. This section uses the SPEC FPrate 2017 test suite to illustrate how much
    performance that might be. </para>

   <para> We have built the benchmarking suite using optimization level
     <literal>-&#8288;O3</literal>, LTO (though without PGO) and
     <literal>-&#8288;march=native</literal> to target the native ISA of our AMD EPYC 9755
    Processor. Then we compared its runtime score against the suite built with these options and
     <literal>-&#8288;ffast-math</literal>. As you can see in <xref
     linkend="fig-gcc14-specfp-o3-fastmath-geomean" xrefstyle="template:figure %n"/>, the geometric
    mean grew by over 13%. But a quick look at <xref linkend="fig-gcc14-specfp-o3-fastmath-indiv"
     xrefstyle="template:figure %n"/> will tell you that there are four benchmarks with scores which
    improved by more than 15% and that of <literal>538.imagick_r</literal> grew by over 60%. </para>

   <figure xml:id="fig-gcc14-specfp-o3-fastmath-geomean">
    <title>Overall performance (bigger is better) of SPEC FPrate 2017 built with GCC 14.2 and
     -&#8288;O3 -&#8288;flto -&#8288;march=native, without and with
     -&#8288;ffast-math</title>
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="gcc14-specfp-o3-fastmath-perf-geomean.svg" width="85%" format="SVG"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="gcc14-specfp-o3-fastmath-perf-geomean.svg" width="85%" format="SVG"/>
     </imageobject>
    </mediaobject>
   </figure>

   <figure xml:id="fig-gcc14-specfp-o3-fastmath-indiv">
    <title>Runtime performance (bigger is better) of individual floating-point benchmarks built with
     GCC 14.2 and -&#8288;O3 -&#8288;flto -&#8288;march=native, without and with
     -&#8288;ffast-math</title>
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="gcc14-specfp-o3-fastmath-perf-indiv.svg" width="100%" format="SVG"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="gcc14-specfp-o3-fastmath-perf-indiv.svg" width="100%" format="SVG"/>
     </imageobject>
    </mediaobject>
   </figure>
  </sect2>

  <sect2 xml:id="sec-gcc14-spec-compared-to-others">
   <title>Comparison with other compilers</title>

   <para> The toolchain team at SUSE regularly uses the SPEC CPU 2017 suite to compare the
    optimization capabilities of GCC with other compilers, mainly LLVM/Clang and ICX from
    Intel. In the final section of this case study, we will discuss how the Development Module 
    compiler compares to its competitors on SUSE Linux Enterprise Server 15 SP6. Before we begin, 
    it is important to note that the comparison was conducted by individuals with significantly more 
    expertise in GCC than in the other compilers, and they are not completely <quote>unbiased</quote>. 
    Also, keep in mind that everything we explained previously about how we carry out the 
    measurements and patch the benchmarks also applies to this section. However, since the results 
    inform our own work, rest assured that we strive for accuracy.</para>

   <para> We have built the <literal>clang</literal>, <literal>clang++</literal> and
   <literal>flang-new</literal> compilers from sources obtained from the official git repository
   (tag <literal>llvmorg-19.1.4</literal>), used it to compile the SPEC CPU 2017 suite with
   <literal>-&#8288;Ofast</literal> and <literal>-&#8288;march=native</literal> and compared the
   performance against the suites built with GCC 14.2 with the same options. When using Clang's LTO
   to compile SPEC, we selected the <emphasis role="italic">full</emphasis> variant because it is
   more powerful in terms of optimization capabilities even though it is not suitable for building
   large projects.</para>

   <figure xml:id="fig-gcc14-specint-ofast-vsllvm-geomean">
    <title>Overall performance (bigger is better) of C/C++ integer benchmarks built with Clang 19
     and GCC 14.2</title>
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="gcc14-specint-ofast-vsllvm-geomean.svg" width="100%" format="SVG"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="gcc14-specint-ofast-vsllvm-geomean.svg" width="100%" format="SVG"/>
     </imageobject>
    </mediaobject>
   </figure>

   <para><xref linkend="fig-gcc14-specint-ofast-vsllvm-geomean" xrefstyle="template:Figure %n"/>
   shows that the geometric mean of the whole SPEC INTrate 2017 suite is quite substantially better
   when the benchmarks are compiled with GCC. To be fair, a disproportionate amount of the
   difference is because GNU Fortran can optimize <literal>548.exchange2_r</literal> much better
   than LLVM (see <xref linkend="fig-gcc14-specint-ofast-vsllvm-geomean" xrefstyle="template:figure
   %n"/>). Given that the LLVM Fortran front-end is relatively new and the optimization
   opportunities in this particular benchmark are quite specific, the result may not be relevant
   for many users.</para>

   <figure xml:id="fig-gcc14-specint-ofast-vsllvm-exchange">
    <title>Runtime performance (bigger is better) of 548.exchange2_r benchmarks built with Clang 19
     and GCC 14.2</title>
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="gcc14-specint-ofast-vsllvm-exchange.svg" width="90%" format="SVG"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="gcc14-specint-ofast-vsllvm-exchange.svg" width="90%" format="SVG"/>
     </imageobject>
    </mediaobject>
   </figure>

   <figure xml:id="fig-gcc14-specint-ofast-vsllvm-indiv">
    <title>Runtime performance (bigger is better) of C/C++ integer benchmarks built with Clang 19
     and GCC 14.2</title>
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="gcc14-specint-ofast-vsllvm-indiv.svg" width="90%" format="SVG"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="gcc14-specint-ofast-vsllvm-indiv.svg" width="90%" format="SVG"/>
     </imageobject>
    </mediaobject>
   </figure>

   <para>
    <xref linkend="fig-gcc14-specint-ofast-vsllvm-indiv" xrefstyle="template:Figure %n"/> shows
    relative rates of integer benchmarks written in C/C++ and the compilers perform fairly similarly
    there. GCC wins by a significant margin on <literal>505.mcf_r</literal>,
    <literal>531.deepsjeng_r</literal> and <literal>500.perlbench_r</literal> but clearly loses when
    compiling <literal>525.x264_r</literal>. This is because the compiler chooses a vectorizing
    factor that is too large for the important loops in this video encoder. It is possible to
    mitigate the problem using compiler option
    <literal>-&#8288;mprefer-&#8288;vector-&#8288;width=128</literal>, with which it is only 9%
    slower than Clang/LLVM, as you can see in <xref
    linkend="fig-gcc14-specint-ofast-vsllvm-x264_128" xrefstyle="template:figure %n"/>.  Another
    option yielding similar runtime of the benchmark is to use masked vectorized epilogues by
    passing option <literal>–&#8288;param vect-partial-vector-usage=1</literal> to the compiler.  Note that
    PGO can substantially help in this case too. The upcoming version, GCC 15, aims to solve the
    problem without a need for extra options by producing multiple cascading vector
    epilogues.</para>

   <figure xml:id="fig-gcc14-specint-ofast-vsllvm-x264_128">
    <title>Runtime performance (bigger is better) of 525.x264_r benchmark built with Clang 19 and
     with GCC 14.2 using -mprefer-vector-width=128</title>
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="gcc14-specint-ofast-vsllvm-x264-128.svg" width="90%" format="SVG"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="gcc14-specint-ofast-vsllvm-x264-128.svg" width="90%" format="SVG"/>
     </imageobject>
    </mediaobject>
   </figure>

   <para> The comparison of geometric mean of scores of SPEC FPrate 2017 suite when built with the
   two compiler suites is depicted in <xref linkend="fig-gcc14-specfp-ofast-vsllvm-geomean"
   xrefstyle="template:figure %n"/>. The floating point benchmark suite includes many more Fortran benchmarks, 
    and it is clear that GCC has an advantage in having a mature optimization pipeline for this language. 
    This is particularly evident when compiling <literal>503.bwaves_r</literal>,
   <literal>519.lbm_r</literal> and <literal>527.cam4_r</literal> (see <xref
   linkend="fig-gcc14-specfp-ofast-vsllvm-indiv" xrefstyle="template:figure %n"/>). The comparison of
   performance of individual benchmarks also shows that the performance of
    <literal>538.imagick_r</literal> is substantially bigger when compiled with GCC 14.2 while
   Clang/LLVM has an edge when optimizing <literal>508.namd_r</literal> and
   <literal>544.nab_r</literal>. </para>

   <figure xml:id="fig-gcc14-specfp-ofast-vsllvm-geomean">
    <title>Overall performance (bigger is better) of SPEC FPrate 2017 built with Clang 19 and GCC
    14.2</title>
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="gcc14-specfp-ofast-vsllvm-geomean.svg" width="100%" format="SVG"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="gcc14-specfp-ofast-vsllvm-geomean.svg" width="100%" format="SVG"/>
     </imageobject>
    </mediaobject>
   </figure>

   <figure xml:id="fig-gcc14-specfp-ofast-vsllvm-indiv">
    <title>Runtime performance (bigger is better) of floating point benchmarks built with Clang 19
     and GCC 14.2</title>
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="gcc14-specfp-ofast-vsllvm-indiv.svg" width="90%" format="SVG"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="gcc14-specfp-ofast-vsllvm-indiv.svg" width="90%" format="SVG"/>
     </imageobject>
    </mediaobject>
   </figure>

   <!-- ICX -->

   <para>Although Intel compilers are not designed for AMD processors, they are well-known 
    for their high-level optimization capabilities, particularly in vectorization. Therefore, we have 
    traditionally included ICC in our comparisons of compilers. Recently, however, Intel decided 
    to discontinue this compiler and redirect its users toward ICX, a new compiler built on top of LLVM. 
    In consequence, we have also shifted our focus to ICX. To keep the amount of data presented 
    in this section manageable, we will focus on comparing only binaries built with LTO
    <literal>-&#8288;Ofast</literal> and <literal>-&#8288;march=native</literal>.</para>

   <figure xml:id="fig-gcc14-specint-ofast-vsicx-geomean">
    <title>Overall performance (bigger is better) of SPEC INTrate 2017 built with ICX 2025.0.1 and
    GCC 14.2</title>
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="gcc14-specint-ofast-vsicx-geomean.svg" width="85%" format="SVG"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="gcc14-specint-ofast-vsicx-geomean.svg" width="85%" format="SVG"/>
     </imageobject>
    </mediaobject>
   </figure>

   <para>
    <xref linkend="fig-gcc14-specint-ofast-vsicx-geomean" xrefstyle="template:Figure %n"/> shows
    that the new ICX compiler takes the lead in overall SPEC INTrate assessment. The results of
    individual benchmarks (see <xref linkend="fig-gcc14-specint-ofast-vsicx-indiv"
    xrefstyle="template:figure %n"/>), however, illustrate that the majority of the lead is due to
    one benchmark, <literal>525.x264_r</literal>, and for the same reasons we outlined when
    discussing LLVM/Clang results. GCC picks too large vectorizing factor and the mitigation is
    again using <literal>-&#8288;mprefer-&#8288;vector-&#8288;width=128</literal> which leads to a
    much narrower gap (see <xref linkend="fig-gcc14-specint-ofast-vsicx-x264_128"
    xrefstyle="template:figure %n"/>). When looking at the other benchmarks (see <xref
    linkend="fig-gcc14-specint-ofast-vsicx-indiv" xrefstyle="template:figure %n"/>), GCC achieves
    comparable results. In fact, if we excluded benchmark <literal>525.x264_r</literal> from the
    computations of the geometric means, GCC would achieve a slightly better score than ICX in the
    LTO case.  At this point we want to re-iterate that the next version of GCC aims to solve
    this problem without a need for extra compiler options.  </para>

   <figure xml:id="fig-gcc14-specint-ofast-vsicx-indiv">
    <title>Runtime performance (bigger is better) of individual integer benchmarks built with ICX
    2025.0.1 and GCC 14.2</title>
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="gcc14-specint-ofast-vsicx-indiv.svg" width="90%" format="SVG"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="gcc14-specint-ofast-vsicx-indiv.svg" width="90%" format="SVG"/>
     </imageobject>
    </mediaobject>
   </figure>

   <figure xml:id="fig-gcc14-specint-ofast-vsicx-x264_128">
    <title>Runtime performance (bigger is better) of 525.x264_r benchmark built with ICX 2025.0.1
    and with GCC 14.2 using -mprefer-vector-width=128</title>
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="gcc14-specint-ofast-vsicx-x264-128.svg" width="90%" format="SVG"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="gcc14-specint-ofast-vsicx-x264-128.svg" width="90%" format="SVG"/>
     </imageobject>
    </mediaobject>
   </figure>

   <para>If we look at the geometric means that the two compilers can achieve when they are used to
   build SPEC FPrate suite, GCC wins by 17% or 19% without and with LTO respectively (see <xref
   linkend="fig-gcc14-specfp-ofast-vsicx-geomean" xrefstyle="template:figure %n"/>).  Even in this
   case it is important to look at individual results though as the overall picture is more nuanced
   (see <xref linkend="fig-gcc14-specfp-ofast-vsicx-indiv" xrefstyle="template:figure %n"/>).  There
   are benchmarks where GCC is much better (most prominently <literal>538.imagick_r</literal> and
   <literal>554.roms_r</literal>) but there are also those where the competition produces
   considerably faster code (especially <literal>519.lbm_r</literal> and
   <literal>544.nab_r</literal>).  Nevertheless, the conclusion is that GCC manages to perform
   consistently and competitively against these high-performance compilers.</para>

   <figure xml:id="fig-gcc14-specfp-ofast-vsicx-geomean">
    <title>Overall performance (bigger is better) of SPEC FPrate 2017 built with ICX 2025.0.1 and
    GCC 14.2</title>
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="gcc14-specfp-ofast-vsicx-geomean.svg" width="85%" format="SVG"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="gcc14-specfp-ofast-vsicx-geomean.svg" width="85%" format="SVG"/>
     </imageobject>
    </mediaobject>
   </figure>

   <figure xml:id="fig-gcc14-specfp-ofast-vsicx-indiv">
    <title>Runtime performance (bigger is better) of individual floating point benchmarks built with
     ICX 2025.0.1 and GCC 14.2</title>
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="gcc14-specfp-ofast-vsicx-indiv.svg" width="90%" format="SVG"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="gcc14-specfp-ofast-vsicx-indiv.svg" width="90%" format="SVG"/>
     </imageobject>
    </mediaobject>
   </figure>

  </sect2>
 </sect1>


 <?pdfpagebreak style="sbp" formatter="fop"?>

 <xi:include href="sbp-legal-notice.xml"/>


 <?pdfpagebreak style="sbp" formatter="fop"?>
 <xi:include href="license-gfdl.xml"/>
</article>
