== About This Document

This document describes how to design and build a large and scalable
private cloud to provide *Infrastructure as a Service* (IaaS) based on
open source products and open APIs. Private cloud setups are advantageous
for both Internet service providers and customers, in comparison to
conventional IT setups. From a customer's point of view, running their own
workload inside a public cloud allows for agility and flexibility.
For service providers, public cloud setups leverage the principle of 
_economy of scale_. This means that even with a growing demand, it remains
easy and convenient to serve customers.

Together, by means of a public cloud environment, customers and
providers create an integrated and optimized enterprise and
accelerate digital transformation across the business.

Large scale cloud platforms are designed and built to fulfill the requirements
of a modern and future-proof data center. In such an environment, applications
are created on virtual machines or container-based, highly automated and with a 
ast life-cycle (DevOps approach), and are not limited to specific uses cases.

This document provides an overview of the architecture and key aspects of
an IaaS platform based on SUSE products and is specifically designed and
targeted for cloud native workloads running in a large environment. The
architecture is based on real world implementations that have been
deployed at scale with enterprise customers and utilises best practices
from these setups.

=== Cloud Primer

The term _Cloud_ is present everywhere in the IT industry. However, it
is important to define the term _Private Cloud_ as it is used throughout
this document.

// Cloud still has not been defined here. Should we define it for the writer?

==== Cloud Computing and Conventional Setups

Most conventional IT setups share the same basic design tenets; typically they
are customer-specific. This means they were built for a certain
customer and only upon said customer's request. Conventional
setups do not share resources with other setups, all resources present
in a conventional IT setup are made available to the customer for
whom the setup was originally created only.

Conventional IT setups come with a number of disadvantages for both the
Internet Service Provider (ISP) and the customer. The most important aspects are listed below:

- Conventional setups come with long lead times, as they need to be
  planned and the required hardware must then be acquired. This can take
  several weeks.

- Conventional setups come with high investment costs to customers
  for both the development of an actual software solution and the
  acquisition of hardware (including infrastructure hardware such as
  network switches or load-balancers).

- Conventional setups tend to see service providers locking customers
  into a contract for several years, limiting the flexibility of the
  customer.

- Conventional setups have a low degree of automation. They
  require several manual steps to be performed both by the customer and the
  ISP.

The concept of _Cloud Computing_ was introduced several years ago
as a way to deal with the disadvantages of conventional setups. Clouds
enforce a certain role shift, especially from the service provider's
point of view. Instead of serving individual customers with solutions
tailor-made to their demands, a cloud setup turns the service provider
into a platform provider. A cloud provider's main responsibility
is to run and maintain a platform that makes computing, storage, and
network resources available dynamically and on an on-demand principle to
customers.

The following list contains a number of factors that are very basic
design tenets of clouds:

- Cloud environments allow for seamless scale-out of the platform. This means 
  in case of resource shortage, it is easy for the provider to
  extend the amount of available resources.

- Cloud environments are based on the principle of API services
  and the ability to issue requests for resources to said API services
  using a defined and well-known protocol such as ReST. Using such APIs,
  services can be implemented in clouds.

- Cloud environments decouple hardware and software and use Software
  Defined Networking (SDN) and Software Defined Storage (SDS). Because
  all core functionality is written in software and exists inside the
  platform itself, the manual configuration of infrastructure
  hardware such as networking switches becomes unnecessary.

- Cloud environments allow customers to service themselves based
  on SDN, SDS, and the aforementioned APIs.

- Cloud environments come with a higher level of automation from
  both the customers' and the provider's point of view. This saves
  time on tasks that, in conventional setups, need to be done manually.

Running a public cloud forces an ISP to transform their business. Rather than
providing individual services to individual customers, they can use a public cloud
that provides an overarching platform that customers are free to use at their own
discretion.

==== OpenStack as Base for the Cloud

By using software built for the sole purpose of running public clouds,
ISPs improve the level of automation and standardization in their platform. Combined with
additional tools the OpenStack cloud computing platform allows enterprises
to launch a public cloud product quickly and conveniently. Over the last few years,
OpenStack has become the number one open source solution to run public clouds
all over the world.

Some of the key features of the OpenStack cloud computing software are as follows:

- OpenStack has a well-proven track record of being the perfect solution
  for large public cloud environments. Organizations such as CERN, the European Organization
  for Nuclear Research, or SAP use OpenStack for their cloud platforms.

- OpenStack has the principle of well-documented, standardized, open APIs
  at the heart of its concept. This allows users to leverage the full power
  of the API principle.

- OpenStack is open source software licensed under the terms of the
  Apache License. This effectively helps avoid vendor lock-in that
  comes along with most commercial products. Because COTS (Commercial
  off-the-shelf) hardware can be used, there is also no vendor lock-in on the
  hardware side.

- OpenStack does not require an ISP to trust the manufacturer of a software
  product blindly. Because of its nature as an open source solution,
  the source code is open for everybody to audit and examine.

- OpenStack is not dominated by individual vendors but by the OpenStack
  Foundation, of which everybody can become a member.

- OpenStack, thanks to its large user and developer community, comes
  with a lot of useful components and features. These components make operating the
  cloud and using its features a convenient task.

- OpenStack supports multi-tenant setups. This effectively allows large
  numbers of customers to use one and the same cloud platform.

- OpenStack is made available by its developers to users free of charge,
  which results in extremely low initial setup costs. Also, license fees and
  license renewal costs do not apply.

The SUSE OpenStack Cloud product is based on the upstream OpenStack project. It enables the 
operator to smoothly deal with the complexitiy of the project and control the deployment, the daily operation and 
the maintanace of the platform. The integrated deployment tool allows for an easy setup and deployment of
the complex infrastructure. The professional support provided by SUSE ensures the provision of a stable and available platform,
turning an open source project in an enterprise grade software solution.

==== Scope Of This Document

The following paragraphs define the purpose of this document.

Based on best practices, this document describes the most basic
design tenets of a cloud environment built for massive scale-out and a
large target size. It does not provide specific implementation
details, such as the required configuration for individual components.
One objective of this document is to outline which decisions during the design
phase are important  for the creation of a scalable future proof cloud architecture.

As the details for such a design depend on a lot of parameters, this 
document cannot provide a one-size-fits-all solution. Examples 
show possibilities and options, and can help you design your own solution.

As such, this document does explicitly not aim to replace any official SUSE product 
documentation provided at https://www.suse.com/documentation. There are various
reference documents available for SUSE OpenStack Cloud, SUSE
Enterprise Storage or SUSE Linux Enterprise Server, infrastructure management
solutions or patch concepts like SUSE Manager or the Subscriptions Management
Tool, and SUSE Linux Enterprise Linux High Availability Extension. In addition to
this guide, we recommend referring to the official documentation applicable to
your respective setup.

For implementation-specific documentation, refer to the
documentation at https://www.suse.com/documentation. SUSE has provided
documentation prevelant to the deployment, administration, and usage for
SUSE Enterprise Storage and SUSE OpenStack Cloud.

Details specific to a specific customer, a specific environment, or a specific
business case are determined by the customer and SUSE during a _Design
and Implementation Workshop_. See also section <<Implementation_Phases>>. This
document does not deal with specific details.

=== Target Audience

The target audience of this guide are decision makers and application,
cloud, and network architects. After reading this document, you should 
be able to understand a basic architecture of large scale clouds and how clouds 
can be used to solve your respective business challenges.

OpenStack, thanks to its versatility and flexibility, allows for all operation
models. This document focuses on the provider point-of-view and explains
how customers can use SUSE OpenStack Cloud to build seamlessly scalable,
large cloud environments for IaaS services.

==== IaaS, PaaS, Serverless: Operation Models for Applications in Clouds

In cloud environments, providers typically have different offerings for
different requirements on the customers' side. These are
referred to as "as-a-Service" offerings, such as Infrastructure as a
Service (IaaS), Platform as a Service (PaaS) or Software as a Service (SaaS).
In recent times, the term "serverless computing" is also commonly used.

All these terms describe models to operate particular environments and
applications inside a cloud computing environment. They differ when it
comes to defining the provider's and the customer's responsibilities for
running the platform.

- *Infrastructure as a Service*: The provider's sole job is to run
  and operate the platform to provide customers with arbitrary amounts
  of compute, storage, and network resources. Running and managing actual
  applications in the platform is the responsibility of the customer.

- *Platform as a Service*: In a PaaS setup, the provider does not only
  offer virtual compute, storage, and network resources, but also several
  integration tools to combine them properly. For example, users needing
  a database can acquire a database with a few mouse clicks as result of
  a Database as a Service (DBaaS) offering instead of having to set up a database
  in a virtual machine themselves.

- *Software as a Service*: This operation model describes a design where
  the cloud provider takes care of running the virtual machines and the
  actual application for the customers (which is why in a certain way,
  this operation model resembles "managed services" from the conventional
  world). The user is only consuming the service and does not care about
  the used infrastructure.

.IT service consumation variants 
image::it-service-consumation-basics_v2.svg[align="center",width=400]

==== Private, Public, Hybrid

There are three ways for customers to consume services provided by cloud
setups:

- *Private Cloud*: A private cloud is run internally by a company for own
  purposes only. It is not available for usage to the public.

- *Public Cloud*: A public cloud environment is run by a company to offer
  compute, storage, and network resources to the wide public, often giving
  users the opportunity to register an account themselves and start using
  the cloud services immediately.

- *Hybrid Cloud*: When following a hybrid cloud approach, customers use
  services offered by public cloud environments (such as Amazon AWS or
  Microsoft Azure) as well as services offered by an own private cloud.

The cloud setup described in this guide can serve as a public
cloud or a private cloud. Hybrid considerations are, however, not within
the scope of this document.

.Hybrid environments combine the advantages of public and private clouds.
image::hybrid-computing.png[align="center",width=400]

==== Compute, Storage, Network

The three main aspects of IaaS are compute, storage, and networking. These aspects
deserve a separate discussion in the context of a large cloud environment.
This technical guide elaborates on all factors separately in
the respective chapters. The minimum viable product assumed to be
the desired result is a virtual machine with attached block-storage that
has working connectivity to the Internet, with all of these components
being provided virtualized or software-defined.

=== The Design Principles

Although every business is unique and every customer implementation comes with 
different requirements, there is a small set of basic requirements that all cloud
environments have in common.

To build your IaaS solution, you need at least these resources:

- Hardware (standard industry servers, Commercial off-the-shelf [COTS])
to run the cloud, control servers, admininstration servers, and host storage.
Commodity hardware (one or two different types for the whole platform)
is used for cost efficiency.

- Standard OSI Layer 2 network hardware

- Open source software to provide basic cloud functionality to implement
the IaaS offering, including SDN, the operating system for said servers
and a solution for SDS.

==== Design Principles, Goals and Features

The following list describes the basic design tenets that were taken
into consideration while designing the highly scalable cloud that is
the subject of this guide.

- Scalability: At any point in time, it must be possible to extend the
  cloud's resources by adding additional nodes for compute or storage
  purposes.

- Resiliance: The cloud service must be robust and fault-tolerant. A concept
  for high availability must be in place. 

- Standardization: Open standards, open source software, open APIs that
  are well documented and commodity hardware (COTS) allow for high
  flexibility and help to avoid vendor lock-in.

- The old world and the new world: The platform must be able to handle
  cloud-native applications and traditional or legacy workloads,
  with a clear focus on cloud-native applications. 

Some examples for typical workloads are:

- Traditional root VMs (hosted)
- Orchestrated applications (cloud optimized)
- Cloud-native workloads, for example BOSH (to deploy a Cloud Foundry PaaS
  solution)
- Container-based solutions

.Container-based workloads such as the SUSE CaaS Platform work perfectly on top of cloud environments
image::container-on-top.png[align="center",width=300]

==== Workload Types for Cloud Environments

Cloud computing has fundamentally changed the way how applications are
rolled out for production use. While conventional applications typically
follow a monolithic approach, modern applications built according to
agile standards are based on numerous small components, these are called
"micro services". This document refers to conventional applications as
"traditional" and to applications following the new paradigm as "cloud-native".

There are, however, applications or workloads that do not fit perfectly
into either of these categories, effectively creating a gray area in
which special requirements exist. Traditional applications (for example legacy
workloads, sometimes also referred to as 'pets' or 'kitten') are for
sure not to disappear anytime soon. Any given IaaS platform
must be able to deal with traditional workloads, and of course also with
cloud-native workloads. The necessity to store data permanently is one
of the biggest challenges in that context.

An IaaS platform such as SUSE OpenStack Cloud is
optimized for cloud-native workloads and allows these to leverage the
existing functionality the best possible way. Running such cloud-native
workloads on a SUSE OpenStack Cloud platform means the following for the service:

* Stateless: The service stores no local data and can be restarted at any time. All data has to be stored externally in an data store.
* Automated: The installation of the server is automated and no manual configuration is needed.
* Scale out: More performance of the application can be achieved by starting (adding) new instances.
* Availability: The availability of a service depends on his redundancy.

Applications that do not follow the cloud-native approach work in
a public cloud environment but do not leverage most of the platforms'
features. SUSE OpenStack Cloud offers an option to 
include hypervisors also in a high-availability configuration. A failure of a hypervisor 
is detected and the failed instances are restarted on remaining hypervisors.
This helps to operate traditional workloads in a cloud-native optimized environment.


=== Business Drivers and Use Cases

Businesses in differing industries and application segments are enforcing
the adoption of cloud principles in their environments. While the
reasons for that are as diverse as the customers requirements themselves, there are a
few common goals that most enterprises share. The main motivation is the
need:

- For more flexibility in the own IT setup.
- For a higher level of automation.
- For competitive innovation.
- For lower times-to-market when creating new products and applications.
- For the migration of legacy application and workloads.
- To identify disposable components in the own environment.
- To accelerate the own growth and performance.
- To reduce IT costs (CAPEX/OPEX).

All these factors play a vibrant role in the decision to deliver services
in a cloud-native manner and move more applications to the cloud.

=== Bimodal IT

Modern IT companies have developed a way of working that allows them to
be agile and quick when developing new features and yet protect existing
processes and systems. This can be crucial for a company. 
Often, such legacy processes and systems cannot be
replaced at ease or at all. By following such a model of two speeds,
being agile and innovative on the one hand and protecting existing and
critical infrastructure at the other hand, companies can meet the needs
of today's fast-paced IT industry. This is what many refer to as "Bimodal
IT".

In said scheme, Mode 1 is responsible for providing enterprise-class IT
at constant speeds (traditional workloads, "legacy") and Mode 2 is to
develop and deliver cloud-native applications using principles such as Continuous Integration
(CI) and Continous Delivery (CD) at high velocity. Successful companies deliver
both items in an optimized way. The IaaS platform outlined in
this document supports companies by being a solution for both needs. The
companies deploying such a solution benefit from the following:

- A highly cost-effective, rapidly responsible and elastic IT that is
  very well aligned with its actual businees needs to support
  the bimodal IT operations model.

- A large portfolio of business and IT services that effectively
  leverage the best features provided by the underlying IaaS solution,
  allowing for seamless flexibility (applications can be built exactly
  as necessary and run wherever they are required).

- The ability to map business processes to applications.

- The ability to innovate faster while leveraging already-existing
  servers and capabilities, allowing for very short times-to-market.

==== Cloud Use Cases

This document explains how service providers for private or public clouds build and operate a cloud
designed to meet the needs of both Mode 1 and Mode 2 IT environments. Possible ways
to use an environment like the one described in this document are:

- The provisioning of an IaaS layer for enterprise and cloud providers
- PaaS and SaaS offerings.
- Allowing Cloud Service Providers (CSP) the ability to use, market, and
  sell their own services on top of an existing IaaS layer.
- The increase of automation in their own environment based on the cloud
  orchestration services.
- Provisioning infrastructure for DevOps and agile environments.

Each of the mentioned scenarios however has a specific business case behind 
it. This means that companies need to decide on the solution 
they want to provide before building out. Depending on the use case, 
there are minimal differences that lead to great effects when the solution 
is in place. Even smallest design decisions directly influence how well the 
platform is suited for what it is expected to do. Getting help from experts 
on this subject is recommended.

==== SLA Considerations

When you plan a cloud environment and determine your use case, take into account 
as early as possible the Service Level Agreement (SLA) that the platform is expected
to be delivered on. To define a proper 
SLA, the functionality of the platform must be clear and understood. 
The provider running the cloud also has to define what kind of 
provider they want to be. As an example, all major public cloud providers 
clearly distinct between their work (which is providing a working platform) 
and anything that the customers might do on it. For the latter part of the 
work, the customer bears the sole responsibility.

Of course, the answer to this question also depends on the kind of cloud
that is supposed to be created. Private clouds constructed for specific
use cases face other requirements than large clouds made
available to the public.

NOTE: A cloud takes the control services in the focus
of the SLA. The running workload on top of a hypervisor is in the 
responsibility of the user - and mostly not part of the SLA.
// vim:set syntax=asciidoc:
