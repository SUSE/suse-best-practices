
:docinfo:

= SAP Data Hub 2 on SUSE CaaS Platform 3: Installation Guide

++++
<?pdfpagebreak?>
++++

== Introduction

Today more and more data is created in business and industries. To the same extend as data grows the need grows to manage these data and get best out of them.
SAP Data Hub 2 is a tool that makes dealing with these amounts of data more easy. With SUSE Container as a Service (CaaS) Platform 3 SUSE delivers a perfect foundation to run SAP Data Hub 2 on top of it.

== Requirements

To install SAP Data Hub 2 on SUSE CaaS Platform 3 you need to meet certain requirements:

Relevant documentation:

* SUSE

** link:https://documentation.suse.com/suse-caasp/3/[SUSE CaaS Platform 3]
** link:https://documentation.suse.com/ses/5.5/[SUSE Enterprise Storage]

* SAP

** link:https://help.sap.com/viewer/product/SAP_DATA_HUB/2.5.latest/en-US[SAP Data Hub]
** link:https://launchpad.support.sap.com/#/notes/2764652[SAP Data Hub 2.5 release note]
** link:https://launchpad.support.sap.com/#/notes/2686169[Pre-requisites for installing SAP Data Hub]
** link:https://launchpad.support.sap.com/#/notes/2776522[SAP Data Hub 2: Specific Configurations for Installation on SUSE CaaS Platform]

=== Hardware and Software Requirements

==== SUSE CaaS Platform 3 Cluster

Hardware requirements (see https://help.sap.com/viewer/product/SAP_DATA_HUB/[SAP Data Hub Install Guide])
See SAP's sizing recommendations:

* link:https://help.sap.com/viewer/e66c399612e84a83a8abe97c0eeb443a/2.3.latest/en-US/79724de552db4b2b81c4a893f2c7ed18.html[SAP Data Hub 2.3 ]

* link:https://help.sap.com/viewer/e66c399612e84a83a8abe97c0eeb443a/2.4.latest/en-US/7e2a9bf62ec94e9694648e2b5d2ce882.html[SAP Data Hub 2.4]

* link:https://help.sap.com/viewer/e66c399612e84a83a8abe97c0eeb443a/2.5.latest/en-US[SAP Data Hub 2.5]

* link:https://help.sap.com/viewer/e66c399612e84a83a8abe97c0eeb443a/2.6.latest/en-US[SAP Data Hub 2.6]

The minimum hardware requirements for installing SAP Data Hub 2 on premise are:

* 4 Kubernetes cluster nodes (1 master node and 3 worker nodes)

   ** The master node should be a 4 core machine with > 32 GiB RAM

   ** The three Kubernetes worker nodes should be a machine with 4 cores and with > 64 GiB RAM
// TODO check network requirements
// TODO disk requirements

* Access to a SUSE Enterprise Storage 5 system (see SAP Note link:https://launchpad.support.sap.com/#/notes/2686169[Pre-requisites for installing SAP Data Hub])

==== Management ("Jump") Host

It is recommended to do the installation of SAP Data Hub Foundation from an external Jump host and not from within the SUSE CaaS Platform Cluster.

The hardware and operating system specifications for the jump host can be for example as follows:

- SUSE Linux Enterprise Server 12 SP4 or SUSE Linux Enterprise Server 15 (or even openSUSE Leap 15.X)
- 2 Cores
- 8 GiB RAM
- Disk space: 50 GiB for */*, including the space for the SAP Data Hub 2 software and at least 20 GiB for */var/lib/docker* (needed for the SAP Data Hub 2 installation)
- Network connectivity to the SUSE CaaS Platform cluster (1 GBit/s)

=== Software Requirements

The following software is needed

* SUSE CaaS Platform 3

* SAP Data Hub 2

* optional: SAP Maintenance Planner

* optional: SAP Host Agent

* optional: Hadoop/Spark (see Vora's Spark extensions)


== Installation of SUSE CaaS Platform 3

=== Get the Installation Media

All installation media can be found at:
link:++https://download.suse.com++[SUSE CaaS Platform ISO images]

=== Get a Subscription for SUSE CaaS Platform 3

To get all maintenance updates for your SUSE products you need a valid subscription for the respective products.
https://www.suse.com/support/?id=SUSE_CaaS_Platform[Order subscription for SUSE CaaS Platform]
example

=== Read the Deployment Guide for SUSE CaaS Platform 3

SUSE CaaS Platform is designed to make the installation of Kubernetes easy. To get a deeper understanding of how it works, you should read the Deployment Guide for SUSE CaaS Platform 3, available at https://documentation.suse.com.
For further reference a Quick Start Guide and an Administrator's Guide are available as well.

=== Installation of SUSE CaaS Platform 3

The document at hand describes the installation of SUSE CaaS Platform 3 from ISO images.
Make sure that the host names you will use for the installation are resolvable via DNS.
A static network setup is preferred.

Have the FQDN or IP address of your time server available. A reliable system time is required.
Connect the media to your hardware and boot from the media.
// Screenshot?

Choose *Installation* from the GRUB menu.

==== Installation of the Admin Node
// Add Pictures

After booting the hardware the YaST installer opens the network configuration dialog.


image::002-SCT-CaaSP.png[title="Network Configuration Admin Node",480,640,scaledwidth=80%,align=center]

The next screen shows the installation overview dialog.

image::007-SCT-CaaSP.png[title="Installation Overview Admin Node",480,640,scaledwidth=80%,align=center]

On the installation screen select the keyboard layout and language according to your needs.
Enter your subscription credentials or the URL of your Subscription Management Tool (SMT) server to register your installation.
Set the password for the root account.

Assign the role _administration host_ to your installation.


// Screen Shots????


==== Installation of Remaining Cluster Nodes

Boot the machine from the ISO image and select *Installation* from the GRUB2 boot menu.

The installer starts and the network configuration dialog is shown.

image::002-SCT-CaaSP.png[title="Network Configuration Cluster Nodes",480,640,scaledwidth=80%,align=center]


Again, configure the network according to your needs.

The next screen shows the installation overview dialog.

image::021-SCT-CaaSP.png[title="Installation Overview Cluster Node",480,640,scaledwidth=80%,align=center]

//TODO Screenshots

==== Bootstrap of the Kubernetes Cluster

After the installation of the admin node, open your browser and visit
https://name.domain.tld.

image::015-SCT-CaaSP.png[title="Velum",480,640,scaledwidth=80%,align=center]

Create the admin account and set the admin user name and password.
Log in with the newly created admin credentials.

image::014-SCT-CaaSP.png[title="Velum login",480,640,scaledwidth=80%,align=center]

Configure SUSE CaaS Platform 3.

image::016-SCT-CaaSP.png[title="Velum Cluster Configuration",480,640,scaledwidth=80%,align=center]

Select the nodes to be included in the cluster.

image::024-SCT-CaaSP.png[title="Select Nodes and Roles 1",480,640,scaledwidth=80%,align=center]

Assign roles (master/worker) according to your needs.

image::027-SCT-CaaSP.png[title="Select Nodes and Roles 2",480,640,scaledwidth=80%,align=center]

image::028-SCT-CaaSP.png[itle="Select Nodes and Roles 3",480,640,scaledwidth=80%,align=center]

Bootstrap the Kubernetes cluster.

image::030-SCT-CaaSP.png[title="Confirm Bootstrap",480,640,scaledwidth=80%,align=center]

After a successful bootstrap, the screen below is shown.

image::032-SCT-CaaSP.png[title="Cluster Status Nodes",480,640,scaledwidth=80%,scaledwidth=80%,align=center]



==== Installation of the Jump Host

For further configuration and deployments on SUSE CaaS Platform it is highly recommended to install a jump or management host.
This chapter describes the installation of the necessary tools to be able to deploy SAP Data Hub 2 on the SUSE CaaS Platform environment.

Install SUSE Linux Enterprise Server 12 SP4+ or SUSE Linux Enterprise Server 15 as operating system on the jump host.
Register your installation against the SUSE Customer Center (SCC) or your local SMT or Repository Mirroring Tool (RMT).
Register the Container Module included in the SUSE Linux Enterprise Server subscription.

----
# SUSEConnect -p /x86_64/SLE-Container-Module
----

Install Docker from the Container Module:

----
# zypper in docker
----

Download *kubectl* matching the Kubernetes version of your SUSE CaaS Platform installation.
Download *kubectl 1.10.11* or higher.

----
$ curl -LO https://storage.googleapis.com/kubernetes-release/release/v1.10.11/bin/linux/amd64/kubectl
$ sudo mv kubectl /usr/bin/kubectl
$ sudo chmod a+x /usr/bin/kubectl
----

Download *kubectl-configuration* from the Velum-Dashboard.

image::032a-SCT-CaaSP.png[title="kubeconfig 1",480,640,scaledwidth=80%,align=center]

image::033-SCT-CaaSP.png[title="kubeconfig 2",480,640,scaledwidth=80%,align=center]

image::034-SCT-CaaSP.png[title="kubeconfig 3",480,640,scaledwidth=80%,align=center]

----
$ export KUBECONFIG=<PATH/TO/YOUR/kubeconfig-file>/kubeconfig
----

or

----
$ mv <PATH/TO/YOUR/kubeconfig-file>/kubeconfig ~/.kube/config
----


Connect to your Kubernetes cluster using *kubectl*.

----
$ kubectl get cluster-info
$ kubectl get nodes
----


The output of the commands above should look similar to this:

----
OUTPUT //TODO
----

Download Helm from *helm.sh*. Install and configure the Helm client.
The version should match the tiller version deployed on your SUSE CaaS Platform installation.

----
$ curl https://raw.githubusercontent.com/helm/helm/master/scripts/get > get_helm.sh
$ chmod 700 get_helm.sh
$ ./get_helm.sh --version 2.8.2
$ mv helm ~/bin/helm
$ helm init --client-only
----


==== Optional Components Deployed in the SUSE CaaS Platform 3 Cluster

You can also deploy some useful optional applications in your SUSE CaaS Platform 3 cluster:

* Heapster (creates simple graphics)

* Kubernetes dashboard (allows administration and basic monitoring of the Kubernetes cluster)


See also https://www.suse.com/documentation/suse-caasp-3/book_caasp_admin/data/book_caasp_admin.html

Installation of Heapster:

----
$ helm install --name heapster-default --namespace=kube-system stable/heapster \
--version=0.2.7 --set rbac.create=true
----

Installation of the Kubernetes dashboard:

----
$ helm install --namespace=kube-system \
--name=kubernetes-dashboard stable/kubernetes-dashboard \
--version=0.6.1
----

To authenticate against the Kubernetes cluster extract the *id-token* from the *kubeconfig* file.
----
$ grep id-token $KUBECONFIG | awk '{ print $2 }'
----

----
$ kubectl proxy
----

Point your browser to
----
http://127.0.0.1:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/
----

Use the ID grep'ed from *kubeconfig* to log in to the Kubernetes dashboard.



== Installation of SAP Data Hub 2

The following sections describe the preparation and installation of SAP Data Hub 2 on the SUSE CaaS Platform 3 Cluster.


=== Prepare the SAP Data Hub 2 Installation

To install SAP Data Hub on SUSE CaaS Platform successfully, perform the actions detailed below. 


==== Download the SAP Data Hub 2 Software Archive

Go to the SAP Software Download Center, log in with your SAP account and search for SAP DATA HUB 2 or access this link.
Download the SAP Data Hub Foundation file, for example: DHFOUNDATION03_3-80004015.ZIP (SAP DATA HUB - FOUNDATION 2.3) or DHFOUNDATION04_0-80004015.ZIP (SAP DATA HUB - FOUNDATION 2.4


Unzip the software archive on to your jump host.

There are two ways to install the SAP Data Hub 2:

* Use the SL Plugin. There are two variants of doing so:

** SL Plugin with Maintenance Planner (mpsl)
** SL Plugin only (mpfree)

* Use the command line install.sh script. 

This document will focus on the latter installation method.



==== Prerequisites on the SUSE CaaS Platform 3 Cluster

If not stated otherwise, the following steps are done on the jump host.

Create the namespace in the Kubernetes cluster to install SAP Data Hub 2:

----
$ kubectl create namespace datahub
----

Create the storage class to provide volumes for SAP Data Hub 2 on SUSE Enterprise Storage.

Make sure you have the connection data for your SUSE Enterprise Storage at hand:

* IP addresses and port number (defaults to 6789) of the monitor nodes of your SUSE Enterprise Storage

* A data pool created (data hub in this example) on your SUSE Enterprise Storage for the use with SAP Data Hub 2

Edit the example below to fit your environment.

----
$ cat > storageClass.yaml <<EOF
apiVersion: storage.kubernetes.io/v1
kind: StorageClass
metadata:
  annotations:
    storageclass.kubernetes.io/is-default-class: "true"
  name: datahub
  namespace: default
parameters:
  adminId: admin
  adminSecretName: ceph-admin-secret
  adminSecretNamespace:  default
  imageFeatures: layering
  imageFormat: "2"
  monitors: <IP ADDRESS OF MONITOR 1>:6789, <IP ADDRESS OF MONITOR 2>:6789, <IP ADDRESS OF MONITOR 3 >:6789
  pool: datahub
  userId: admin
  userSecretName: ceph-user-secret
provisioner: kubernetes.io/rbd
reclaimPolicy: Delete
volumeBindingMode: Immediate
EOF

$ kubectl create -f storageClass.yaml
----

Create the secrets needed to access the storage:
From your SUSE Enterprise Storage obtain the keys located in
*ceph.admin.keyring* and *ceph.user.keyring*

You need to do a base64 encoding of the keys as follows:

----
echo <YOUR KEY HERE> | base64
----

----
$ cat > ceph-admin-secret.yaml <<EOF
apiVersion: v1
kind: Secret
metadata:
    name: ceph-admin-secret
type: "kubernetes.io/rbd"
data:
   key: <YOUR BASE64 ENCODED KEY HERE>
EOF
image::002-SCT-CaaSP.png
$ cat > ceph-user-secret.yaml <<EOF
apiVersion: v1
kind: Secret
metadata:
    name: ceph-user-secret
type: "kubernetes.io/rbd"
data:
   key: <YOUR BASE64 ENCODED KEY HERE>
EOF

$ kubectl create -f ceph-admin-secret.yaml
$ kubectl create -f ceph-user-secret.yaml
----

=== Installation of SAP Data Hub 2 Using the Maintenance Planner with SL Plugin (mpsl Method)

The installation method via SL plugin is a Web-based installation method recommended by SAP offering you an option to send analytics data and feedback to SAP. 
All necessary prerequisites are met by applying all the steps described above.

Note: You need to install the latest SAP Host Agent on the jump host. You can use the RPM package which can be downloaded from the SAP Software Download Center.


=== Installation of SAP Data Hub 2 Using the SL Plugin (mpfree Method)

The Installation of SAP Data Hub 2 using the SL plugin is an alternative command-line-based installation method. 
Refer to the SAP Data Hub documentation (2.3)) / (2.4) / (2.5) / (2.6) for more information and the exact procedure.
//TODO insert URLs


=== Installation of SAP Data Hub 2 Using the Command Line (Manual Installation)

Unpack the SAP Data Hub software archive on the jump host with the following command:

----
$ unzip DHFOUNDATION04_1-80004015.ZIP
----

Run the install command as described in SAP Data Hub 2 install guide at https://help.sap,com/datahub
// TODO URL help.sap.com/
https://help.sap.com/viewer/e66c399612e84a83a8abe97c0eeb443a/2.6.latest/en-US
----
$ cd SAP-Datahub-2.4.63-Foundation
$ export DOCKER_REGISTRY=<URI of your registry>
$ export NAMESPACE=datahub
$ ./install.sh
----

This interactive script configures the installation of SAP Data Hub.
You should have the following information at a hand:
//TODO namespace, login on registry, S-User

* Name and credentials of your SAP S-User 
* Login credentials to your secure registry

//TODO explain cmdline options


=== Post-Installation Actions

After successful installation you can connect to the SAP Data Hub Web UI.
You need to identify the service IP and port of the SAP Data Hub UI.

----
kubectl get services
kubectl describe service
----

Point your browser to the IP and port you received from the commands above.
// TODO Example.

Use the login data you defined during the installation.

==== Post-Installation Work

Follow the documentation provided by SAP (link) to the post installation work.

* Create the *vflow-secret* for the modeler app as pointed out in the SAP documentation.

* Import necessary CAs, for example the CA that signed the certificate of the secure registry.


== Upgrade of SAP Data Hub 2

This section describes the update of an existing SAP Data Hub 2 installation to a higher version (for example 2.3 to 2.4)

Execute the SAP Data Hub upgrade as described in the official instructions. You can choose between different upgrade methods:

* Maintenance Planner: Upgrade SAP Data Hub 2 using the Maintenance Planner / SL Plugin and SAP Host Agent (https://help.sap.com/viewer/e66c399612e84a83a8abe97c0eeb443a/2.6.latest/en-US/31079833a65f4f379d5a76957ff8073c.html)
* SL Plugin method: Upgrade SAP Data Hub 2 using the SL Plugin and SAP Host Agent (https://help.sap.com/viewer/e66c399612e84a83a8abe97c0eeb443a/2.6.latest/en-US/ff37f3ccf6504bb38d7db53936fe8017.html)
* Command line method: Upgrade SAP Data Hub 2 using the install.sh script (https://help.sap.com/viewer/e66c399612e84a83a8abe97c0eeb443a/2.6.latest/en-US/aec679bc0209443ba4ae03a9018d4bd8.html)


== Appendix


=== Secure Private Registry

To meet the Data Hub requirements you also need a Docker registry.
The easiest way to build and manage it is described with the project Portus.

** link:http://port.us.org/[Portus]

First you need to create a dedicated server for your Docker registry and Portus stack.

----
# sudo virt-install --name portus-dr --ram 8192 --disk path=/var/lib/libvirt/VMS/portus-dr.qcow2,size=40 --vcpus 4 --os-type linux --os-variant generic --network bridge=common --graphics none --console pty,target_type=serial --location '/var/lib/libvirt/isos/SLE-12-SP4-Server-DVD-x86_64-GM-DVD1.iso' --extra-args 'console=ttyS0,115200n8 serial ifcfg=eth0=10.10.10.11/24,10.10.10.1,10.10.10.11,suse-sap.net hostname=portus-dr domain=suse-sap.net Textmode=1'
----

In our example this server will be connected to another local bridge which provides common services (DNS, SMT, Docker-registry) for the Data Hub stack.

Our Portus deployment is based on container, and orchestrated locally with *docker-compose*.

Portus *docker-compose* deployment requires an up-to-date release of *docker-compose*.

----
sudo curl -L "https://github.com/docker/compose/releases/download/1.24.1/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose
sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose
----

Now you can simply clone the Portus repository. Adapt the *.env* and the *nginx* configuration to your naming convention.

----
# git clone https://github.com/SUSE/Portus.git /tmp/Portus-DR
# mv /tmp/Portus-DR/examples/compose ./portus
# cd portus
----

Edit both *.env* and *nginx/nginx.conf*.
As an example, this is how our configuration looks like :

----
# cat .env
MACHINE_FQDN=portus-dr.suse-sap.net
SECRET_KEY_BASE=b494a25faa8d22e430e843e220e424e10ac84d2ce0e64231f5b636d21251
eb6d267adb042ad5884cbff0f3891bcf911bdf8abb3ce719849ccda9a4889249e5c2
PORTUS_PASSWORD=XXXXXXXX
DATABASE_PASSWORD=YYYYYYYY
----

In the *nginx/nginx.conf* file, adapt the following section:

----
server {
    listen 443 ssl http2;
    server_name portus-dr.suse-sap.net;
    root /srv/Portus/public;
----

Now, you can pull the latest *docker-compose.yml*.

----
# rm docker-compose.*
# wget https://gist.githubusercontent.com/Patazerty/d05652294d5874eddf192c9b633751ee/raw/6bf4ac6ba14192a1fe5c337494ab213200dd076e/docker-compose.yml
----

To avoid dealing with Docker insecure registry configuration add SSL to your setup.

----
echo "subjectAltName = DNS:portus-dr.suse-sap.net" > extfile.cnf
openssl genrsa -out secrets/rootca.key 2048
openssl req -x509 -new -nodes -key secrets/rootca.key -subj "/C=FR/ST=FR/O=SUSE"  -sha256 -days 1024 -out secrets/rootca.crt
openssl genrsa -out secrets/portus.key 2048
openssl req -new -key secrets/portus.key -out secrets/portus.csr -subj "/C=FR/ST=FR/O=SUSE/CN
openssl req -new -key secrets/portus.key -out secrets/portus.csr -subj "/C=FR/ST=FR/O=SUSE/CN=portus-dr.suse-sap.net"
openssl x509 -req -in secrets/portus.csr -CA secrets/rootca.crt -extfile extfile.cnf -CAkey secrets/rootca.key -CAcreateserial  -out secrets/portus.crt -days 500 -sha256
----

Make the servers aware of the new certificate:

----
cp -p secrets/rootca.crt /etc/pki/trust/anchors/.net-ca.crt
scp secrets/rootca.crt root@jumpbox.suse-sap.net:/etc/pki/trust/anchors/portus-dr.suse-sap.net-ca.crt
----

Update the certificate on all servers that will need to interact with the Docker registry:

----
sudo update-ca-certificates
sudo systemctl restart docker
----

Start your Portus setup with the following command:

----
docker-compose up -d
----

Log in to Portus and set the registry as shown below.

image::portus-registry.png[title="Portus Registry",480,640,scaledwidth=80%,align=center]

To install and configure a secure private registry using SUSE Linux Enterprise Server with the Container Module
the needed componentes are Docker, registry and Portus.
Create SSL certificates as needed. Distribute the CA certificate to all your kubernetes nodes.
Run the command:

----
# update-ca-certificates
# systemctl restart docker
----


Create the name spaces on your registry that are needed for SAP Data Hub 2:

* com.sap.hana.container

* com.sap.datahub.linuxx86_64

* com.sap.datahub.linuxx86_64.gcc6

* consul

* elasticsearch

* fabric8

* google_containers

* grafana

* kibana

* prom

* vora

* kaniko-project

* com.sap.bds.docker


//TODO Liste der Namespaces


=== SUSE Enterprise Storage

//SAP Data Hub 2 installation on premise requires SUSE Enterprise Storage 5 or higher.
//Follow the installation documentation to create SUSE Enterprise Storage.
//Create a storage pool on your SES for the use with SAP Data Hub 2.
//You can also leverage the S3 API to create buckets on SES that can be used from applications from within SAP Data Hub 2.


An SAP Data Hub 2 installation on premise requires SUSE Enterprise Storage 5 or higher.
If you plan to use SUSE Enterprise Storage not only for your Kubernetes dynamic storage class but also for your Kubernetes Control plan, virtualized or not, you should reserve enough resources to address *etcd* requirements regarding
** link:https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/hardware.md.[etcd Hardware]

Follow the next steps to deploy a minimalist, virtualized, test oriented SUSE Enterprise Storage 5.5.

In the following example, we are going to build a 4 nodes (1 admin + 3 OSD) Ceph Cluster.

Before you start, be sure to:

* Collect your SUSE Linux Enterprise Server 12 SP3 and SUSE Enterprise Storage registration code from scc.suse.com. Alternatively, have an SMT/RMT properly set up and already mirroring theses products.

** link:https://scc.suse.com[SCC]
** link:https://documentation.suse.com/sles/12-SP4/html/SLES-all/book-smt.html[SMT]

image::scc-sle.png[title="SUSE Customer Center Products",480,640,scaledwidth=80%,align=center]
image::scc-ses.png[title="SUSE Customer Center Registration Code",480,640,scaledwidth=80%,align=center]

Your DNS zone should already be set. In our example where all Data Hub components are in the same DNS zone and subnet, it should look like the following:

image::dns.png[title="DNS Server",480,640,scaledwidth=80%,align=center]

Also, to be as efficient as possible when using interactive shell scripted infrastructure deployment, it is recommended to use an advanced terminal client or multiplexer which permits to address multiple shells at once.

image::multi-s-virtinstall.png[title="Advanced Terminal Client - Multi Shell",480,640,align=center]

----
# sudo virt-install --name ses55-admin --ram 16384 --disk bus=virtio,path=/var/lib/libvirt/VMS/ses55-admin.qcow2,size=40 --disk bus=virtio,path=/var/lib/libvirt/VMS/ses55-admin-osd0.qcow2,size=20 --disk bus=virtio,path=/var/lib/libvirt/VMS/ses55-admin-osd1.qcow2,size=20 --disk bus=virtio,path=/var/lib/libvirt/VMS/ses55-admin-osd2.qcow2,size=20 --disk bus=virtio,path=/var/lib/libvirt/VMS/ses55-admin-osd3.qcow2,size=20 --vcpus 4 --os-type linux --os-variant generic --network bridge=caasp3 --graphics none --console pty,target_type=serial --location '/var/lib/libvirt/ISOS/SLE-12-SP3-Server-DVD-x86_64-GM-DVD1.iso' --extra-args 'console=ttyS0,115200n8 serial autoyast-ses5=http://10.10.10.101/autoyast-ses5 ifcfg=eth0=10.18.10.200/24,10.18.10.1,10.10.10.11,suse-sap.net domain=suse-sap.net Textmode=1'

# sudo virt-install --name ses55-osd0 --ram 16384 --disk bus=virtio,path=/var/lib/libvirt/VMS/ses55-osd0.qcow2,size=40 --disk bus=virtio,path=/var/lib/libvirt/VMS/ses55-osd0-osd0.qcow2,size=20 --disk bus=virtio,path=/var/lib/libvirt/VMS/ses55-osd0-osd1.qcow2,size=20 --disk bus=virtio,path=/var/lib/libvirt/VMS/ses55-osd0-osd2.qcow2,size=20 --disk bus=virtio,path=/var/lib/libvirt/VMS/ses55-osd0-osd3.qcow2,size=20 --vcpus 4 --os-type linux --os-variant generic --network bridge=caasp3 --graphics none --console pty,target_type=serial --location '/var/lib/libvirt/ISOS/SLE-12-SP3-Server-DVD-x86_64-GM-DVD1.iso' --extra-args 'console=ttyS0,115200n8 serial autoyast-ses5=http://10.10.10.101/autoyast-ses5 ifcfg=eth0=10.18.10.230/24,10.18.10.1,10.10.10.11,suse-sap.net domain=suse-sap.net Textmode=1'

# sudo virt-install --name ses55-osd1 --ram 16384 --disk bus=virtio,path=/var/lib/libvirt/VMS/ses55-osd1.qcow2,size=40 --disk bus=virtio,path=/var/lib/libvirt/VMS/ses55-osd1-osd0.qcow2,size=20 --disk bus=virtio,path=/var/lib/libvirt/VMS/ses55-osd1-osd1.qcow2,size=20 --disk bus=virtio,path=/var/lib/libvirt/VMS/ses55-osd1-osd2.qcow2,size=20 --disk bus=virtio,path=/var/lib/libvirt/VMS/ses55-osd1-osd3.qcow2,size=20 --vcpus 4 --os-type linux --os-variant generic --network bridge=caasp3 --graphics none --console pty,target_type=serial --location '/var/lib/libvirt/ISOS/SLE-12-SP3-Server-DVD-x86_64-GM-DVD1.iso' --extra-args 'console=ttyS0,115200n8 serial autoyast-ses5=http://10.10.10.101/autoyast-ses5 ifcfg=eth0=10.18.10.231/24,10.18.10.1,10.10.10.11,suse-sap.net domain=suse-sap.net Textmode=1'

# sudo virt-install --name ses55-osd2 --ram 16384 --disk bus=virtio,path=/var/lib/libvirt/VMS/ses55-osd2.qcow2,size=40 --disk bus=virtio,path=/var/lib/libvirt/VMS/ses55-osd2-osd0.qcow2,size=20 --disk bus=virtio,path=/var/lib/libvirt/VMS/ses55-osd2-osd1.qcow2,size=20 --disk bus=virtio,path=/var/lib/libvirt/VMS/ses55-osd2-osd2.qcow2,size=20 --disk bus=virtio,path=/var/lib/libvirt/VMS/ses55-osd2-osd3.qcow2,size=20 --vcpus 4 --os-type linux --os-variant generic --network bridge=caasp3 --graphics none --console pty,target_type=serial --location '/var/lib/libvirt/ISOS/SLE-12-SP3-Server-DVD-x86_64-GM-DVD1.iso' --extra-args 'console=ttyS0,115200n8 serial autoyast-ses5=http://10.10.10.101/autoyast-ses5 ifcfg=eth0=10.18.10.232/24,10.18.10.1,10.10.10.11,suse-sap.net domain=suse-sap.net Textmode=1'
----

image::multi-s-smt.png[title="Multi Shell SMT",480,640,align=center]

Select the SUSE Enterprise Storage 5 Extension.

image::multi-s-addon.png[title="Multi Shell Extensions and Modules",480,640,align=center]

On the hypervisor you should also be able to route or bridge (either a traditional bridge using *brctl* or a virtual bridge) your upcoming SUSE Enterprise Storage 5.5 network segment. In our example, for simplicity, we are using the same bridge and network address than our CaaSP cluster "--network bridge=caasp3‚Äù

In the following example, each node is powered by 16GB of RAM, 4 VCPU, 40 GB for the root disk, 4 * 20GB OSDB disk.

image::multi-s-default.png[title="Multi Shell Default System",480,640,align=center]

NTP must be configured on each nodes

image::multi-s-ntp.png[title="Multi Shell NTP Server",480,640,align=center]

Deselect AppArmor and unnecessary X and GNOME Patterns, but select the SUSE Enterprise Storage pattern.

image::multi-s-patterns.png[title="Multi Shell Patterns",480,640,align=center]

Deactivate the Firewall on the nodes.
Start the Installation on all nodes.

image::multi-s-install.png[title="Multi Shell Installation",480,640,align=center]

When the nodes are rebooted, log in and finish the network/host name and NTP configurations so that

----
# hostname -f
----

returns the FQDN of the nodes and

----
#ntpq -p
----

returns a stratum less than 16.

image::multi-s-hostname-ntp.png[title="Multi Shell Host Name",480,640,align=center]

Using *ssh-keygen* and then *ssh-copy-id*, send your SUSE Enterprise Storage admin node SSH public key to all other nodes.

Verify that the drives you are going to allocate for SUSE Enterprise Storage OSDs are clean by wiping them (refer to 4.3.12 of the Deployment Guide)

** link:https://documentation.suse.com/ses/5.5/html/ses-all/ceph-install-saltstack.html#ceph-install-stack[Wipe disk]

Install *salt-minion* on all nodes (including admin) and *salt-master* only on the admin node (in our example ses55-admin.suse-sap.net). Install also *deepsea* on the admin node.

Then restart *salt-minion* on all nodes and *salt-master* on the admin node.

image::multi-s-salt-install-restart.png[title="Multi Shell Salt Installation",480,640,align=center]

Accept related pending Salt keys.

image::salt-key.png[title="Salt Keys",480,640,scaledwidth=80%,align=center]

Verify that */srv/pillar/ceph/master_minion.sls* points to your admin node. In our example it contains our *salt-master* FQDN: master_minion: ses55-admin.suse-sap.net

Prepare the cluster with the following command:

----
# salt-run state.orch ceph.stage.0
----

image::ceph-stage-0.png[title="Ceph Stage 0",480,640,scaledwidth=70%,align=center]

Collect information about the nodes:

----
# salt-run state.orch ceph.stage.1
----

image::ceph-stage-1.png[title="Ceph Stage 1",480,640,scaledwidth=80%,align=center]

Adapt the file  */srv/pillar/ceph/proposals/policy.cfg* to your needs.

In our example, where the only deployed service is OpenAttic, it contains the following information:

----
cluster-ceph/cluster/ses55-osd2.suse-sap.net.sls
config/stack/default/ceph/cluster.yml
config/stack/default/global.yml
profile-default/cluster/ses55-admin.suse-sap.net.sls
profile-default/cluster/ses55-osd0.suse-sap.net.sls
profile-default/cluster/ses55-osd1.suse-sap.net.sls
profile-default/cluster/ses55-osd2.suse-sap.net.sls
profile-default/stack/default/ceph/minions/ses55-admin.suse-sap.net.yml
profile-default/stack/default/ceph/minions/ses55-osd0.suse-sap.net.yml
profile-default/stack/default/ceph/minions/ses55-osd1.suse-sap.net.yml
profile-default/stack/default/ceph/minions/ses55-osd2.suse-sap.net.yml
role-admin/cluster/ses55-admin.suse-sap.net.sls
role-admin/cluster/ses55-osd0.suse-sap.net.sls
role-admin/cluster/ses55-osd1.suse-sap.net.sls
role-admin/cluster/ses55-osd2.suse-sap.net.sls
role-master/cluster/ses55-admin.suse-sap.net.sls
role-mgr/cluster/ses55-osd0.suse-sap.net.sls
role-mgr/cluster/ses55-osd1.suse-sap.net.sls
role-mgr/cluster/ses55-osd2.suse-sap.net.sls
role-mon/cluster/ses55-osd0.suse-sap.net.sls
role-mon/cluster/ses55-osd1.suse-sap.net.sls
role-mon/cluster/ses55-osd2.suse-sap.net.sls
role-openattic/cluster/ses55-admin.suse-sap.net.sls
----

Prepare the final state of the configuration files set:

----
# salt-run state.orch ceph.stage.2
----

image::ceph-stage-2.png[title="Ceph Stage 2",480,640,scaledwidth=80%,align=center]

You can now safely deploy your configuration:

----
# salt-run state.orch ceph.stage.3
----

image::ceph-stage-3.png[title="Ceph Stage 3",480,640,scaledwidth=70%,align=center]

When the stage 3 has been successfully passed, check the cluster health to insure that everything is running properly:

----
# ceph -s
----

image::ceph-health.png[title="Ceph Health",480,640,scaledwidth=80%,align=center]

To benefit from the OpenAttic WebUI you have to initiate the *ceph.stage.4* which will install the OpenAttic service:

----
# salt-run state.orch ceph.stage.4
----

image::ceph-stage-4.png[title="Ceph Stage 4",480,640,scaledwidth=80%,align=center]

You can now manage your cluster through the WebUI.

image::openattic-dash.png[title="SUSE Enterprise Storage WebUI",480,640,scaledwidth=80%,align=center]

To provide a Data Hub RBD device you first need to create a related pool.

image::openattic-pool.png[title="Ceph Pool",480,640,scaledwidth=80%,align=center]

Then provide access to this pool through an RBD device.

image::openattic-rbd.png[title="Ceph RBD",480,640,scaledwidth=80%,align=center]

You can now proceed to Section 4.1.2 of this documentation and follow the instructions detailed in "Prerequisites on the SUSE CaaS Platform 3 Cluster" 

=== Troubleshooting

// Standard SUSE Best Practices includes
== Legal Notice
include::common_sbp_legal_notice.adoc[]

++++
<?pdfpagebreak?>
++++

// Standard SUSE Best Practices includes
include::common_gfdl1.2_i.adoc[]
