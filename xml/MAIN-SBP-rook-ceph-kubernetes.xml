<?xml version="1.0" encoding="UTF-8"?>
<!--<?oxygen RNGSchema="http://www.oasis-open.org/docbook/xml/5.0/rng/docbook.rng" type="xml"?>-->
<!DOCTYPE article [
<!ENTITY % entity SYSTEM "entity-decl.ent">
%entity;
]>

<article role="sbp" xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude"
	xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0" xml:id="art-rook-kubernetes-ceph"
	xml:lang="en">

	<info>
		<title>Rook Best Practices for Running Ceph on Kubernetes </title>
		<productname>SUSE Enterprise Storage, Ceph, Rook, Kubernetes, Cloud as a Service Platform</productname>
		<author>
			<personname>
				<firstname>Blaine</firstname>
				<surname>Gardner, Senior Software Developer, SUSE</surname>
			</personname>
		</author>
		<author>
      <personname>
				<firstname>Alexandra</firstname>
				<surname>Settle, Senior Information Developer, SUSE</surname>
			</personname>
		</author>
		<date>May 14, 2020</date>
	</info>

  <sect1 xml:id="sec-rook-bp-overview">
    <title>Overview</title>
		<para>
			Ceph and Kubernetes are both complex tools and harmonizing
			the interactions between the two can be daunting. This is
			especially true for users who are new to operating either
			system, prompting questions such as:
		</para>
		<itemizedlist>
			<listitem>
				<para>
					How can I restrict Ceph to a portion of my nodes?
				</para>
			</listitem>
			<listitem>
				<para>
					Can I set Kubernetes CPU or RAM limits for my Ceph daemons?
				</para>
			</listitem>
			<listitem>
				<para>
					What are some ways to get better performance from my cluster?
				</para>
			</listitem>
		</itemizedlist>
		<para>
			This document covers tested patterns and best practices to answer
			these questions and more. Our examples will help you configure and
			manage your Ceph cluster running in Kubernetes to meet your needs.
			The following examples and advice is based on Ceph Octopus with
			Rook v1.3.
		</para>
		<para>
			This is a moderately advanced topic, so basic experience with Rook
			is recommended. Before you begin, ensure you have the following
			requisite knowledge:
		</para>
		<itemizedlist>
			<listitem>
				<para>
					Basics of Kubernetes
				</para>
			</listitem>
			<listitem>
				<para>
					How to create Kubernetes applications using manifests
				</para>
			</listitem>
			<listitem>
				<para>
					Kubernetes topics:
				</para>
				<itemizedlist>
					<listitem>
						<para>
							Pods
						</para>
					</listitem>
					<listitem>
						<para>
							Nodes
						</para>
					</listitem>
					<listitem>
						<para>
							Labels
						</para>
					</listitem>
					<listitem>
						<para>
							Topology
						</para>
					</listitem>
					<listitem>
						<para>
							Taints and tolerations
						</para>
					</listitem>
					<listitem>
						<para>
							(Anti-)affinity
						</para>
					</listitem>
					<listitem>
						<para>
							Resource requests
						</para>
					</listitem>
					<listitem>
						<para>
							Limits
						</para>
					</listitem>
				</itemizedlist>
			</listitem>
			<listitem>
				<para>
					Ceph components and daemons, basic Ceph configuration
				</para>
			</listitem>
			<listitem>
				<para>
					Rook basics and how to install Rook-Ceph. For more information
					see <link xlink:href="https://rook.io/docs/rook/master/ceph-storage.html"/>
				</para>
			</listitem>
		</itemizedlist>
		<para>
			In places, we will give examples that describe an imaginary
			data center. This data center is hypothetical, and it will focus
			on the Ceph- and Rook-centric elements and ignore user applications.
		</para>
		<para>
			Our example data center has two rooms for data storage. Ceph must
			have at least three monitor (MON) nodes. These should be spread
			across fault-tolerant rooms if possible. The example will have a
			separate failure domain for the third monitor node. As such, our
			hypothetical data center has two rooms and one failure domain, with
			the following configuration:
		</para>
		<itemizedlist>
			<listitem>
				<para>
					The failure domain is small and can only to be used for the
					third Ceph MON; it does not have space for storage nodes.
				</para>
			</listitem>
			<listitem>
				<para>
					Eight OSD nodes provides a good amount of data safety without
					requiring too many nodes.
				</para>
			</listitem>
			<listitem>
				<para>
					These eight nodes should be equally separated — four to each data center room.
				</para>
			</listitem>
			<listitem>
				<para>
					The four nodes are separated in each room into two racks.
				</para>
			</listitem>
			<listitem>
				<para>
					In the event of a MON node failure, ensure that you can run MONs on
					each rack for failure scenarios.
				</para>
			</listitem>
		</itemizedlist>
		<para>
			The data center looks as follows:
		</para>

		<figure xml:id="fig-datacenter">
     <title>Example Datacenter</title>
		 <mediaobject>
			<imageobject role="fo">
			 <imagedata fileref="example-datacenter.png" width="100%"/>
			</imageobject>
			<imageobject role="html">
			 <imagedata fileref="example-datacenter.png" width="100%"/>
			</imageobject>
		 </mediaobject>
		</figure>

    <para>
			Now we will dig a little deeper and talk about the actual disks used
			for Rook and Ceph storage. To ensure we are following known Ceph
			best practices for this data center setup, ensure that MON storage
			goes on the SSDs. Because each rack should be able to run a Ceph MON,
			one of the nodes in each rack will have an SSD that is usable for MON
			storage. Additionally, all nodes in all racks (except in the failure
			domain) will have disks for OSD storage. This will look like the following:
    </para>

		<figure xml:id="fig-datacenter-disks">
     <title>Example Datacenter - Disks</title>
			<mediaobject>
			 <imageobject role="fo">
				<imagedata fileref="example-datacenter-disks.png" width="100%"/>
			 </imageobject>
			 <imageobject role="html">
				<imagedata fileref="example-datacenter-disks.png" width="100%"/>
			 </imageobject>
			</mediaobject>
		</figure>

    <important>
    	<title>Diagrams</title>
			<para>
				Refer to these diagrams when we discuss the example data center below.
			</para>
    </important>

  </sect1>
	<sect1 xml:id="sec-rook-bp-intro">
    <title>Introduction</title>
		<para>
			Ceph and Kubernetes both have their own well-known and established
			best practices. This document specifically covers best practices
			for running Ceph on Kubernetes with Rook. Rook bridges the gap between
			Ceph and Kubernetes, putting it in a unique domain with its own best
			practices to follow. Rook also has different ways to meet Ceph and
			Kubernetes best practices, compared to the bare metal version of
			Kubernetes itself as Rook augments on top. Out of the box, Rook is
			predominantly a default Ceph cluster. The Ceph cluster needs tuning
			to meet user workloads, and Rook does not absolve the user from
			planning out their production storage cluster beforehand.
		</para>
		<para>
			For the purpose of this document, we will consider two simplified
			use cases to help us make informed decisions about Rook and Ceph:
		</para>

		<itemizedlist>
			<listitem>
				<para>
					Co-located: User applications co-exist on nodes running Ceph
				</para>
			</listitem>
			<listitem>
				<para>
					Dis-aggregated: Ceph nodes are totally separated from user applications
				</para>
			</listitem>
		</itemizedlist>

  </sect1>
	<sect1 xml:id="sec-rook-bp-general">
    <title>General Best Practices</title>
		<para>
			This chapter provides an outline of a series of generalized
			recommendations for best practices:
		</para>

		<itemizedlist>
			<listitem>
				<para>
					Ceph monitors are more stable on fast storage (SSD-class
					or better) according to Ceph best practices. In Rook, this means
					that the <literal>dataDirHostPath</literal> location in the <filename>cluster.yaml</filename>
					should be backed by SSD or better on MON nodes.
				</para>
			</listitem>
			<listitem>
				<para>
					Raise the Rook log level to <option>DEBUG</option> for initial deployment or upgrades,
					as it will help with debugging problems that are more likely to occur
					at those times.
				</para>
				<para>
					Ensure that the <literal>ROOK_LOG_LEVEL</literal> in <filename>operator.yaml</filename>
					equals <option>debug</option>.
				</para>
			</listitem>
			<listitem>
				<para>
					The Kubernetes CSI driver is the preferred default but ensure that
					in <filename>operator.yaml</filename> the <option>ROOK_ENABLE_FLEX_DRIVER</option> remains set to
					<option>false</option>. This is because the FlexVolume driver is in sustaining mode,
					is not getting non-priority bug fixes, and will soon be deprecated.
				</para>
			</listitem>
			<listitem>
				<para>
					Ceph’s placement group (PG) auto-scaler module makes it unnecessary
					to manually manage PGs. We recommend you always set this to <option>enabled</option>,
					unless you have some need to manage PGs manually. In <filename>cluster.yaml</filename>,
					enable the <literal>pg_autoscaler</literal> MGR module.
				</para>
			</listitem>
			<listitem>
				<para>
					Rook has the capability to auto-remove deployments for OSDs which
					are kicked out of a Ceph cluster. An example is: <literal>removeOSDSIfOutAndSafeToRemove=true</literal>.
					This means there is less user OSD maintenance and no need to
					delete deployments for OSDs that have been kicked out. Rook will
					automatically clean up the cluster by removing OSD pods if the OSDs
					are no longer holding Ceph data. However, keep in mind that this can
					reduce the visibility of failures from Kubernetes cluster levels.
					You can optionally set <literal>removeOSDSIfOutAndSafeToRemove</literal> to <option>false</option>
					if need be, such as if a Kubernetes administrator wants to see disk
					failures via a Pod overview.
				</para>
			</listitem>
			<listitem>
				<para>
					Configure Ceph using the central configuration database when
					possible. This allows for more runtime configuration flexibility.
					Do this using the <command>ceph config set</command> commands. Only use Rook’s
					provided <filename>ceph.conf</filename> to override <literal>ConfigMap</literal> when it is required.
				</para>
			</listitem>
		</itemizedlist>

  </sect1>
	<sect1 xml:id="sec-limit-ceph-specifc-nodes">
    <title>Limiting Ceph to Specific Nodes</title>
		<para>
			One of the more common setups you may want for your Rook-Ceph cluster
			is to limit Ceph to a specific set of nodes. Even for co-located use
			cases, you should have valid reasons why you must not (or do not want
			to) use some nodes for storage. This is applicable for both co-located
			and dis-aggregated use cases. To limit Ceph to specific nodes, we
			can label Kubernetes nodes and configure Rook to have <option>affinity</option> (as
			a hard preference) for our label.
		</para>
		<para>
			Label the desired storage nodes with <literal>storage-node=true</literal>. We will
			configure Rook affinities in both the Rook Operator manifest
			(<filename>operator.yaml</filename>) and the Ceph cluster manifest (<filename>cluster.yaml</filename>).
		</para>
		<para>
			<filename>operator.yaml</filename>
		</para>

<screen>
CSI_PROVISIONER_NODE_AFFINITY: “storage-node=true”
AGENT_NODE_AFFINITY: “storage-node=true”
DISCOVER_AGENT_NODE_AFFINITY: “storage-node=true”
</screen>

    <note>
			<para>
				The CSI provisioner is best started on the same nodes as the
				other Ceph daemons. As above, add affinity for all storage
				nodes in <filename>cluster.yaml</filename>:
			</para>
<screen>
placement:
  all:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
	nodeSelectorTerms:
	- matchExpressions:
	  - key: storage-node
            operator: In
	    values:
	    - "true"
</screen>
    </note>

  </sect1>
	<sect1 xml:id="sec-segregate-ceph-user-app">
    <title>Segregating Ceph From User Applications</title>
		<para>
			You should separate Rook and Ceph nodes from application nodes.
			This falls under the dis-aggregated use-case, and it is a more
			traditional way to deploy storage. In this case, we still need to
			<xref linkend="sec-limit-ceph-specifc-nodes"/> as described in the section
			above, and we also need some additional settings.
		</para>
		<para>
			To segregate Ceph from user applications, we will also label
			all non-storage nodes with <literal>storage-node=false</literal>. The CSI plugin pods
			must run where user applications run (not where Rook or Ceph pods
			are run). We then add a CSI plugin affinity for all non-storage
			nodes in the Rook operator configuration.
		</para>

<screen>
CSI_PLUGIN_NODE_AFFINITY: "storage-node=false"
</screen>

    <para>
			In addition to that, we will configure Kubernetes Node Taints
			and Rook Tolerations. For example, Taint the storage nodes with
			<literal>storage-node=true:NoSchedule</literal>. We then add
			Tolerations to the Rook operator in <filename>operator.yaml</filename>:
    </para>

<screen>
AGENT_TOLERATIONS:  |
	 - key: storage-node
	   operator: Exists
</screen>

<screen>
DISCOVER_TOLERATIONS:  |
	 - key: storage-node
	   operator: Exists
</screen>

<screen>
CSI_PROVISIONER_TOLERATIONS:  |
	 - key: storage-node
	   operator: Exists
</screen>

     <para>
			 Also add a Toleration for Ceph daemon pods in <filename>cluster.yaml</filename>:
     </para>

<screen>
placement:
  all:
	  tolerations:
		- key: storage-node
		  operator: Exists
</screen>

     <tip>
			 <title>Set CRUSH Map via Kubernetes Node Labels</title>
			 <para>
				 A feature that was implemented early in Rook’s development is
				 to set Ceph’s CRUSH map via Kubernetes Node Labels. For our example
				 data center, label nodes with <option>room</option>, <option>rack</option>,
				 and <option>chassis</option> are used.
			 </para>
			 <para>
				 As a note, Rook will only set a CRUSH map on initial creation for
				 each OSD associated with the node. It will not alter the CRUSH map
				 if labels are modified later. Therefore, modifying the CRUSH map
				 after Rook has created it must be done manually.
			 </para>
			 <para>
				 For example, in our hypothetical data center, label nodes will
				 look like the following:
			 </para>

<screen>
# -- room-1 --
kubectl label node node-1-1-1 topology.rook.io/room=room-1
kubectl label node node-1-1-1 topology.rook.io/rack=rack-1-1
kubectl label node node-1-1-1 topology.rook.io/chassis=node-1-1-1

kubectl label node node-1-1-2 topology.rook.io/room=room-1
kubectl label node node-1-1-2 topology.rook.io/rack=rack-1-1
kubectl label node node-1-1-2 topology.rook.io/chassis=node-1-1-2

kubectl label node node-1-2-1 topology.rook.io/room=room-1
kubectl label node node-1-2-1 topology.rook.io/rack=rack-1-2
kubectl label node node-1-2-1 topology.rook.io/chassis=node-1-2-1

kubectl label node node-1-2-2 topology.rook.io/room=room-1
kubectl label node node-1-2-2 topology.rook.io/rack=rack-1-2
kubectl label node node-1-2-2 topology.rook.io/chassis=node-1-2-2

# -- room-2 --

kubectl label node node-2-1-1 topology.rook.io/room=room-2
kubectl label node node-2-1-1 topology.rook.io/rack=rack-2-1
kubectl label node node-2-1-1 topology.rook.io/chassis=node-2-1-1

kubectl label node node-2-1-2 topology.rook.io/room=room-2
kubectl label node node-2-1-2 topology.rook.io/rack=rack-2-1
kubectl label node node-2-1-2 topology.rook.io/chassis=node-2-1-2

kubectl label node node-2-2-1 topology.rook.io/room=room-2
kubectl label node node-2-2-1 topology.rook.io/rack=rack-2-2
kubectl label node node-2-2-1 topology.rook.io/chassis=node-2-2-1

kubectl label node node-2-2-2 topology.rook.io/room=room-2
kubectl label node node-2-2-2 topology.rook.io/rack=rack-2-2
kubectl label node node-2-2-2 topology.rook.io/chassis=node-2-2-2

# -- room-f (failure domain) --

kubectl label node node-f-1-1 topology.rook.io/room=room-f
kubectl label node node-f-1-1 topology.rook.io/rack=rack-f-1
kubectl label node node-f-1-1 topology.rook.io/chassis=node-f-1-1
</screen>

     </tip>

  </sect1>
	<sect1 xml:id="sec-planning-nodes-ceph-daemons">
    <title>Planning the Nodes Where Ceph Daemons Will Run</title>
		<para>
			Using the hypothetical data center described in the <xref linkend="sec-rook-bp-overview"/>,
			this section will look at planning the nodes where Ceph daemons are going to run.
		</para>
		<para>
			Ceph MON scheduling is one of the more detailed, and more important,
			things to understand about maintaining a healthy Ceph cluster. The
			goals we will target in this section can be summarized as:
			<quote>Avoid risky co-location scenarios, but allow them if there are no
				other options, to still have as much redundancy as possible.</quote>
		</para>
		<para>
			This can lead us to the following specific goals:
		</para>

		<itemizedlist>
			<listitem>
				<para>
					Allow MONs to be in the same room if a room is unavailable.
				</para>
			</listitem>
			<listitem>
				<para>
					Allow MONs to be in the same rack if no other racks in the room
					are available.
				</para>
			</listitem>
			<listitem>
				<para>
					Allow MONs to be on the same host only if no other hosts are available.
				</para>
				<para>
					We must allow this specifically in the cluster configuration <filename>cluster.yaml</filename>
					by setting <option>allowMultiplePerNode: true</option>.
				</para>
				<note>
					<para>
						This cannot be set to <option>true</option> for clusters using host networking.
					</para>
				</note>
			</listitem>
		</itemizedlist>

		<tip>
			<title>Topology Labels</title>
			<para>
				We recommend using the same topology labels used for informing the
				CRUSH map here for convenience.
			</para>
		</tip>

		<para>
			Because of our MON SSD availability, in our hypothetical data center,
			we only want monitors to be able to run where shown below in green.
			We need to plan for monitors to fail over, and so we will make two
			nodes explicitly available for this scenario. In our example, we
			want any node with a MON SSD to be a MON failover location in
			emergencies, for maximum cluster health. This is highlighted in
			orange below. This will give us the most redundancy under failure
			conditions.
		</para>

		<figure xml:id="fig-datacenter-mon-failover">
     <title>Example Datacenter - MON Failover</title>
			<mediaobject>
			 <imageobject role="fo">
				<imagedata fileref="example-datacenter-mon-failover.png" width="100%"/>
			 </imageobject>
			 <imageobject role="html">
				<imagedata fileref="example-datacenter-mon-failover.png" width="100%"/>
			 </imageobject>
			</mediaobject>
		</figure>

    <para>
			To implement this in Rook, ensure you only schedule MONs on nodes
			with MON SSDs. There is a required affinity for those nodes, which
			can be accomplished by applying a <option>ceph-mon-ssd=true</option> label to nodes
			with SSDs for Ceph MONs. Note that the MON section’s <literal>nodeAffinity</literal>
			overwrites the all section’s <literal>nodeAffinity</literal>. Thus we must ensure that
			we re-specify the rules from the all section to ensure Ceph MONs
			maintain affinity only for storage nodes.
    </para>

<screen>
nodeAffinity:​
	requiredDuringSchedulingIgnoredDuringExecution:​
	  nodeSelectorTerms:​
	  - matchExpressions:​
	    - key: role​
	      operator: In​
	      values:​
	      - storage-node  ​
	  - matchExpressions:​
	    - key: ceph-mon-ssd​
	      operator: In​
	      values:​
	      - "true"
</screen>

    <para>
			We want to schedule MONs so they are spread across failure domains
			whenever possible. We will accomplish this by applying anti-affinity
			between MON pods. Rook labels all MON pods <literal>app=rook-ceph-mon</literal>, and
			that is what will be used to spread the monitors apart. There is
			one rule for rooms, and one for racks if a room is down. We want to
			ensure a higher weight is given to riskier co-location scenarios:
    </para>

<screen>
podAntiAffinity:​
	preferredDuringSchedulingIgnoredDuringExecution:​
	- weight: 80​
	  podAffinityTerm:​
	    labelSelector:​
	      matchLabels:​
	        app: rook-ceph-mon​
	    topologyKey: topology.rook.io/room​
	- weight: 90​
	  podAffinityTerm:​
	    labelSelector:​
	      matchLabels:​
	        app: rook-ceph-mon​
	    topologyKey: topology.rook.io/rack​
</screen>

    <para>
			We do not recommend running MONs on the same node unless absolutely
			necessary. Rook automatically applies an anti-affinity with
			medium-level weight. However, this might not be appropriate for
			all scenarios. For our scenario, we only want node-level co-location
			in the worst of failure scenarios, so we want to apply the
			highest weight anti-affinity for nodes.
    </para>

<screen>
podAntiAffinity:​
	preferredDuringSchedulingIgnoredDuringExecution:​
	- weight: 100​
	  podAffinityTerm:​
	    labelSelector:​
	      matchLabels:​
	        app: rook-ceph-mon​
	    topologyKey: kubernetes.io/hostname​
</screen>

    <note>
			<para>
				If <literal>hostNetworking</literal> is enabled, you cannot co-locate MONs, because
				the ports will collide on nodes. To enforce this, if<literal>hostNetworking</literal>
				is enabled, Rook will automatically set a
				<literal>requiredDuringSchedulingIgnoredDuringExecution</literal> Pod Anti-affinity rule.
			</para>
    </note>

		<para>
			There is a lot of planning that goes into the placement of monitors,
			and this is also true for OSDs. Fortunately, because the planning is
			already done with the monitors and because we have discussed the methods,
			it is quite a bit easier to plan for the OSDs.
		</para>

		<figure xml:id="fig-datacenter-osd-placement">
     <title>Example Datacenter - OSD Placement</title>
			<mediaobject>
			 <imageobject role="fo">
				<imagedata fileref="example-datacenter-osd-placement.png" width="100%"/>
			 </imageobject>
			 <imageobject role="html">
				<imagedata fileref="example-datacenter-osd-placement.png" width="100%"/>
			 </imageobject>
			</mediaobject>
		</figure>

    <para>
			There are two ways to select nodes to use for OSDs:
    </para>

		<itemizedlist>
			<listitem>
				<para>
					Apply Kubernetes Node labels and tell Rook to look for
					those labels. Specify in the <filename>cluster.yaml</filename>
					<filename>storage:useAllNodes true</filename> and specify
					<literal>osd nodeAffinity</literal> using <literal>ceph-osd=true</literal>
					label using the same affinity methods we used for MONs.
				</para>
			</listitem>
			<listitem>
				<para>
					Specify Node names in the <literal>CephCluster</literal> definition
					(<filename>cluster.yaml</filename>) individually: <literal>storage:nodes</literal>.
				</para>
			</listitem>
		</itemizedlist>

		<para>
			Choosing which option to use depends on your desired management
			strategy. There is no single strategy we would recommend over any other.
		</para>
		<para>
			Placing the other Ceph daemons follows the same logic and methods as
			MONs and OSDs: MGR, MDS, RGW, NFS-Ganesha, and RBD mirroring
			daemons can all be placed as desired. For more information, see
			<link xlink:href="https://rook.io/docs/rook/master/ceph-cluster-crd.html#placement-configuration-settings"/>
		</para>

  </sect1>
	<sect1 xml:id="sec-hardware-resource-req">
    <title>Hardware Resource Requirements and Requests</title>
		<para>
			Kubernetes can watch the system resources available on nodes and can
			help schedule applications—such as the Ceph daemons—automatically.
			Kubernetes uses Resource Requests to do this.
		</para>
		<para>
			Kubernetes has two resource request types: <emphasis>Requests</emphasis> and <emphasis>Limits</emphasis>.
			<emphasis>Requests</emphasis> govern scheduling, and <emphasis>Limits</emphasis> instruct Kubernetes to kill and
			restart application Pods when they are over-consuming given <emphasis>Limits</emphasis>.
		</para>
		<para>
			When there are Ceph hardware requirements, treat those requirements as
			<emphasis>Requests</emphasis>, not <emphasis>Limits</emphasis>. This is because all Ceph daemons are critical for
			storage, and it is best to never set resource <emphasis>Limits</emphasis> for Ceph pods. If
			Ceph Daemons are over-consuming <emphasis>Requests</emphasis>, there is likely a failure
			scenario happening. Killing a daemon beyond a <emphasis>Limit</emphasis> is likely to
			make an already bad situation worse. This could create a
			“thundering herds” situation where failures synchronize and magnify.
		</para>
		<para>
			Generally, storage is given minimum resource guarantees, and other
			applications should be limited so as not to interfere. This guideline
			already applies to bare-metal storage deployments, not only for Kubernetes.
		</para>
		<para>
			As you read on, it is important to note that all recommendations can
			be affected by how Ceph daemons are configured. For example, any
			configuration regarding caching. Keep in mind that individual
			configurations are out of scope for this document.
		</para>

		<sect2 xml:id="sec-resource-req-mon-mgr">
			<title>Resource Requests - MON/MGR</title>
			<para>
				Resource requests for MONs and MGRs are straightforward. MONs
				try to keep memory usage to around 1 GB — however, that can
				expand under failure scenarios. We recommend 4 GB RAM and 4 CPU cores.
			</para>
			<para>
				Recommendations for MGR nodes are harder to make, since enabling
				more modules means higher usage. We recommend starting with
				2 GB RAM and 2 CPU cores for MGRs. It is a good idea to look at the
				actual usage for deployments. Do not forget to consider usage during
				failure scenarios.
			</para>
			<para>
				MONs:
			</para>

			<itemizedlist>
				<listitem>
					<para>
						<emphasis>Request</emphasis> 4 CPU cores
					</para>
				</listitem>
				<listitem>
					<para>
						<emphasis>Request</emphasis> 4GB RAM (2.5GB minimum)
					</para>
				</listitem>
			</itemizedlist>
			<para>
				MGR:
			</para>
			<itemizedlist>
				<listitem>
					<para>
						Memory will grow the more MGR modules are enabled
					</para>
				</listitem>
				<listitem>
					<para>
						<emphasis>Request</emphasis> 2 GB RAM and 2 CPU cores
					</para>
				</listitem>
			</itemizedlist>

		</sect2>
		<sect2 xml:id="sec-resource-req-osd-cpu">
			<title>Resource Requests - OSD CPU</title>
			<para>
				Recommendations and calculations for OSD CPU are straightforward.
				Note that resources are applied cluster-wide to
				all OSDs. If a cluster contains multiple OSD types, you must use the
				highest requests for the whole cluster. For the examples below, a
				mixture of HDDs journaled to SSD and SSDs without journals would
				necessitate a <emphasis>Request</emphasis> for 2 cores.
			</para>
			<para>
				Hardware recommendations:
			</para>

			<itemizedlist>
				<listitem>
					<para>
						1 x 2GHz CPU Thread per spinner
					</para>
				</listitem>
				<listitem>
					<para>
						2 x GHz CPU Thread per SSD
					</para>
				</listitem>
				<listitem>
					<para>
						4 x GHz CPU Thread per NVMe
					</para>
				</listitem>
			</itemizedlist>
			<para>
				Examples:
			</para>
			<itemizedlist>
				<listitem>
					<para>
						8 HDDS journaled to SSD – 10 cores / 8 OSDs = 1.25 cores per OSD
					</para>
				</listitem>
				<listitem>
					<para>
						6 SSDs without journals – 12 cores / 6 OSDs = 2 cores per OSD
					</para>
				</listitem>
				<listitem>
					<para>
						8 SSDs journaled to NVMe – 20 cores / 8 OSDs = 2.5 cores per OSD
					</para>
				</listitem>
			</itemizedlist>

		</sect2>
		<sect2 xml:id="sec-resource-req-osd-ram">
			<title>Resource Requests - OSD RAM</title>
			<para>
				OSD RAM usage comes with the same cluster-wide resource note. Also
				note that Ceph OSDs self-inspect the Kubernetes Pod Resource <emphasis>Request</emphasis>,
				and they will try not to overconsume the detected <emphasis>Request</emphasis> on a
				best-effort basis. Select the greatest of the below options considering
				all the OSDs in your cluster:
			</para>

			<itemizedlist>
				<listitem>
					<para>
						1 GB x [OSD size]
					</para>
				</listitem>
				<listitem>
					<para>
						2 GB = [Bluestore cache size]
					</para>
				</listitem>
			</itemizedlist>

			<note>
				<para>
					Default BlueStore cache is 1 GB for HDDs and 3 GB for SSDs.
				</para>
			</note>

		</sect2>
		<sect2 xml:id="sec-resource-req-gateways">
			<title>Resource Requests - Gateways</title>
			<para>
				For gateways, the best recommendation is to always tune your
				workload and daemon configurations. However, we do recommend the
				following initial configurations:
			</para>

			<note>
				<para>
					The numbers below for RGW assume a lot of clients connecting. Thus
					they might not be the best for your scenario. The RAM usage should be
					lower for the newer “beast” protocol as opposed to the older
					“civetweb” protocol.
				</para>

			</note>
			<para>
				RGWs:
			</para>

			<itemizedlist>
				<listitem>
					<para>
						6-8 CPU cores
					</para>
				</listitem>
				<listitem>
					<para>
						64 GB RAM (32 GB minimum – may only apply to older civetweb protocol)
					</para>
				</listitem>
			</itemizedlist>

			<para>
				MDS:
			</para>

			<itemizedlist>
				<listitem>
					<para>
						2.5 GHz CPU with a least 2 cores
					</para>
				</listitem>
				<listitem>
					<para>
						3GB RAM
					</para>
				</listitem>
			</itemizedlist>

			<para>
				NFS-Ganesha:
			</para>

			<itemizedlist>
				<listitem>
					<para>
						6-8 CPU cores (untested, high estimate)
					</para>
				</listitem>
				<listitem>
					<para>
						4GB RAM for default settings (settings hardcoded in Rook presently)
					</para>
				</listitem>
			</itemizedlist>
		</sect2>

  </sect1>
	<sect1 xml:id="sec-basic-performance-enhancements">
		<title>Basic Performance Enhancements</title>
		<para>
			The following are some basic performance enhancements. These are a few
			easy, low-hanging-fruit recommendations.
		</para>

		<note>
			<para>
				Not all of these will be right for all clusters or workloads.
				Always performance test and use your best judgment.
			</para>
		</note>

		<itemizedlist>
			<listitem>
				<para>
					You can gain performance by using a CNI plugin with an
					accelerated network stack. For example, Cilium uses eBPF to
					improve performance over some other CNI plugins.
				</para>
			</listitem>
			<listitem>
				<para>
					Enable host networking to improve network performance.
					Notably, this provides lower, more stable latency. This does,
					however, step outside of Kubernetes’ network security domain.
					In <filename>cluster.yaml</filename> enable <literal>hostNetwork: true</literal>.
				</para>
			</listitem>
			<listitem>
				<para>
					Use jumbo frames for your networking. This can be applied to both
					host networking and the CNI plugin.
				</para>
			</listitem>
		</itemizedlist>
	</sect1>


	<sect1 xml:id="sec-legal-notice">
		<title>Legal Notice</title>
		<para>Copyright &copy;2006–2020 SUSE LLC and contributors. All rights reserved. </para>
		<para>Permission is granted to copy, distribute and/or modify this document under the terms of
			the GNU Free Documentation License, Version 1.2 or (at your option) version 1.3; with the
			Invariant Section being this copyright notice and license. A copy of the license version 1.2
			is included in the section entitled <quote>GNU Free Documentation License</quote>.</para>
		<para>SUSE, the SUSE logo and YaST are registered trademarks of SUSE LLC in the United States
			and other countries. For SUSE trademarks, see <link
				xlink:href="http://www.suse.com/company/legal/">http://www.suse.com/company/legal/</link>.
			Linux is a registered trademark of Linus Torvalds. All other names or trademarks mentioned in
			this document may be trademarks or registered trademarks of their respective owners.</para>
		<para>This article is part of a series of documents called <quote>SUSE Best Practices</quote>. The individual
			documents in the series were contributed voluntarily by SUSE's employees and by third
			parties.</para>
		<para>The articles are intended only to be one example of how a particular action could be
			taken. They should not be understood to be the only action and certainly not to be the
			action recommended by SUSE. Also, SUSE cannot verify either that the actions described
			in the articles do what they claim to do or that they don't have unintended
			consequences.</para>
		<para> All information found in this article has been compiled with utmost attention to detail.
			However, this does not guarantee complete accuracy.
			<!--Neither SUSE LLC, the authors, nor the translators shall be held liable
				for possible errors or the consequences thereof. --></para>
		<para>Therefore, we need to specifically state that neither SUSE LLC, its affiliates, the
			authors, nor the translators may be held liable for possible errors or the consequences
			thereof. Below we draw your attention to the license under which the articles are
			published.</para>
	</sect1>

	<?pdfpagebreak style="suse2013-sbp" formatter="fop"?>

	<xi:include href="license-gfdl.xml"/>
</article>
